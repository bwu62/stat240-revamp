

# Proportions

```{r,include=F}
library(tidyverse)
options(pillar.print_min = 5, readr.show_col_types = FALSE)
source("ggplot_theme_options.R")
```

Let's look specifically at proportions-type inference setups, where we apply a **binomial model** to sample proportions to infer about an underlying **probability** in the population. We will divide this into two scenarios:

 - One-proportion scenario, where there is a single population with a single probability parameter of interest, and
 - Two-proportions scenario, where there are two populations, each with its own probability parameter, which we seek to compare.


:::{.note}
A proportions-type inference approach using a binomial model is **only appropriate** if your sample consists of either 1 or 2 samples where, for each sample, your data looks like **counts across two categories**, one of which we consider "success" and the other "failure" (e.g. heads/tails, true/false, etc.).

In these setups, the probability parameter of the binomial model **always corresponds to the probability of the _success_ category** by convention. Make sure to define the category whose probability is of primary interest as "success".
:::


## One proportion

### Model notation

In the one-proportion scenario, suppose we draw a **fixed sample size of $n$** observations, each of which we model as **independent** and having some constant underlying **true probability $p$ of being a success**, and $1-p$ of being a failure (and there's no other possible outcome).

Let lower-case **$x$ be the observed number of successes in our sample**, and note that we must have $0\le x\le n$. Let $\hat p=x/n$ denote then the **proportion of successes in our sample**.

It's customary to also use upper-case $X$ to represent our model of the true distribution of $x$, which here we choose to be $X\sim\bin(n,p)$.

Under these assumptions, $\hat p$ is a natural **point estimate** for $p$, i.e. our **sample proportion of successes estimates the true underlying probability of success $p$**, since the LLN guarantees $\hat p\to p$ as $n\to\infty$.

:::{.note}
Note several things:

 - $n$ must be a fixed, predetermined sample size,
 - trials must be able to be reasonably modeled as independent,
 - there must only be 2 possible outcomes (success & failure) for each trial,
 - $p$ is always the TRUE probability of the "success" category, however it's defined,
 - $\hat p$ is the observed sample proportion, which can estimate the true $p$ by LLN,
 - $X$ represents the theoretical RV model we choose to apply to the sample's observed $x$,
 - $x$ represents the actual observed number of successes in your sample out of $n$ trials.
:::

:::{.eg}

```{r d5-rolls,include=F}
# combine 50-roll chunks of data, split, then parse to numeric vector
rolls <- paste0("21252134521555355115322514314333142113433335345333",
                "43242443535423223523352541521331244241531554241354",
                "34244524112155254341541335443433245314125431131335",
                "43114331251421521112234535251142334354341123345541") %>%
  strsplit("") %>% unlist %>% as.numeric
rolls
```
```{r,include=F}
n = length(rolls)
x4 = sum(rolls==4)
x5 = sum(rolls==5)
x = sum(rolls>=4)
options(width = 80)
```

Let's see all this in the context of an example. Below are $n=`r n`$ rolls of a purportedly fair 5-sided die I bought online (yes, I really sat in my office and rolled it `r n` times).

![](d5.jpg){.i3}

```{r reuse-rolls-chunk,ref.label=I('d5-rolls'),include=T}
```
```{r}
# quick table + bar plot of results using base R
table(rolls)
```
```{r,eval=F}
barplot(table(rolls))
```

:::{.i6}
```{r,echo=F}
par(mar=c(2,2,0.5,0),mgp=c(2,.6,0),cex=1.3)
barplot(table(rolls))
```
:::

Suppose my question of interest is whether this specific die design is in fact fair. There are different ways of testing this^[the most [powerful](https://www.scribbr.com/statistics/statistical-power) method is probably a [chi-squared test](https://www.scribbr.com/statistics/chi-square-tests).], but a simple way using a proportions-type setup is to ask **whether the two triangular-shaped faces** (which are 4 and 5) **are observed 2/5 or 40% of the time**.

In this setup, we can define "success" as getting 4 or 5, which has theoretical probability $p=0.4$. Our RV model for $X$, i.e. the number of successes (4s & 5s), is then $X\sim\bin(`r n`,0.4)$.

In our sample, we observed $x=`r x4`+`r x5`=`r x`$ times this actually occured, which gives us a sample proportion of $\hat p=x/n=`r x`/`r n`=`r x/n`$.
:::

### Confidence interval

For a one-proportion scenario, the confidence interval has the following form:

$$
\text{$C\%$ or $(1\!-\!\alpha)$ interval}~=~\hat p~\pm~z_{\alpha/2}\cdot\sqrt{\frac{\hat p(1-\hat p)}{n}},~\text{ where}
$$

 - $\alpha$ is **implicitly defined as 100% – C%**, e.g. for a 95% confidence interval, $\alpha=1-0.95=0.05$,
 
 - $\hat p=x/n$, the sample proportion of successes, is the **point estimate** for the true probability $p$,
 
 - $z_{\alpha/2}$ is the **$\alpha$-level normal critical value** such that $\p(|Z|>|z_{\alpha/2}|)=\p(Z>z_{\alpha/2})+\p(Z<-z_{\alpha/2})=\alpha$, in other words the observation on the standard normal such that the two "outer-tails" defined by it and its mirror image sum to $\alpha$ together.
   
   ::::{.i5 .fold .s}
   ```{r setup-all,echo=F}
   library(tidyverse)
   source("ggplot_theme_options.R")
   ```
   ```{r,fig.width=3.7,fig.height=2.6}
   library(latex2exp)
   ggplot() + geom_function(fun=dnorm, xlim=c(-4,4)) +
     stat_function(fun=dnorm, geom="area", xlim=c(-4,qnorm(.025)), fill="red") +
     stat_function(fun=dnorm, geom="area", xlim=c(qnorm(.975),4), fill="red") +
     scale_x_continuous(breaks=qnorm(c(.025,.5,.975)), minor_breaks=NULL, expand=0,
                        labels=TeX(c("$-z_{\\alpha/2}$","0","$z_{\\alpha/2}$"))) +
     scale_y_continuous(breaks=NULL, limits=c(0,.4), expand=0) + theme(axis.text.x=element_text(size=13)) +
     labs(x=NULL, y=NULL, title=TeX("$z_{\\alpha/2}$ critical value for Z (red areas sum to $\\alpha$)"))
   ```
   ::::
   
   This value is called $z_{\alpha/2}$ since by convention the subscript denotes the area of only the right-corner, which is $\alpha/2$ by symmetry. To compute $\alpha/2$ for a C% interval, you need to ask `qnorm()` for the $(1-\alpha/2)$--percentile, e.g. for a 95% confidence interval, we seek the 97.5%-tile:
   
   ```{r}
   # for a given α, e.g.
   alpha <- 0.05
   # compute the 1-α/2 percentile as the z_α/2 critical value
   1-alpha/2
   qnorm(0.975)  # often approximated as 1.96 or simply 2
   ```
 
 - and finally $\se(\hat p)=\sqrt{\hat p(1-\hat p)/n}$ is the **estimated standard error of $\hat p$**, which can be thought of as dividing the binomial SD by $n$ then substituting $p\to\hat p$ everywhere.

:::{.eg}
Continuing the example above, a 95% confidence interval for $p$ based on `r x` successes out of `r n` trials can be computed as:

```{r}
# define x, n
x <- sum(rolls>=4) ; n <- length(rolls)
x
n
# define p-hat
phat <- x/n   # alternative shortcut: phat <- mean(rolls>=4)
phat
# 95% confidence interval, using c(-1,1) as a shorcut for ±
phat + c(-1,1) * qnorm(0.975) * sqrt(phat*(1-phat)/n)
```
```{r,include=F}
C <- phat + c(-1,1) * qnorm(0.975) * sqrt(phat*(1-phat)/n)
```

Thus, a 95% confidence interval for $p$, i.e. the true probability of 4 or 5, is `r ci(C)`, or in other words, **we are 95% confident the true $p$ is between `r sf(C[1],2)` and `r sf(C[2],2)`**.

If a different level of confidence is desired, simply change the argument to `qnorm()`:

```{r}
# e.g. for 90% interval, implied alpha=0.10 so we want qnorm of (1-0.1/2)=0.95
phat + c(-1,1) * qnorm(0.95) * sqrt(phat*(1-phat)/n)
# a shortcut is to take the midpoint between the confidence level and 1
# another example, for a 99% interval, we want qnorm of 0.995
phat + c(-1,1) * qnorm(0.995) * sqrt(phat*(1-phat)/n)
```

Note the lower the confidence desired the smaller the interval, and vice versa the higher the confidence desired the larger the interval.
:::

### Hypothesis testing

For a one-proportion scenario, where you wish to test the following hypotheses:

$$
H_0:p=p_0~~~~~~~~\\
~~~~~~~~H_a:p<,\,\ne,\,\text{or}> p_0
$$

You start, as always, by **assuming the null**, i.e. suppose that $X\sim\bin(n,p_0)$. Note this means your sample observation $x$ is drawn from this distribution.

For the p-value, simply **compute the appropriate tail area of $x$ corresponding to the alternative**. Remember the rule is for one-sided take the corresponding side tail, and for two-sided take the two outer tails (or take one outer tail and double it).

Then finally, compare with $\alpha$ and make a conclusion.


:::{.eg}
Continuing with the die example, we saw in our sample $\hat p=`r phat`$ was quite close to what we expected under a fair die of $p_0=0.4$. Let's formally test this. Recall from the previous section if we wish to reject $H_0$ if our sample statistic is too high OR too low, we choose the two-sided alternative. This applies here, since if $\hat p$ is too low or too high vs $0.4$, we should reject. Thus, we choose:

$$
H_0:p=0.4\\
H_a:p\ne0.4
$$

Next, under the null we have $X\sim\bin(`r n`,0.4)$. This distribution is shown below, along with a red line at our observed sample $x=`r x`$.

:::{.fold .s}
```{r}
mu = n*.4 ; sd = sqrt(n*.4*(1-.4))
tibble(k=floor(mu-3*sd):ceiling(mu+3*sd),p=dbinom(k,n,0.4)) %>% 
  ggplot(aes(x=k,y=p)) + geom_col() + geom_vline(xintercept=x, color="red", linewidth=1.5) +
  ggtitle(str_glue("Distribution of X under null hypothesis, i.e. Bin({n},0.4)"))
```
:::

Recall for a two-sided alternative, we take the "outer-tail" corresponding to our observed statistic and multiply by 2 to get our final p-value. Here, this means we look for $2\cdot\p(X\le`r x`)$ where $X\sim\bin(`r n`,0.4)$.

```{r}
# our two-sided p-value here
2 * pbinom(x, n, 0.4)
```

**Important note: if our sample $x$ were on the _RIGHT_ half of the curve instead of the left, then the "outer-tail" here would be the _RIGHT_ side tail, **i.e. $\p(X\ge x)$.

If instead our alternative had been $<$ or $>$, then instead the p-value here would be $\p(X\le`r x`)$ or $\p(X\ge`r x`)$ respectively.

```{r}
# p-value if Ha had been p<0.4
pbinom(x, n, 0.4)
# p-value if Ha had been p>0.4 (note the -1 to include the bar at x)
1 - pbinom(x-1, n, 0.4)
```

In any of these cases, we see the p-value is quite large compared to $\alpha$. This means our experimental result of $x=`r x`$ was in fact close to our expectations, so there's no evidence to refute the null. Thus, we do not reject the null, and we conclude the die appears to be fair.
:::


### R method

Of course, you can also use R to compute the interval or do the testing. This is a good way to check your manual calculations to make sure you did it right. The function for both is `binom.test()`. It accepts several arguments:

 - `x` is the observed sample count $x$
 
 - `n` is the sample size `n`
 
 - `p` (defaults to 0.5) is the hypothesized proportion under the null $p_0$
 
 - `alternative` (defaults to `"two.sided"`) controls the direction of the alternative and can be set instead to either `"greater"` or `"less"`
 
 - `conf.level` (defaults to 0.95) controls the desired confidence level

Important note: setting a one-sided alternative will generate a one-sided confidence interval with one end at $\pm\infty$, which is generally not what we desire, so if you want a standard confidence interval as well as a one-sided test, you should run the function twice.

:::{.eg}
Continuing with the die example, recall we still have `x`, `n` defined

```{r}
print(c(x,n))
```

Let's compute a 95% confidence interval for our problem:

```{r}
binom.test(x, n, p=0.4)
```

Note this interval is very slightly wider than our computation, since it uses a modified method called the [Clopper-Pearson](https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval#Clopper%E2%80%93Pearson_interval) formula, which is technically slightly better than our method which is called the [Wald](https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval#Problems_with_using_a_normal_approximation_or_%22Wald_interval%22) interval, but this is beyond the scope of STAT240. For our purposes we will prefer the simpler Wald method.

We can also compute a 90% or 99% interval:

```{r}
binom.test(x, n, p=0.4, conf.level=0.90)
binom.test(x, n, p=0.4, conf.level=0.99)
```

If you demand an R method for our simpler Wald interval (e.g. to check your own computation), the [`BinomCI()`](https://rdrr.io/cran/DescTools/man/BinomCI.html) function from the `DescTools` package works:

```{r}
# compute wald interval to check our work
DescTools::BinomCI(x, n, 0.95, method="wald")
```

For a hypothesis test, note the previous outputs all show that the two-sided p-value is `r sf(binom.test(x,n,0.4)$p.value,4)`. This is once again very slightly different from our computation, since it uses a slightly more exact method where instead of doing $2\cdot\p(X\le`r x`)$, it computes $\p(X\le`r x`)+\p(X\ge`r n*.4*2-x`)$.

```{r,echo=F,results='asis'}
cat(glue::glue('``` r
pbinom({x},{n},0.4) + 1-pbinom({n*.4*2-x-1},{n},.4)
```'))
```
```{r,echo=F}
pbinom(x,n,0.4) + 1-pbinom(n*.4*2-x-1,n,.4)
```

Again, we can feel free to continue doubling the outer tail area on one side as an approximation, which should usually be fairly accurate. We can also run one-sided tests if we wish:

```{r}
binom.test(x, n, p=0.4, alternative="less")
binom.test(x, n, p=0.4, alternative="greater")
```

This time, the p-values are exactly what we found previously (up to rounding).
:::


## Two proportions

### Model notation

In the two-proportions scenario, suppose we draw **samples of size $n_1$, $n_2$ from two different populations**, and we again assume everything is independent (both within and between the two samples). Suppose the populations have **true probabilities $p_1$, $p_2$ of succeeding** for each trial, and again these are treated as true unknown constants.

Let **$x_1$, $x_2$ be observed numbers of successes in our samples** where $0\le x_1\le n_1$ and $0\le x_2\le n_2$ and define **$\hat p_1=x_1/n_1$, $\hat p_2=x_2/n_2$ as the corresponding proportions of successes in our samples**.

Then, our models for the true distributions are $X_1\sim\bin(n_1,p_1)$ and $X_2\sim\bin(n_2,p_2)$. Again, we know from the LLN that $\hat p_1\to p_1$ and $\hat p_2\to p_2$ so we take **$\hat p_1$, $\hat p_2$ as our point estimates for $p_1$, $p_2$**.

So far it's all pretty intuitive.

:::{.eg}
Again, let's see all this in the context of an example. Let's use this dataset of [thoracic surgery outcomes](https://archive.ics.uci.edu/dataset/277/thoracic+surgery+data) for lung cancer patients from the Wroclaw Thoracic Surgery Centre at the [University of Wroclaw](https://uwr.edu.pl/en). A slightly cleaned version can be found here: [`thoracic.csv`](data/thoracic.csv).

```{r import-penguins2,echo=F}
thoracic <- read_csv("data/thoracic.csv")
print(thoracic)
```
```{r,eval=F}
# remember to load packages and set any desired options
thoracic <- read_csv("https://bwu62.github.io/stat240-revamp/data/thoracic.csv")
print(thoracic)
```

There are a lot of columns here we can use (see linked page for explanations of all variables), but just to keep the example simple, suppose we want to see if patients who are smokers have worse 1-year survival rates than non-smokers (spoiler: they do).

Let's consider population 1 to be non-smokers and population 2 to be smokers. For each population, we can use `dplyr` to calculate the number of 1-year survivors in each sample ($x_1$, $x_2$) and divide by the total number of smokers and non-smokers ($n_1$, $n_2$) to get the 1-year survival rates for each group ($\hat p_1$, $\hat p_2$).

```{r}
thoracic_smoker_summary <- thoracic %>% 
  count(smoker, survive1, name="x") %>% 
  group_by(smoker) %>% 
  mutate(n=sum(x)) %>% 
  summarise(x=last(x), n=last(n), phat=x/n)
thoracic_smoker_summary
```
```{r,include=F}
th <- thoracic_smoker_summary
```

We can see now that $x_1=`r th[1,2]`$, $x_2=`r th[2,2]`$, $n_1=`r th[1,3]`$, $n_2=`r th[2,3]`$, $\hat p_1=`r sf(th[1,4],3)`$, $\hat p_2=`r sf(th[2,4],3)`$.

We can now take this dataset and proceed to find a confidence interval or conduct a hypothesis test.
:::

### Confidence interval

In a two-proportions scenario, generally our goal is to run inference on the **difference of the underlying population probabilities $p_1-p_2$**. We think of this as our parameter of interest.

For this parameter, our point estimate naturally is the **difference of our sample proportions $\hat p_1-\hat p_2$**. Then, our interval takes the form:

$$
\text{$C\%$ or $(1\!-\!\alpha)$ interval}~=~(\hat p_1-\hat p_2)~\pm~z_{\alpha/2}\cdot\sqrt{\frac{\hat p_1(1-\hat p_1)}{n_1}+\frac{\hat p_2(1-\hat p_2)}{n_2}},~\text{ where}
$$

- $\hat p_1-\hat p_2$ is our point estimate of the true difference $p_1-p_2$,

- $z_{\alpha/2}$ is the same $\alpha$-level normal critical value,

- $\sqrt{\frac{\hat p_1(1-\hat p_1)}{n_1}+\frac{\hat p_2(1-\hat p_2)}{n_2}}$ is the **standard error of the difference of our sample proportions**, i.e. $\se(\hat p_1-\hat p_2)$. This formula comes from the fact that for independent $X$, $Y$, $\var(X\pm Y)=\var(X)+\var(Y)$

:::{.eg}
Continuing with the thoracic example, let's compute the 95% confidence interval for the true difference of survival probability $p_1-p_2$ between smokers and non-smokers

```{r}
# starting with summary, mutate to add se contribution from each group
# then summarize to get the point estimate, combined se, and interval bounds
# note -diff() is necessary to get row1-row2
thoracic_smoker_summary %>% mutate(se = sqrt(phat*(1-phat)/n)) %>%
  summarize(p1mp2 = -diff(phat), se = sqrt(sum(se^2)),
            lower95 = p1mp2-1.96*se, upper95 = p1mp2+1.96*se)
```
```{r,include=F}
C <- thoracic_smoker_summary %>% mutate(se = sqrt(phat*(1-phat)/n)) %>%
  summarize(p1mp2 = -diff(phat), se = sqrt(sum(se^2)),
            lower95 = p1mp2-1.96*se, upper95 = p1mp2+1.96*se) %>%
  unlist(use.names=F) %>% .[3:4]
```

Thus we can see our 95% confidence interval for the true difference in probabilities is `r ci(C)`. In other words, based on the data, we're 95% confident non-smokeing lung cancer patients are between `r sf(C[1]*100,2)`% and `r sf(C[2]*100,2)`% more likely to survive for at least 1 year after receiving thoracic surgery.
:::
