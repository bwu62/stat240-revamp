

# Regression

Regression is a broad class of methods where predictor variables are used to predict a numeric response. In this class, we will primarily focus on **simple linear regression**, where a single numeric predictor is used and the model is linear.


## Correlation coefficient

First, a brief aside on the correlation coefficient. Suppose we have a sample of pairs of observations $x_i$, $y_i$ drawn from $X$, $Y$ where each pair is independent from other pairs. Note however no assumption of independence is made between the variables, only between different pairs.

Similar to other statistics like mean or variance, there are both theoretical---i.e. population---and sample versions of the correlation coefficient definition. One is the underlying true value and the other is what you observe in your real dataset. The population correlation coefficient is defined as:

$$
\rho=\frac{\e\big[(X-\mu_X)(Y-\mu_Y)\big]}{\sigma_X\sigma_Y}
$$

where the numerator, also called the covariance of $X$ and $Y$, represents how much on average $X$ and $Y$ change together when compared to their means, and the denominator normalizes it by the product of their standard deviations.

Compare this with the definition of the sample correlation coefficient:

$$
r=\frac{\frac1{n-1}\sum(x_i-\bar x)(y_i-\bar y)}{s_xs_y}
$$

Note similar to the definitions of $s_x$, $s_y$, the numerator also use $n-1$ instead of $n$ for its averaging.

It's easy to show that both $\rho$, $r$ always belong in the range $[-1,1]$, i.e. the **correlation coefficient must always have absolute value $<1$**.

Below shows a series of simulated [jointly-normal](https://en.wikipedia.org/wiki/Multivariate_normal_distribution) $x_i$, $y_i$ observations drawn from $X$, $Y$ both with mean 0 and SD 1 but with various population correlation coefficient values:

:::{.fold .s}
```{r,include=F}
set.seed(3)
```
```{r,}
library(tidyverse) ; library(mvtnorm) ; library(plotly)
n <- 200
cor_dfs <- do.call(rbind, lapply(
  c(-20:20/20), \(r) rmvnorm(n,c(0,0),matrix(c(1,r,r,1),ncol=2)) %>% round(3) %>% 
    as.data.frame %>% setNames(c("x","y")) %>% cbind(r=r))) %>% arrange(r,x)
plot_ly(cor_dfs, type = "scatter", x = ~x, y = ~y, frame = ~r, mode = "markers", height=600) %>%
  config(displayModeBar = FALSE) %>% animation_opts(frame = 100, transition = 0) %>% 
  layout(title = list(text = "Simulated X,Y with various correlation coefficients r", x = .15),
         xaxis = list(range = list(-3,3)), yaxis = list(range = list(-3,3)),
         margin = list(l = 140, r = 140, b = 50, t = 50), dragmode=FALSE) %>%
  animation_slider(currentvalue = list(font = list(color = "#444444")))
```
:::

From this, several things should be clear:

 - The correlation coefficient's **sign indicates the direction of the trend**
 
   - Positive $+$ sign indicates a positive relationship (slope $>0$)
   
   - Negative $-$ sign indicates a negative relationship (slope $<0$)
   
 - The correlation coefficient's **absolute value indicates how "tight" the points are**
 
   - Absolute value close to 1 indicates the points are tight around the line

 - Correlation **equal or close to 0 indicates little or no relationship** (flat cloud of points)



