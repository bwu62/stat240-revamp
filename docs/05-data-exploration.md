

# Data Exploration

One of the first and most important things you should do after obtaining a dataset is to **explore the data thoroughly** using a combination of summary statistics and visualizations. Careful data exploration will help you do the following:

 1. Understand the dataset,
 2. Discover interesting, sometimes unexpected patterns and trends,
 3. Identify potential sources of problems (e.g. errors, biases, other obstacles to later analysis),
 4. Formulate meaningful questions to ask using the data, and
 5. Choose the most appropriate path of analysis.

In this chapter, we will cover a variety of data exploration techniques, starting with descriptive (i.e. summary) statistics, then move on to data visualization (i.e. graphing/plotting).




## Descriptive statistics


Descriptive statistics is what most people think of when they hear the word "statistics", i.e. a collection of numbers that summarize some data. This is often a good starting point for exploring a newly encountered dataset.

:::{.def}
A **statistic** is just some number computed from a sample of data, often intended to summarize the data in a specific way. Virtually any function that ingests a sample and outputs a number can be referred to as a statistic.
:::


### Measures of central tendency

There are MANY statistics that quantify the "center" of some sample. These are all collectively referred to as **measures of central tendency**, also often called **averages** for short. The 3 most common averages are the **mean**, **median**, and **mode**.

:::{.note}
**"Average" can refer to ANY measure of central tendency**, i.e. average can refer to either mean, median, or mode (or any of these [other measures](https://en.wikipedia.org/wiki/Central_tendency#Measures)). Thus, it's generally recommended to specify which measure you're referring to and avoid using the word "average" (unless you're being strategically ambiguous).
:::


#### Mean

The arithmetic mean, commonly referred to as just "mean", is what most people think of when they hear "average". It is the **sum of a sample divided by the sample size**. Formally, given a sample $x_1,x_2,\dots,x_n$ the mean $\bar{x}$ is defined as:

$$\bar{x}=\frac1n\sum_{i=1}^nx_i=\frac{x_1+x_2+\cdots+x_n}n$$

The mean may seem the most natural and intuitive central tendency measure, but it has a number of drawbacks:

 1. The mean is sensitive to "outliers" and is not recommended with heavily skewed data.
 2. The mean should generally only be used with truly numeric data, i.e. data where values are intrinsically tied to some quantitative observable.
    - A common example of data that is not "truly" numeric is ordinal data, which is commonly generated by [Likert scales](https://en.wikipedia.org/wiki/Likert_scale) (e.g. strongly disagree, disagree, neutral, agree, strongly agree), or star-based review systems (e.g. &#9733;&#9733;&#9733;&#9733;&#9734;).

Continuing with our previous 21^st^ century US volcanic eruptions dataset, you can use `mean()` to, for example, find the mean length of eruptions in days:


``` r
# import all core tidyverse packages, since we will need several
# (again, this imports readr, tibble, and stringr, as well as several others)
library(tidyverse)
# reload dataset
eruptions_recent <- read_csv(
  "https://bwu62.github.io/stat240-revamp/data/eruptions_recent.csv",
  show_col_types = FALSE
)
```


``` r
# compute mean duration of eruptions
mean(eruptions_recent$duration)
```

```
## [1] 192.0685
```

``` r
# we can check this agrees with our mathematical definition
sum(eruptions_recent$duration) / length(eruptions_recent$duration)
```

```
## [1] 192.0685
```

:::{.note}
If a vector has missing values, i.e. `NA`, `mean()` and most other statistical functions will return `NA`. This is a safety measure, to help remind you to handle missing values appropriately before attempting further analysis. You can tell R to ignore `NA`s and proceed by setting `na.rm = TRUE` in the function.

``` r
# example of NAs causing mean to fail
mean(c(1,6,NA,2))
```

```
## [1] NA
```

``` r
# setting na.rm = TRUE tells R to safely ignore NAs
mean(c(1,6,NA,2), na.rm = TRUE)
```

```
## [1] 3
```
:::


#### Median

The median, a common alternative to the mean, is defined as the **"middle" number in a sorted sample**. Formally, it's the value that is both greater than or equal to half the sample, and also less than or equal to half the sample. If there are an even number of observations, the median isn't uniquely defined but is commonly taken as the mean of the middle two numbers.

The median is generally recommended over the mean in the following situations:

 1. There are "outliers", or the data is significantly skewed.
 2. The data is not truly numeric, e.g. if you have ordinal data.

We can use `median()` to find the median length of eruptions in days:


``` r
# compute median duration of eruptions
median(eruptions_recent$duration)
```

```
## [1] 71
```

``` r
# check to see if it satisfies the formal definition
# recall from the logical vectors section from Chapter 3 that
# mean() of a logical vector gives the proportion of TRUEs
c(
  mean(
    eruptions_recent$duration >= median(eruptions_recent$duration)
  ),
  mean(
    eruptions_recent$duration <= median(eruptions_recent$duration)
  ) 
)
```

```
## [1] 0.5068493 0.5205479
```

Note the median length of eruptions, 71, is significantly smaller than the mean, 192.0684932, because the data is extremely skewed, i.e. there are a few extremely long eruptions, which pull the mean up to be much higher (since it's more sensitive to extreme values).

:::{.note}
It's worth mentioning here the word "outliers" isn't well defined formally and is actually a surprisingly tricky subject in statistics. Here, an "outlier" just loosely refers to observations that differ dramatically compared to the rest of your data. It's important to remember that **not all "outliers" are errors**; some may in fact point to new information you're not aware of.
:::


#### Mode

The mode is the oft-maligned black sheep of the central tendency family. It is defined as **the most common observation**, i.e. the observation that occurs the most number of times in a sample. It's primarily intended for categorical data (e.g. male vs female) though it also has some relevance to distributions (more on this much later).

The mode is of course also a form of "average". For example, statistics show roughly [95% of lumberjacks in the US are male](https://www.zippia.com/lumberjack-jobs/demographics). It would therefore be accurate to say "the average American lumberjack is male". In fact, for categorical data---which is ubiquitous---this is the only possible measure of central tendency.

Unfortunately, base R does not have a convenient function for computing the mode (the function `mode()` is [completely unrelated](https://ds-pl-r-book.netlify.app/modes-types-classes-of-objects.html)), but you can easily either define it yourself or import `Mode()` from the `DescTools` package


``` r
# this defines a simple Mode function using mostly commands we already know
# explanation: table tabulates observations, then
#              sort(- ...) sorts by descending order, then
#              names(...)[1] extracts the name of the first item
# note this function doesn't return multiple modes if there are more than 1
Mode <- function(x) names(sort(-table(x)))[1]
```


``` r
# find the volcano with the most number of eruptions
Mode(eruptions_recent$volcano)
```

```
## [1] "Cleveland"
```

``` r
# how many eruptions has Cleveland had since 2001?
sum(eruptions_recent$volcano == "Cleveland")
```

```
## [1] 13
```


``` r
# the DescTools package also has a Mode function,
# which correctly handles ties and also gives the frequency
# make sure to install it before using: install.packages("DescTools")
DescTools::Mode(eruptions_recent$volcano)
```

```
## [1] "Cleveland"
## attr(,"freq")
## [1] 13
```







<!--

 - central tendency
   - mean, median, mode
 - min, max
 - quantiles
   - quartiles
 - spread
   - var, sd, range, IQR
 - skew
 - correlation?


## Data visualization

 - all plots!

-->
