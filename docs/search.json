[{"path":"index.html","id":"welcome","chapter":"Welcome!","heading":"Welcome!","text":"-progress working draft revamp STAT 240 course notes. Significant changes made order topics, degree coverage, examples employed. Currently, intended supplement rather replace existing body STAT 240 notes.","code":""},{"path":"index.html","id":"prerequisitesscope","chapter":"Welcome!","heading":"Prerequisites/scope","text":"notes, prior R computer science knowledge assumed; everything taught scratch.consult notes, please keep mind aim teach everything need know topic, rather equip foundational understanding encourage learn explore . , typically cover basic usage operations demonstrate key examples, leaving details practice.Also note occasionally bonus/extra/aside content considered advanced knowledge may mentioned passing sake completeness discussing topic, considered outside scope need know.","code":""},{"path":"index.html","id":"how-to-use-this-book","chapter":"Welcome!","heading":"How to use this book","text":"’s tips get book.","code":""},{"path":"index.html","id":"organization","chapter":"Welcome!","heading":"Organization","text":"notes loosely organized following order topics:Setup,R crash course, rapidly bring speed basic R usage,Data exploration, introduce data exploration R,Data transformation, demonstrate common data cleaning techniques,Probability theory (progress), introduce basic probability theory,Inference (added soon), teach foundational inference techniques, specifically:\nInference means,\nInference proportions,\nInference regression.\nInference means,Inference proportions,Inference regression.also appendices additional info:Datasets: info sources preprocessing done data set examples,Cheat sheets: list cheat sheets various packages/programs used notes.","code":""},{"path":"index.html","id":"notes-layout","chapter":"Welcome!","heading":"Notes layout","text":"First, note table contents left chapter navigation bar right page. Use quickly navigate around notes. Also note search bar top corner; use search highlight keywords across entire site. smaller phone screens elements may collapse, fully visible wider laptop/tablet screens.notes pages mostly composed paragraph text (like one), code chunks (see ). also occasionally encounter additional reference links, embedded images, footnotes extra info, tables, elements.block code chunk. frequently annotated comments. Note can copy contents chunk using clipboard icon corner. Also note functions automatically link help pages usage notes, argument explanations, examples.Important notes, often warning common mistakes/errors, appear yellow alert boxes.Tips improving R understanding optimizing workflow sppear green alert boxes.","code":"\n# this is a code chunk; lines starting with # are comments\n# R code in here will be run and output shown below\nprint(\"Hello world!\")[1] \"Hello world!\""},{"path":"index.html","id":"source-code","chapter":"Welcome!","heading":"Source code","text":"notes open-sourced GitHub built using bookdown served GitHub pages, provides convenient, easily editable, reproducible workflow. page link “View source” page right-side navbar, want see ’s hood.Note code base primarily written R Markdown syntax, may include ordinary text, markdown code, YAML headers, R chunks, knitr tweaks, \\(\\LaTeX\\) formulae, pandoc elements (especially fenced divs braced attributes). auxiliary files, may even find HTML/CSS/jQuery snippets. obviously made read/understand, browse curiosity.","code":""},{"path":"index.html","id":"contributing","chapter":"Welcome!","heading":"Contributing","text":"work hard avoid errors, alas nothing perfect! notice errors, please consider contributing suggestion! can 2 ways. (Note: ways require GitHub account, make sure sign register first!1)Directly propose change GitHub pull request:\npage error, click “Edit page” right-side navbar.\nfirst time contributing project, asked “Fork repository”, .e. make copy.\nforking, make edits text editor window appears click “Commit changes…”. Make sure add brief, descriptive title, well additional necessary details description box. Note description box supports markdown syntax.\nNext, click “Propose changes”, click “Create pull request”. , make sure good title description, click “Create pull request” . Make sure leave “Allow edits maintainers” checked, can modify edit want!\ncan check status pull request (PR) PR tab repo.\nPR looks perfect, may immediately merge .\nPR good perfect, may make comments/edits eventually merging.\nPR isn’t par reason, may discuss , ask follow questions, simply close . close PR, don’t discouraged! ’re welcome make contributions, just make sure understand didn’t merge try make better PR next time!\n\npage error, click “Edit page” right-side navbar.first time contributing project, asked “Fork repository”, .e. make copy.forking, make edits text editor window appears click “Commit changes…”. Make sure add brief, descriptive title, well additional necessary details description box. Note description box supports markdown syntax.Next, click “Propose changes”, click “Create pull request”. , make sure good title description, click “Create pull request” . Make sure leave “Allow edits maintainers” checked, can modify edit want!can check status pull request (PR) PR tab repo.\nPR looks perfect, may immediately merge .\nPR good perfect, may make comments/edits eventually merging.\nPR isn’t par reason, may discuss , ask follow questions, simply close . close PR, don’t discouraged! ’re welcome make contributions, just make sure understand didn’t merge try make better PR next time!\nPR looks perfect, may immediately merge .PR good perfect, may make comments/edits eventually merging.PR isn’t par reason, may discuss , ask follow questions, simply close . close PR, don’t discouraged! ’re welcome make contributions, just make sure understand didn’t merge try make better PR next time!seems like much work, can also simply raise issue point error. Note since work , usually lower priority well-written PR, can easily merged single click.","code":""},{"path":"index.html","id":"acknowledgements","chapter":"Welcome!","heading":"Acknowledgements","text":"good time acknowledge people made contributions. Bret Larget original creator STAT 240 author first set STAT 240 notes, primary source inspiration many aspects notes. Cameron Jones also agreed help write practice materials notes evolve. Beyond , thanks also @jennamotto1 also contributing repo (make successful PR get name list!).","code":""},{"path":"index.html","id":"future-ideas","chapter":"Welcome!","heading":"Future ideas","text":"list additional ideas future improvements notes, considered implementation unspecified future time (prioritized finishing first-pass writeup).dark mode?add exercises pageautomagic index generator using _common.R?glossary?DT datatable fancy printouts??","code":""},{"path":"setup.html","id":"setup","chapter":"1 Setup","heading":"1 Setup","text":"chapter take steps necessary fully setup computer. several things need :First, section 1.1 install R Rstudio.Next, section 1.2 install necessary R packages configure recommended Rstudio settings.Finally, section 1.3 setup organization system files.","code":""},{"path":"setup.html","id":"setup-install","chapter":"1 Setup","heading":"1.1 R/Rstudio setup","text":"using R Rstudio throughout course.R free open-source statistical computing software.Rstudio IDE (integrated development environment) makes developing R much easier.\nprefer, can also use different IDE like Visual Studio Jupyter.\nprefer, can also use different IDE like Visual Studio Jupyter.R Rstudio two different programs need installed! Also, previously installed R Rstudio, highly recommended first completely uninstall reinstalling latest version avoid conflicts (instructions Windows Mac).First, install latest R release, version 4.4.1 released Jun 14, 2024; install Rstudio. instructions separated operating system, depending Windows Mac machine.Linux system, follow one linked instructions .Chromebook, try steps.","code":""},{"path":"setup.html","id":"setup-win","chapter":"1 Setup","heading":"1.1.1 Windows instructions","text":"Download R-4.4.1-win.exe run , accepting default settings.Download R-4.4.1-win.exe run , accepting default settings.Download Rstudio-latest.exe run , accepting default settings.Download Rstudio-latest.exe run , accepting default settings.Sometimes, R may need recompile package installation, require Rtools utility. download right version, check system’s page look “System type” line.\nshows “… x64-based processor”, download Rtools installer run , accepting default settings.\nshows “… ARM-based processor”, download Rtools installer run , accepting default settings.\nSometimes, R may need recompile package installation, require Rtools utility. download right version, check system’s page look “System type” line.shows “… x64-based processor”, download Rtools installer run , accepting default settings.shows “… ARM-based processor”, download Rtools installer run , accepting default settings.Now, R Rstudio setup. check installation, find “Rstudio” start menu run . asked choose installation, just accept default click OK.get window looks like , ’re set ready move next section!","code":""},{"path":"setup.html","id":"setup-mac","chapter":"1 Setup","heading":"1.1.2 Mac instructions","text":"First, need determine right R installer file specific machine. Open Apple menu top left corner screen open “mac”.\nshows “Chip: Apple M1/M2/M3”, download R-4.4.1-arm64.pkg run , accepting default settings.\nshows “Processor: …Intel Core”, download R-4.4.1-x86_64.pkg run , accepting default settings.\nget error, check OS version window. ’s older (.e. <11) may need either upgrade OS download older version .\nshows “Chip: Apple M1/M2/M3”, download R-4.4.1-arm64.pkg run , accepting default settings.shows “Processor: …Intel Core”, download R-4.4.1-x86_64.pkg run , accepting default settings.get error, check OS version window. ’s older (.e. <11) may need either upgrade OS download older version .Now, download Rstudio-latest.dmg install . Note dmg virtual disk image file, need follow steps install :\nDouble click file open . mount virtual drive desktop open new Finder window.\nnew window, drag Rstudio icon Applications directory. install computer.\nOpen new Finder window, go Applications directory, find new Rstudio program drag dock easy access.\n(Optional) can now unmount virtual disk. Right click mounted virtual disk desktop choose “Unmount”, alternatively find mounted drive right side dock drag trash bin. can also delete .dmg install file.\nDouble click file open . mount virtual drive desktop open new Finder window.new window, drag Rstudio icon Applications directory. install computer.Open new Finder window, go Applications directory, find new Rstudio program drag dock easy access.(Optional) can now unmount virtual disk. Right click mounted virtual disk desktop choose “Unmount”, alternatively find mounted drive right side dock drag trash bin. can also delete .dmg install file.many () systems, two additional programs need installed everything run smoothly. recommended everyone install just case (’s harm didn’t actually need ).\nDownload XQuartz-2.8.5.pkg run , accepting default settings. installs tool Rstudio uses display certain outputs.\nUsing either Spotlight, Launchpad, Applications directory, open “Terminal” type copy line xcode-select --install hit enter, follow -screen instructions. may asked fingerprint password (note password show type, normal done security purposes).\nDownload XQuartz-2.8.5.pkg run , accepting default settings. installs tool Rstudio uses display certain outputs.Using either Spotlight, Launchpad, Applications directory, open “Terminal” type copy line xcode-select --install hit enter, follow -screen instructions. may asked fingerprint password (note password show type, normal done security purposes).machines, R Rstudio may blocked OS overabundance caution. Follow steps unblock try .Now, assuming everything went smoothly, R Rstudio setup. check installation, find “Rstudio” Dock Applications directory run . asked choose installation, just accept default click OK.get window looks like , ’re set!","code":""},{"path":"setup.html","id":"setup-packs-config","chapter":"1 Setup","heading":"1.2 Packages/config","text":"continuing, make sure can open Rstudio correct version (R-4.4.1) installed!Next, install necessary packages configure recommended options improve workflow.Open Rstudio. Console window, type copy line install.packages(c(\"tidyverse\",\"rmarkdown\")) hit enter.\nRstudio asks whether “use personal library”, choose yes.\nRstudio asks whether “install source”, first try choosing work people. fails, try repeating step 1, time choose yes.\nMake sure see either “successfully unpacked” “downloaded binary packages ” console messages confirm installation succeeded.Open Rstudio. Console window, type copy line install.packages(c(\"tidyverse\",\"rmarkdown\")) hit enter.Rstudio asks whether “use personal library”, choose yes.Rstudio asks whether “install source”, first try choosing work people. fails, try repeating step 1, time choose yes.Make sure see either “successfully unpacked” “downloaded binary packages ” console messages confirm installation succeeded.Next, menu bar top, go “Tools” > “Global Options”.\nfirst page, “Workspace” section, set following:\nTurn “Restore .RData workspace startup”\nensures every time close reopen Rstudio start fresh session uncluttered junk previous sessions.\n\nChange “Save workspace .Rdata exit:” “Never”\nstops Rstudio asking shutdown want save session, also preventing clutter.\n\n\nNext, “R Markdown” page Options window, set following:\nChange “Show output preview :” “Viewer Pane”\nimproves workflow displaying plots Viewer pane instead opening new window.\n\nTurn “Show output inline R Markdown documents”\nalso improves workflow displaying output console instead inline documents.\n\n\n(Optional) wish customize interface, can go “Appearance” page change font theme.2\nPress OK save changes.\nLOTS options can feel free explore later , now move .Next, menu bar top, go “Tools” > “Global Options”.first page, “Workspace” section, set following:\nTurn “Restore .RData workspace startup”\nensures every time close reopen Rstudio start fresh session uncluttered junk previous sessions.\n\nChange “Save workspace .Rdata exit:” “Never”\nstops Rstudio asking shutdown want save session, also preventing clutter.\n\nTurn “Restore .RData workspace startup”\nensures every time close reopen Rstudio start fresh session uncluttered junk previous sessions.\nensures every time close reopen Rstudio start fresh session uncluttered junk previous sessions.Change “Save workspace .Rdata exit:” “Never”\nstops Rstudio asking shutdown want save session, also preventing clutter.\nstops Rstudio asking shutdown want save session, also preventing clutter.Next, “R Markdown” page Options window, set following:\nChange “Show output preview :” “Viewer Pane”\nimproves workflow displaying plots Viewer pane instead opening new window.\n\nTurn “Show output inline R Markdown documents”\nalso improves workflow displaying output console instead inline documents.\n\nChange “Show output preview :” “Viewer Pane”\nimproves workflow displaying plots Viewer pane instead opening new window.\nimproves workflow displaying plots Viewer pane instead opening new window.Turn “Show output inline R Markdown documents”\nalso improves workflow displaying output console instead inline documents.\nalso improves workflow displaying output console instead inline documents.(Optional) wish customize interface, can go “Appearance” page change font theme.2Press OK save changes.LOTS options can feel free explore later , now move .Due poor design, need repeat previous R Markdown configuration steps Rstudio duplicates settings another menu.\nmenu bar top, go “File” > “New File” > “R Markdown”. Ignore options new window click “OK” create new R Markdown file (learn R Markdown files later).\nnew editor pane, open gear-icon dropdown menu make sure reselect options (highlighted red).\nDue poor design, need repeat previous R Markdown configuration steps Rstudio duplicates settings another menu.menu bar top, go “File” > “New File” > “R Markdown”. Ignore options new window click “OK” create new R Markdown file (learn R Markdown files later).new editor pane, open gear-icon dropdown menu make sure reselect options (highlighted red).Now R/Rstudio properly setup.","code":""},{"path":"setup.html","id":"setup-files","chapter":"1 Setup","heading":"1.3 File organization","text":"lot files keep track course, highly recommended create neat directory structure computer help organize files. recommend directory structure similar :“Directory” synonymous “folder”. technical spaces, “directory” often preferred term.tree diagram shows somewhere computer (“..”) make “STAT240” directory. Inside, directories like “homework” “discussion” subdirectory specific assignment (e.g. “hw01”, “hw02”, “ds01”, “ds02”, etc..).also recommend creating directories “data”, place datasets download; “notes”, can place notes download take; “project”, can place project files assigned later. necessary, can also create directories discretion.Make sure STAT240 directory backed cloud synchronized app like OneDrive, Box, iCloud. programs sometimes interfere R/Rstudio may also cut larger datasets.recommend pick different parent directory (“..”) “Desktop” “Documents” since often backed default many modern systems. good alternative either “Downloads” directory usually backed , user’s home directory (instructions Windows Mac).creation, can make directory convenient access making shortcut desktop, pinning somewhere accessible like Quick Access Windows Dock Macs.","code":"..\n└── STAT240/\n    ├── data/\n    ├── discussion/\n    │   ├── ds01/\n    │   ├── ds02/\n    │   ├── ds03/\n    │   :    :\n    ├── homework/\n    │   ├── hw01/\n    │   ├── hw02/\n    │   ├── hw03/\n    │   :    :\n    ├── notes/\n    └── project/"},{"path":"setup.html","id":"setup-troubleshooting-faq","chapter":"1 Setup","heading":"1.4 Setup troubleshooting FAQ","text":"**FAQ added collect commonly encountered problems**","code":""},{"path":"rstudio-intro.html","id":"rstudio-intro","chapter":"2 Intro to R/Rstudio","heading":"2 Intro to R/Rstudio","text":"chapter introduce basics Rstudio help develop workflow testing R code producing beautiful R Markdown documents, using throughout semester.","code":""},{"path":"rstudio-intro.html","id":"rstudio-why","chapter":"2 Intro to R/Rstudio","heading":"2.1 Why Rstudio?","text":"Rstudio free open-source IDE (integrated development environment) designed help facilitate development R code. course don’t need (can write R code using text editor execute terminal) using Rstudio gives access host modern conveniences, just name :R code completion & highlightingeasy access interpreter console, plots, history, help, etc.integration scientific communication tools (e.g. R Markdown, Shiny, etc.)robust debugging toolseasy package/environment managementcustom project workflows (e.g. building websites, presentations, packages, etc.)GitHub SVN integrationand much …learn small fraction Rstudio offer course. always, encouraged explore .","code":""},{"path":"rstudio-intro.html","id":"rstudio-interface","chapter":"2 Intro to R/Rstudio","heading":"2.2 Rstudio interface","text":"default interface setup Rstudio. course can customize , see ---box:brief description purpose tab. ones using frequently course highlighted bold.section find Console, Terminal, Background Jobs tabs\nConsole: arguably important tab Rstudio. provides direct access R interpreter, allowing run code see outputs.\nuseful tips working console:\ncan use TAB key autocomplete code type. works built functions, user-defined objects, even file paths (later).\n\nhighly recommended use TAB often can, can save keystrokes, helps avoid typos!\n\ncan also easily rerun previously executed commands either using ↑ ↓ arrow keys navigate history, even search history using CTRL+R ⌘+R.\n\nTerminal: tab opens terminal current working directory (later). default, Git Bash terminal Windows zsh terminal Macs, can easily changed Options menu.\nBackground Jobs: Rstudio may sometimes run certain operations background jobs . Alternatively, can also run background R scripts desire.\nConsole: arguably important tab Rstudio. provides direct access R interpreter, allowing run code see outputs.\nuseful tips working console:\ncan use TAB key autocomplete code type. works built functions, user-defined objects, even file paths (later).\n\nhighly recommended use TAB often can, can save keystrokes, helps avoid typos!\n\ncan also easily rerun previously executed commands either using ↑ ↓ arrow keys navigate history, even search history using CTRL+R ⌘+R.\nConsole: arguably important tab Rstudio. provides direct access R interpreter, allowing run code see outputs.useful tips working console:can use TAB key autocomplete code type. works built functions, user-defined objects, even file paths (later).highly recommended use TAB often can, can save keystrokes, helps avoid typos!can also easily rerun previously executed commands either using ↑ ↓ arrow keys navigate history, even search history using CTRL+R ⌘+R.Terminal: tab opens terminal current working directory (later). default, Git Bash terminal Windows zsh terminal Macs, can easily changed Options menu.Terminal: tab opens terminal current working directory (later). default, Git Bash terminal Windows zsh terminal Macs, can easily changed Options menu.Background Jobs: Rstudio may sometimes run certain operations background jobs . Alternatively, can also run background R scripts desire.Background Jobs: Rstudio may sometimes run certain operations background jobs . Alternatively, can also run background R scripts desire.section B Environment, History, Connections, Tutorial tabs\nEnvironment: probably second important tab Rstudio. created variables, defined functions, imported datasets, objects used current session appear , along brief descriptions .\nbroomstick icon tab can used clear current session environment, removing defined objects. basically equivalent restarting Rstudio.\nNext broomstick, ’s icon shows memory usage current R session, well “Import Dataset” option can help load datasets, although primarily try write code hand learning purposes.\n\nHistory: tab, find history previous commands current session, want edit rerun something. can also search history, search just current session previous commands anytime opened Rstudio past.\nConnections/Tutorial: can start special data connections, find extra R tutorials wish.\nEnvironment: probably second important tab Rstudio. created variables, defined functions, imported datasets, objects used current session appear , along brief descriptions .\nbroomstick icon tab can used clear current session environment, removing defined objects. basically equivalent restarting Rstudio.\nNext broomstick, ’s icon shows memory usage current R session, well “Import Dataset” option can help load datasets, although primarily try write code hand learning purposes.\nbroomstick icon tab can used clear current session environment, removing defined objects. basically equivalent restarting Rstudio.Next broomstick, ’s icon shows memory usage current R session, well “Import Dataset” option can help load datasets, although primarily try write code hand learning purposes.History: tab, find history previous commands current session, want edit rerun something. can also search history, search just current session previous commands anytime opened Rstudio past.Connections/Tutorial: can start special data connections, find extra R tutorials wish.section C Files, Plots, Packages, Help, Viewer, Presentation tabs.\nFiles: tab gives small, integrated file explorer. can navigate around computer, create/delete/rename files, copy/move files, etc.\nPlots: plots/graphs make show (set options right, otherwise may show pop-). useful features know:\ntop left corner tab, left/right arrows navigating previous next plots (made multiple plots)\nNext , ’s “Zoom” button opens plot larger window.\nNext, ’s “Export” button allows export plot image/pdf/clipboard. opens window additional export options.\nNext, buttons remove current plot, clear plots.\n\nPackages: can view/install/update/load/unload packages. Note can also install packages using console, like previous section.\nHelp: one useful tabs Rstudio. , can access built R help pages. one FIRST places visit help R functions/objects.\nseveral ways access help pages. Suppose want help install.packages() function. can either run ?install.packages help(install.packages) console, put cursor function code hit F1 key.\nhelp page may contain following sections, presents different types information:\nDescription, showing brief summary purpose function\nUsage, listing available arguments (.e. options). argument = sign value, denotes default value\nArguments, details arguments can found\nDetails, details function can found\nValue, gives info function returns output\nSometimes, sections may appear specialized info\nend, may also find advanced notes, links related functions, additional references, example code demos.\n\nleast briefly scan help page time encounter new function. often several different ways use function depending /arguments set, can prevent needing “reinvent wheel” , example, trying manually change output format ’s already built-way output desired format.\n\n\nViewer: preview Rmd document output appear knitting (learn soon).\ntop corner, buttons letting clear current viewer items, well button open viewer new window default web browser, can also useful sometimes checking work printing/exporting.\n\nPresentation: final tab useful ever make presentations Rstudio, e.g. using R’s Beamer reveal.js integrations.\nFiles: tab gives small, integrated file explorer. can navigate around computer, create/delete/rename files, copy/move files, etc.Plots: plots/graphs make show (set options right, otherwise may show pop-). useful features know:\ntop left corner tab, left/right arrows navigating previous next plots (made multiple plots)\nNext , ’s “Zoom” button opens plot larger window.\nNext, ’s “Export” button allows export plot image/pdf/clipboard. opens window additional export options.\nNext, buttons remove current plot, clear plots.\ntop left corner tab, left/right arrows navigating previous next plots (made multiple plots)Next , ’s “Zoom” button opens plot larger window.Next, ’s “Export” button allows export plot image/pdf/clipboard. opens window additional export options.Next, buttons remove current plot, clear plots.Packages: can view/install/update/load/unload packages. Note can also install packages using console, like previous section.Help: one useful tabs Rstudio. , can access built R help pages. one FIRST places visit help R functions/objects.\nseveral ways access help pages. Suppose want help install.packages() function. can either run ?install.packages help(install.packages) console, put cursor function code hit F1 key.\nhelp page may contain following sections, presents different types information:\nDescription, showing brief summary purpose function\nUsage, listing available arguments (.e. options). argument = sign value, denotes default value\nArguments, details arguments can found\nDetails, details function can found\nValue, gives info function returns output\nSometimes, sections may appear specialized info\nend, may also find advanced notes, links related functions, additional references, example code demos.\n\nleast briefly scan help page time encounter new function. often several different ways use function depending /arguments set, can prevent needing “reinvent wheel” , example, trying manually change output format ’s already built-way output desired format.\n\nseveral ways access help pages. Suppose want help install.packages() function. can either run ?install.packages help(install.packages) console, put cursor function code hit F1 key.help page may contain following sections, presents different types information:\nDescription, showing brief summary purpose function\nUsage, listing available arguments (.e. options). argument = sign value, denotes default value\nArguments, details arguments can found\nDetails, details function can found\nValue, gives info function returns output\nSometimes, sections may appear specialized info\nend, may also find advanced notes, links related functions, additional references, example code demos.\n\nleast briefly scan help page time encounter new function. often several different ways use function depending /arguments set, can prevent needing “reinvent wheel” , example, trying manually change output format ’s already built-way output desired format.\nDescription, showing brief summary purpose functionUsage, listing available arguments (.e. options). argument = sign value, denotes default valueArguments, details arguments can foundDetails, details function can foundValue, gives info function returns outputSometimes, sections may appear specialized infoAt end, may also find advanced notes, links related functions, additional references, example code demos.least briefly scan help page time encounter new function. often several different ways use function depending /arguments set, can prevent needing “reinvent wheel” , example, trying manually change output format ’s already built-way output desired format.Viewer: preview Rmd document output appear knitting (learn soon).\ntop corner, buttons letting clear current viewer items, well button open viewer new window default web browser, can also useful sometimes checking work printing/exporting.\ntop corner, buttons letting clear current viewer items, well button open viewer new window default web browser, can also useful sometimes checking work printing/exporting.Presentation: final tab useful ever make presentations Rstudio, e.g. using R’s Beamer reveal.js integrations.concludes tour basic Rstudio interface. also file editor window (also known source panel/window) discuss later , now, let’s learn run basic R commands!","code":""},{"path":"rstudio-intro.html","id":"r-basics","chapter":"2 Intro to R/Rstudio","heading":"2.3 Basics of R","text":"section, give brief introduction working R. prior coding experience assumed. highly encouraged copy run examples read. time capacity, also encouraged peruse linked help pages extra reference links, mandatory.","code":""},{"path":"rstudio-intro.html","id":"r-running","chapter":"2 Intro to R/Rstudio","heading":"2.3.1 Running R code","text":"main way run R code type copy console. Comments can written hashtag # run. output, displayed either console directly ’s text, plot window ’s visual. notes, output shown separate box , starting ## .Try running examples console observe output:[1] appears start output line just means first output value. bracketed numbers part actual output ignored.functions notes automagically link online help pages (help pages inside Rstudio saw previous section). Try clicking barplot() function previous code block see help page.","code":"\n# this line is a comment and will not be run\n# use the copy button in the top corner to easily run this example --->\nprint(\"output is shown here\") # you can also add comments here[1] \"output is shown here\"\n# a VERY simple barplot\n# the c() function creates a vector of numbers\nbarplot(c(1, 3, 2))"},{"path":"rstudio-intro.html","id":"r-math","chapter":"2 Intro to R/Rstudio","heading":"2.3.2 Basic math","text":"One first things learn R use calculator basic math. Operators like +, -, *, /, ^, parentheses ( ) work just like ’d expect. Note R respects standard order operations (see page operation order details).R sometimes output scientific notation, especially number exactly numerically represented due limitations computers. example, compute 2^50 R show result 1.1259e+15, .e. 1.1259×1015. can also type 1.1259e+15 R understand 1.1259×1015.Also note due limitations computers represent numbers, R often distinguish numbers differ less 10-15, .e. 0.000000000000001.3You can also perform integer division R, .e. dividing get quotient remainder, using %/% quotient %% remainder. allows check, example, number even odd.Operators like %/% %% may seem strange first, work just like binary operators R + ^ . examples operators like %% %>% learn later.Trigonometric functions sin(), cos(), tan(), (inverses asin(), acos(), atan() – prefix means arc–), also work ’d expect use radian units. Note pi conveniently predefined \\(\\pi\\). Hyperbolic trig functions also exist need .Exponential logarithm functions exp() log(), also work ’d expect default natural base \\(e\\). Note log function optional base argument using different base. also special base 10 2 versions log10() log2() .Additionally, abs() computes absolute value sqrt() square root (note convention, positive root returned). Taking square root negative number return NaN.","code":"\n(-5 * -3^2 + 4) / 7 - 6[1] 1\n2^50[1] 1.1259e+15\n13 %/% 2[1] 6\n13 %% 2[1] 1\ncos(2 * pi)[1] 1\natan(-1) * 4[1] -3.141593\nlog(exp(2)) * log10(100)[1] 4\nlog(3^5, base = 3)[1] 5\nsqrt(abs(-9))[1] 3"},{"path":"rstudio-intro.html","id":"aside-function-arguments","chapter":"2 Intro to R/Rstudio","heading":"2.3.3 Aside: function arguments","text":"quick aside function “arguments” (.e. additional options can set). R, arguments functions names (see function’s help page details) depending function needed, might set explicitly.previous section, used base = 3 inside log() function explicitly set base argument 3. However, log(3^5, 3) also work, since base second argument (, see help page). Without explicit naming, arguments passed order function.Explicitly naming argument often used clarify teaching purposes, improve debugging legibility, skip certain preceding arguments either unnecessary whose default values acceptable. E.g. suppose function f() 3 arguments, , b, c order. wish set =0 c=1 leaving b blank, can write f(0, c=1).","code":""},{"path":"rstudio-intro.html","id":"r-specials","chapter":"2 Intro to R/Rstudio","heading":"2.3.4 Special values","text":"already mentioned pi predefined. important special values R. TRUE FALSE, along abbreviations T F also predefined. Note capitalization; R case-sensitive language true, True, t TRUE (first two defined, t() matrix transpose function).important thing note R, kind math turns TRUE 1 FALSE 0.Mathematical expressions may also return NaN Number, .e. undefined; Inf infinite. Note R differentiates positive infinity Inf negative infinity -Inf.Additionally, NA used represent missing values, .e. data available. Note NA NaN . learn later handle NA missing values.","code":"\nT[1] TRUE\ntrueError: object 'true' not found\nexp(FALSE) * (TRUE + sqrt(TRUE))[1] 2\nsqrt(-4)[1] NaN\n1 / 0[1] Inf\nlog(0)[1] -Inf"},{"path":"rstudio-intro.html","id":"assignment","chapter":"2 Intro to R/Rstudio","heading":"2.3.5 Assignment","text":"R, variables typically assigned using <- operator, just less < minus - put together. can also use = <- recommended stylistic reasons (see blog post details). class, acceptable prefer <- notes.4You can quickly insert assignment <- operator ALT+- Windows ⌥+- Mac.Generally, = reserved setting arguments inside functions, e.g. like previous code chunk computed log() custom base setting base argument.Variable names can combination upper lower-case letters, numbers, period . underscore _ (treated similar letters), one caveat: variables must begin letter period, number underscore. may use characters variable names.5Observe results expression saved variable, R print default. often confusing first time R users, since may seem like nothing happened. example, running following:produces visible output. normal behavior, since output redirected variable. inspect result, must explicitly call print() object :","code":"\n# this is preferred\nx <- 5\nprint(x)[1] 5\n# this is equivalent and acceptable, but discouraged\nx = 5\nprint(x)[1] 5\nlog(3^5, base = 3)[1] 5\n# these variable names are ok,\n# also remember R is case sensitive!\nvar1 <- 1\nVar1 <- 2\n.OtherVariable <- 3\nanother.variable_42 <- 4\n\nvar1 + Var1 + .OtherVariable + another.variable_42[1] 10\n# even these morse code looking variable names,\n# while not recommended, are technically ok:\n. <- 1\n.. <- 2\n._ <- 3\n._..__ <- 4\n\n. + .. + ._ + ._..__[1] 10# these variable names will raise errors:\n#   1var, _var, bad-var,   e.g.:\n1var <- 1Error: unexpected symbol in \"1var\"\nresult <- 3 * 4 - 5\nresult[1] 7"},{"path":"rstudio-intro.html","id":"summary-functions","chapter":"2 Intro to R/Rstudio","heading":"2.3.6 Summary functions","text":"far, ’ve seen functions run individual values, also functions R run summarize dataset. often statistical nature. give brief summary compute R. -depth discussion meaning applications saved later course.Suppose gather sample observe following values: 3, 6, 6, 2, 4, 1, 5 (don’t worry mean, ’re just using demo). can create vector using c() function store data save :sum() length() functions work like expect produce sum length sample. can use compute mean sample, can also done directly using mean().can also find median (.e. middle number) median() function. (Sadly, ’s built-mode function R, can achieved packages.)can generalize median (50-th percentile) compute percentile using quantile() function, e.g. suppose want compute 30-th percentile:standard deviation another important statistic (think distance average observation mean) can computed using sd(). Note equivalent square root variance can found var().can also find min() max() sample (together give us range() dataset).Another important function working samples %% operator, lets us check value exists dataset.One final statistical function extremely common cor() computes correlation 2 vectors. E.g. suppose following \\((x,y)\\) points: (3.4,1), (5,4.6), (5.7,6.8), (6.5,5.3). can compute correlation \\(x\\) \\(y\\) points like :miscellaneous functions working vectors sometimes useful won’t cover detail now, can explore , prod() computing product numbers vector, sort() sorting vector, rev() reversing vector, unique() getting unique values vector, scale() linearly shifting scaling data mean 0 standard deviation 1, cumsum() cumprod() cumulative sum product along vector, many many …","code":"\ndata <- c(3, 6, 6, 2, 4, 1, 5)\ndata[1] 3 6 6 2 4 1 5\nsum(data) / length(data)[1] 3.857143\nmean(data)[1] 3.857143\nmedian(data)[1] 4\nquantile(data, 0.3)30% \n2.8 \nsqrt(var(data))[1] 1.9518\nsd(data)[1] 1.9518\nmin(data)[1] 1\nmax(data)[1] 6\n# 6 appears in the sample\n6 %in% data[1] TRUE\n# 7 does not appear in the sample\n7 %in% data[1] FALSE\nx <- c(5, 6.5, 3.4, 5.7)\ny <- c(4.6, 5.3, 1, 6.8)\ncor(x, y)[1] 0.8690548"},{"path":"rstudio-intro.html","id":"logical-comparison","chapter":"2 Intro to R/Rstudio","heading":"2.3.7 Logical comparison","text":"Finally, let’s learn basic logical comparisons. crucial data cleaning filtering operations later .R, equality comparison done using == operator. Note double equal sign; single equal assignments arguments. Inequality can checked using !=.Note ! used individually operator, .e. turns TRUE FALSE vice versa.Inequalities done using <, <=, >, >=, less (equal ) greater (equal ).Logical statements can chained together using & operator well | operator (keyboards, vertical bar character typed using SHIFT+\\).& return true expressions sides true; | return true least one expressions sides true. Note & appears higher R’s order operations |.can course chain together R commands compare complicated expressions. sky limit!Since computers don’t infinite precision, arithmetic operations can introduce small errors, especially producing repeating-decimal irrational numbers:imprecisions usually result errors 10-15 less. Generally values around magnitude R treated indistinguishable 0. comparing inexact values like , ’s recommended use .equal() instead ==, allows small tolerance.","code":"\nx <- (2 + 3)^2\nx == 25[1] TRUE\n# if instead we ask \"is x not equal to 25\", we should get FALSE\nx != 25[1] FALSE\n!TRUE[1] FALSE\n# this is equivalent to x != 25\n!(x == 25)[1] FALSE\nx < 30[1] TRUE\nx >= 25[1] TRUE\n(x > 20) & (x <= 30)[1] TRUE\n(x > 20) | (x != 25)[1] TRUE\n# check if x² is even OR if mean of data + 2 * sd is greater than the max\n# note order of operations means we don't need extra parentheses\n# of course, you can add extra parentheses for readability if you wish!\nx^2 %% 2 == 0 | mean(data) + 2 * sd(data) > max(data)[1] TRUE\n1/2 + 1/3 == 5/6[1] FALSE\n1/2 + 1/3 - 5/6[1] -1.110223e-16\nsqrt(2)^2 == 2[1] FALSE\nsqrt(2)^2 - 2[1] 4.440892e-16\nall.equal(1/2 + 1/3, 5/6)[1] TRUE\nall.equal(sqrt(2)^2, 2)[1] TRUE"},{"path":"rstudio-intro.html","id":"packages","chapter":"2 Intro to R/Rstudio","heading":"2.3.8 Packages","text":"Now, let’s briefly discuss packages. One best features R ability anyone easily write distribute packages CRAN (Comprehensive R Archive Network). Currently, 21419 packages available CRAN. also 2300 packages bioinformatics-specific package archive Bioconductor, well countless GitHub.course, primarily make use Tidyverse suite packages, contains several important packages data science: readr reading data, ggplot2 plotting data, dplyr tidyr cleaning data, lubridate stringr working dates strings. learn course progresses.important thing need remember packages :install ; load dailyI.e. need install package computer, need load every time reopen Rstudio want use (unless ’re one people never closes programs). course want setup R/Rstudio new computer, need install well.","code":""},{"path":"rstudio-intro.html","id":"install-a-package","chapter":"2 Intro to R/Rstudio","heading":"2.3.8.1 Install a package","text":"Unless ’re extremely niche work, generally packages want use CRAN can easily installed one time running following.’s important check output messages see install successful, , find important “Error:…” keywords use troubleshooting. Sometimes R ask different things install:R asks use “personal library”, say yes. just means can’t store package files system directory due system permissions, store somewhere else (typically user directory).R asks install “source”, try first; fails, retry yes. just means want R prioritize using precompiled executable files installing, generally much faster.R asks update existing packages installing new package, entirely . like update packages regularly, ’s usually harm don’t want update immediately.\ntry update packages currently loaded, R may ask first “restart R”, usually good idea.\ntry update packages currently loaded, R may ask first “restart R”, usually good idea.","code":"\n# you should have already installed tidyverse from last chapter\n# note the package name MUST be in quotes\ninstall.packages(\"tidyverse\")"},{"path":"rstudio-intro.html","id":"loading-a-package","chapter":"2 Intro to R/Rstudio","heading":"2.3.8.2 Loading a package","text":"can load package either library() require(), basically .6 package names actually load group packages, e.g. library(tidyverse) load “core” Tidyverse packages, include ggplot2, dplyr, tidyr, readr, purrr, tibble, stringr, forcats.Upon loading, many packages print various diagnostic messages console. generally completely ignorable. Sometimes warn “Conflicts”, standard just means overridden default functions. E.g. can see filter() function package dplyr overwritten pre-loaded filter() function stats package.may already guessed message output , can also access function another package without loading entire package using syntax package::function(). often done either avoid name conflicts clarify reader functions come packages.","code":"\nlibrary(tidyverse)── Attaching core tidyverse packages ────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ──────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors"},{"path":"rstudio-intro.html","id":"whitespace","chapter":"2 Intro to R/Rstudio","heading":"2.3.9 Whitespace","text":"final topic, let’s briefly discuss spacing. “Whitespace” refers sequence space-type characters, can mix spaces, tabs, line breaks (.e. hit ENTER).R ignores whitespace variable names, functions, punctuation characters. E.g. following equivalent:long line code often broken across several lines readability. see many examples shortly data visualization chapter.However, make sure break line finish line eventually, otherwise ’ll get error. example, type mean(data console forget close parenthesis (try !) see prompt character > replaced +. continue , patiently waiting finish line, either close typing ) cancel line hitting ESC.","code":"\n# these are all the same\nmean(data)[1] 3.857143\nmean ( data )[1] 3.857143\nmean (\n  data\n)[1] 3.857143"},{"path":"rstudio-intro.html","id":"r-cheat-sheets","chapter":"2 Intro to R/Rstudio","heading":"2.3.10 R cheat sheets","text":"probably important R commands need know now. curated short selection R “cheat sheets” reference need , rough order useful think first time R learner.Matt Baggott’s R Reference Card v2.0 nice complete one-stop-shop R’s built-functions.IQSS’s Base R Cheat Sheet Alexey Shipunov’s One Page R Reference Card slightly shorter curated, offer nice, tighter set critical R commands, along useful examples syntax.slightly longer complete reference manual R, especially details R works different object types data structures, Emmanuel Paradis’s R Beginners may helpful.","code":""},{"path":"rstudio-intro.html","id":"r-markdown","chapter":"2 Intro to R/Rstudio","heading":"2.4 R Markdown","text":"next section, introduce R Markdown, document format allows seamlessly organize integrate text R code/output easily readable editable way. supports many output file types including HTML, PDF, DOCX, can used write reports, articles, presentations, ebooks, even websites (fact, entire website written R Markdown, GitHub repo even maintained using Rstudio; can view source code page using “View source” button right sidebar).Let’s start example! basic R Markdown demo file called demo.Rmd, produces demo.html output. use example learn work Rmd files.","code":"---\ntitle: \"Demo Rmd file\"\nauthor: \"Jane Doe\"\ndate: \"2024-06-20\"\noutput: html_document\n---\n\n```{r setup, include=FALSE}\n# this is a standard \"setup\" chunk usually found at the top of Rmd files,\n# often used for setting options, loading files, and importing libraries\nknitr::opts_chunk$set(echo = TRUE)\nlibrary(tidyverse)\n```\n\n# Section 1\n\n## Subsection A\n\nHere's some ordinary text. You can use Markdown syntax to add more features, e.g. here's a [link](https://markdownguide.org/cheat-sheet), here's some **bold text**, and here's some `inline code`. You can also add images, footnotes, blockquotes, and more. See linked cheat sheet above for more.\n\n 1. Lists are also east to add!\n 2. Here's a second item.\n 3. You can even add sublists:\n    - Here's a sublist with bullets.\n    - Another bullet?\n\n## Subsection B\n\nYou can easily incorporate R code into an Rmd file, with outputs and plots that auto-update. Here's an example code chunk named \"chunk1\".\n\n```{r example-chunk, fig.height=5, fig.align=\"center\"}\ndata <- c(3, 6, 6, 2, 4, 1, 5)\nmean(data)\nhist(data)\n```\n\nYou can even refer to R objects inside text, e.g. the sample mean and standard deviation are `r mean(data)` and `r sd(data)`.\n\n# Section 2\n\nHere's a second section.\n\n<!-- comments in an Rmd file must use HTML-style syntax -->"},{"path":"rstudio-intro.html","id":"source-window","chapter":"2 Intro to R/Rstudio","heading":"2.4.1 Source window","text":"Download demo.Rmd example file open ; automagically open Rstudio new panel top left called source window, actually just basic text editor like Notepad TextEdit, additional R-aware features (later).","code":""},{"path":"rstudio-intro.html","id":"knitting","chapter":"2 Intro to R/Rstudio","heading":"2.4.2 Knitting","text":"first thing learn R Markdown “Knit”, generate output document. Think Rmd file “recipe” tells Rstudio create format nice output audience.top source window, find Knit button click . ’ll see bunch messages scroll new tab called “Render” Rstudio executes processes document. errors, Rstudio produce output document “demo.html” directory saved “demo.Rmd” open preview file “Viewer” tab.can also knit pressing CTRL+SHIFT+K Windows, either CTRL+SHIFT+K, ⌘+SHIFT+K Mac.run errors, look line keyword “Error: …”. Usually, searching error message favorite search engine good way diagnose problem.continue learning R Markdown , feel free play around demo Rmd file re-knit see resulting changes.","code":""},{"path":"rstudio-intro.html","id":"yaml-header","chapter":"2 Intro to R/Rstudio","heading":"2.4.3 YAML header","text":"Rmd files usually start YAML header important metadata file:Title, author, date self explanatory. output: option sets output format R uses knitting. highly recommend using default html_document output format since lightweight, portable, easy us view Canvas grading.lots YAML options can explore, minimally, always 4: title, author, date, output: html_document set beginning Rmd document.","code":"---\ntitle: \"Demo Rmd file\"\nauthor: \"Jane Doe\"\ndate: \"2024-06-20\"\noutput: html_document\n---"},{"path":"rstudio-intro.html","id":"markdown","chapter":"2 Intro to R/Rstudio","heading":"2.4.4 Markdown","text":"R Markdown based Markdown7\nsimple syntax “marking ” text additional formatting. can see mixed paragraphs ordinary text, # Section ## Subsection headings, [links](url) **bold text**, lists sublists, inline separate “chunks” source code.expect learn markdown, minimally learn use section subsection headings, links lists, inline code code chunks.","code":""},{"path":"rstudio-intro.html","id":"code","chapter":"2 Intro to R/Rstudio","heading":"2.4.5 Code","text":"two main ways include code R Markdown file: inline chunks.","code":""},{"path":"rstudio-intro.html","id":"inline-code","chapter":"2 Intro to R/Rstudio","heading":"2.4.5.1 Inline code","text":"want quote R code inside paragraph text, surround backtick character `, can found keyboards top left next 1 key. Note character single quote character ’. example, : `mean(data)` render : mean(data).can also easily refer R variables substitute values, apply functions display output inside text. example, remember data vector defined section 2.3.6? : `r median(data)`\nrender : 4. Note `r prefix , triggers evaluation substitute code. helps avoid “hard-coding”, letting values references update always stay sync.value many digits decimal, e.g. `r mean(data)`\nbecomes: 3.8571429, highly recommended round result reasonable number digits using either round() signif(). case, `r round(mean(data),2)`\nbecomes 3.86 much better.also important round END, present analysis. round original dataset intermediate value used another computation, introduce errors can compound.Generally, recommend rounding either precision data, 2-3 significant figures; picky exact number digits. See page discussion precision rounding.","code":""},{"path":"rstudio-intro.html","id":"code-chunks","chapter":"2 Intro to R/Rstudio","heading":"2.4.5.2 Code chunks","text":"prominent way include R code inside R Markdown document using -called code “chunks” “blocks”. basic structure :can quickly insert chunk using CTRL+ALT+Windows, either CTRL+⌥+, ⌘+⌥+Mac.code chunk basic structure:Chunks always start ```{r r indicates contain R code executed.Chunks always start ```{r r indicates contain R code executed.optionally followed space name chunk, e.g. example-chunk. name necessary, recommend 2 reasons:\ncode errors name chunks, R tell name chunk error, can help troubleshoot faster.\nR also use chunk names (along section headings) generate document outline bottom left source window. can click outline button quickly navigate another part long Rmd file.\noptionally followed space name chunk, e.g. example-chunk. name necessary, recommend 2 reasons:code errors name chunks, R tell name chunk error, can help troubleshoot faster.R also use chunk names (along section headings) generate document outline bottom left source window. can click outline button quickly navigate another part long Rmd file.name can also optionally followed comma , followed additional “chunk options”, extra settings can set control behavior chunk output. long list available options, short list important:\n\nOption\nPossible values (default values bold)\nDescription\neval\nTRUE, FALSE\nControls whether code chunk evaluated.\necho\nTRUE, FALSE\nControls whether code chunk echoed (.e. displayed). Note code can evaluated without echoed, echoed without evaluated, /neither.\ninclude\nTRUE, FALSE\nSetting FALSE run chunk, hide code output. often used “setup chunk” near top document import packages, load datasets, “setup tasks” want hide.\nerror\nTRUE, FALSE\nControls whether allow errors continue knitting. Note option FALSE default, meaning R halt produce output encounters errors.\nfig.width, fig.height\nnumber; default: 7, 5\ncontrol size plot output, one.\nfig.align\n“default”, “left”, “right”, “center”\ncontrols alignment plot output, one. Note option MUST set quotes. “default” set alignment.\ncache\nTRUE, FALSE\nchunk time consuming, can “cache” . Cached chunks rerun unless code inside modified. Note set FALSE default. option used caution! Improper usage may cause code chunks update properly.8\n\nOne last note: remember “setup” chunk top demo file? :\n\n```{r setup, include=FALSE}\n# standard \"setup\" chunk usually found top Rmd files,\n# often used setting options, loading files, importing libraries\nknitr::opts_chunk$set(echo = TRUE)\nlibrary(tidyverse)\n```\n\nfunction knitr::opts_chunk$set() can used set default chunk options chunks document, e.g. can center figures adding fig.align = \"center\" instead copying every chunk header.name can also optionally followed comma , followed additional “chunk options”, extra settings can set control behavior chunk output. long list available options, short list important:One last note: remember “setup” chunk top demo file? :function knitr::opts_chunk$set() can used set default chunk options chunks document, e.g. can center figures adding fig.align = \"center\" instead copying every chunk header.closing header } starting new line, can now put whatever code want inside chunk. code gets run one line time output displayed.closing header } starting new line, can now put whatever code want inside chunk. code gets run one line time output displayed.end, chunk closed another set ```.end, chunk closed another set ```.Remember can also use TAB autocomplete Rmd code chunks save keystrokes avoid typos! can even TAB autocomplete chunk options.concludes discussion code chunks R Markdown.","code":"```{r example-chunk, fig.height=5, fig.align=\"center\"}\ndata <- c(3, 6, 6, 2, 4, 1, 5)\nmean(data)\nhist(data)\n``````{r setup, include=FALSE}\n# this is a standard \"setup\" chunk usually found at the top of Rmd files,\n# often used for setting options, loading files, and importing libraries\nknitr::opts_chunk$set(echo = TRUE)\nlibrary(tidyverse)\n```"},{"path":"rstudio-intro.html","id":"aside-latex","chapter":"2 Intro to R/Rstudio","heading":"2.4.6 Aside: \\(\\LaTeX\\)","text":"also outside scope course, need learn , R Markdown natively supports \\(\\LaTeX\\) code well. ’s rendered using MathJax, open-source Javascript engine rendering equations online. example, $$x=\\frac{-b\\pm\\sqrt{b^2-4ac}}{2a}$$ becomes:\\[x=\\frac{-b\\pm\\sqrt{b^2-4ac}}{2a}\\]see lots \\(\\LaTeX\\) later notes need write math, just wanted mention . can right click equations see notes change MathJax display options, see source code (can course also see source code entire page using link sidebar mentioned previously).wish read \\(\\LaTeX\\), start Rong Zhuang’s MathJax cheat sheet David Richeson’s quick guide lots great beginner-friendly examples. slightly complete list symbols, Eric Torrence’s cheat sheet may also useful.","code":""},{"path":"rstudio-intro.html","id":"cheat-sheet","chapter":"2 Intro to R/Rstudio","heading":"2.4.7 Cheat sheet","text":"need good R Markdown cheat sheet, recommend reference guide published developers Rstudio. Page 1 Markdown syntax guide, pages 2-3 highlight useful chunk options, pages 4-5 additional info different output formats well additional YAML header options.","code":""},{"path":"rstudio-intro.html","id":"workflow","chapter":"2 Intro to R/Rstudio","heading":"2.5 Workflow","text":"final section, briefly discuss workflow considerations working Rstudio R Markdown important know troubleshooting purposes.","code":""},{"path":"rstudio-intro.html","id":"working-directory","chapter":"2 Intro to R/Rstudio","heading":"2.5.1 Working directory","text":"“working directory” concept first-time R users always struggle . Simply put, R always runs ’s inside directory. current directory R running inside called “working directory”. can check current working directory getwd() function:can see current Rstudio session (writing notes) running stat240-revamp directory located /home/admin.Generally, start new Rstudio session, working directory default C:/Users/username/ Windows /Users/username/ Mac (/home/username/ Linux, server building notes day runs), username account name (working directory different intentionally set notes project folder).default working directory actually presents problem, usually different current Rmd file . example, suppose ’re working homework 1. organized files properly—!—Rmd file probably located .../STAT240/homework/hw01/hw01.Rmd. reasons explained next section, working directory always match location current Rmd file.can either methods:Recommended: Using top menu bar, go “Session” > “Set Working Directory” > “Source File Location”. sets working directory location current file edited.\nWindows users, shortcut ALT+S, release keys type W S one time.\nWindows Mac, can also setup custom shortcut action. top menu bar, go “Tools” > “Modify Keyboard Shortcuts…”, find “Set Working Directory Current Document’s Directory” set preferred shortcut. Mine set CTRL+SHIFT+D feel free choose .\nWindows users, shortcut ALT+S, release keys type W S one time.Windows Mac, can also setup custom shortcut action. top menu bar, go “Tools” > “Modify Keyboard Shortcuts…”, find “Set Working Directory Current Document’s Directory” set preferred shortcut. Mine set CTRL+SHIFT+D feel free choose .can also set automagically current Rmd file location try(setwd(dirname(rstudioapi::getSourceEditorContext()$path)),silent=T) can run either console, copied Rmd file (e.g. setup chunk) run whenever open file.can also set manually running setwd() console prefer.Whenever open Rstudio, switch different file, ALWAYS following:Set working directory,Load necessary packages,Read necessary datasets.","code":"\n# check current working directory\ngetwd()[1] \"/home/admin/stat240-revamp\""},{"path":"rstudio-intro.html","id":"knitting-v.-console-execution","chapter":"2 Intro to R/Rstudio","heading":"2.5.2 Knitting v. console execution","text":"need match working directory Rmd file location? difference knitting execution comes play.turns , code runs differently Rstudio console knit Rmd file. Code console always run current working directory, objects created added current session Environment. stay clear Environment.However, Knit document, create new R session background working directory set location Rmd file, run entire document scratch, top bottom produce output file. means working directory Rstudio set place, can break file references need load datasets.may seem overly complicated right now, quickly become intuitive practice .","code":""},{"path":"rstudio-intro.html","id":"tips","chapter":"2 Intro to R/Rstudio","heading":"2.5.3 Tips","text":"end chapter, want offer tips workflow find repeating nearly every student, especially errors arise.important tip avoiding/fixing errors knit often, check output! ?\nKnitting best way catch errors, often knit, easier identify source error (since ’s less new code check).\nKnitting automatically save document , helping avoid lost work due crashes.\ncan check formatting new document elements, whether bodies text, markdown features, plot outputs, code, etc..\nrun unexpected computer Rstudio problems, ’ll recently-knit output can submit interim troubleshoot.\nKnitting best way catch errors, often knit, easier identify source error (since ’s less new code check).Knitting automatically save document , helping avoid lost work due crashes.can check formatting new document elements, whether bodies text, markdown features, plot outputs, code, etc..run unexpected computer Rstudio problems, ’ll recently-knit output can submit interim troubleshoot.Another tip general, think Rstudio’s console place “test ” new line code ’re trying add. Continue test ’re satisfied , immediately copy Rmd. Work console saved! Rmd file work saved knit final output.\ncan easily run line code Rmd file console putting cursor anywhere line using CTRL+ENTER Windows either CTRL+ENTER ⌘+ENTER Mac. run entire chunk, add SHIFT previous shortcut combo. can also use top-right chunk shortcut buttons.\ncan easily run line code Rmd file console putting cursor anywhere line using CTRL+ENTER Windows either CTRL+ENTER ⌘+ENTER Mac. run entire chunk, add SHIFT previous shortcut combo. can also use top-right chunk shortcut buttons.Remember knitting always creates NEW, empty background R session, sets working directory Rmd file location, runs entire file top bottom. means:\nrun line console without copying Rmd file, line run knit.\ndefine object console, forgot copy Rmd file, try use somewhere else file, get error.\nObjects must defined used Rmd file. define data line 20 try computing mean(data) line 10, get error.9\nworking directory match location current Rmd file, may also cause errors need load datasets. Remember always set working directory!\nrun line console without copying Rmd file, line run knit.define object console, forgot copy Rmd file, try use somewhere else file, get error.Objects must defined used Rmd file. define data line 20 try computing mean(data) line 10, get error.9If working directory match location current Rmd file, may also cause errors need load datasets. Remember always set working directory!error? tried following?\nRead error message! Look “Error:…” read search browser! ’re knitting, also line number chunk name (remember name chunks!) help find problem code .\nCheck ’re using function correctly. Read built-help page function, search online example usages.\nCheck input object (often output earlier line chunk) actually correct. E.g. data wasn’t properly created chunk-1, might show error try compute mean(data) chunk-2 . paranoid! Check input output go along!\nimported lots packages, check function names conflicts. E.g. package1 package2 function func1, may accidentally using wrong one. can check also opening help page func1 checking see help page directs .\nstill can’t identify problem, restart R session going top menu bar > “Session” > “Restart R”, run entire Rmd ONE function time, checking function’s output along way. may take longer, almost always work.\ntried everything STILL can’t figure , ask us help.\nRead error message! Look “Error:…” read search browser! ’re knitting, also line number chunk name (remember name chunks!) help find problem code .Check ’re using function correctly. Read built-help page function, search online example usages.Check input object (often output earlier line chunk) actually correct. E.g. data wasn’t properly created chunk-1, might show error try compute mean(data) chunk-2 . paranoid! Check input output go along!imported lots packages, check function names conflicts. E.g. package1 package2 function func1, may accidentally using wrong one. can check also opening help page func1 checking see help page directs .still can’t identify problem, restart R session going top menu bar > “Session” > “Restart R”, run entire Rmd ONE function time, checking function’s output along way. may take longer, almost always work.tried everything STILL can’t figure , ask us help.Phew, lot, wraps introduction working R/Rstudio! , linked bonus readings want learn bit control looping R, need class may good know plan take data science classes build career data science.next chapter, explore data types structures R, well learn read write datasets.","code":""},{"path":"rstudio-intro.html","id":"optional-bonus-topic-controllooping","chapter":"2 Intro to R/Rstudio","heading":"Optional bonus topic: control/looping","text":"includes /else statements /loops. ’re interested, see suggested readings:page Yihui Xie bookdown documentation offers good & quick overview control looping R.-depth discussion, check page Hadley Wickham Advanced R book.","code":""},{"path":"data-vectors.html","id":"data-vectors","chapter":"3 Data Vectors","heading":"3 Data Vectors","text":"chapter, introduce handling data R, starting vectors. Vectors arguably fundamental data structure R. briefly saw example vectors last chapter section 2.3.6 summary functions:Last chapter, mostly used vectors demonstrate summary functions like sum(), mean(), sd(), just tip iceberg. fact, functions R run vectors directly, one value time, actually efficient used way.R, vector can ONE “type” (“class”) object time, e.g. vector numbers, vector characters, vector dates, etc. Vectors mixed-type allowed R.Also, actually working vectors along. ’s single values R fact vectors length 1. E.g. take number, let’s say 5; can use .vector() show fact vector length 1.vectors fundamental structure. may useful going forward think numbers instead numeric vectors, logicals (TRUE/FALSE) logical vectors, characters (.e. strings) character vectors, etc. Everything runs vectors!","code":"\n# create an example dataset of a small sample of numbers\ndata <- c(3, 6, 6, 2, 4, 1, 5)\ndata[1] 3 6 6 2 4 1 5\nx <- 5\nis.vector(x)[1] TRUE\nlength(x)[1] 1"},{"path":"data-vectors.html","id":"types-of-vectors","chapter":"3 Data Vectors","heading":"3.1 Types of vectors","text":"LOTS types data vectors can hold, real complex numbers, characters raw byte-data, even dates times.10 class, deal following 4 types vectors:Numeric vectors, contain real numbers. Generally, R functions don’t distinguish integers decimal numbers (also called “doubles” “floats”) treat numbers decimal-valued real numbers.11Logical vectors, contain TRUE/FALSE values. Usually, arise logical comparison operators functions check condition satisfied. Remember computations, TRUE becomes 1 FALSE becomes 0.12Character vectors, contain characters (often also called “strings”). basically categorical text data. E.g. may groups “” “B”, sex “Male” “Female”. can even sentences, paragraphs, entire bodies text character. briefly touch processing text data class.13Lastly, date vectors also covered. actually closely related numeric vectors (later). ubiquitous data science thus deserving inclusion.14\nNote: cover dates , date + time values (also called datetime) since actually quite different data types many lectures.15\nNote: cover dates , date + time values (also called datetime) since actually quite different data types many lectures.15","code":""},{"path":"data-vectors.html","id":"numeric-vectors","chapter":"3 Data Vectors","heading":"3.2 Numeric vectors","text":"Let’s start numeric vectors. example, suppose want double, square, take arc-tangent, find rounded base-2 logarithm data value, can just directly vector, runs one value time:Note can also use data side operators, argument certain functions:can combine summary functions neat things. example, suppose want manually calculate standard deviation—.e. average deviation mean—sample. , discuss detail later course, now formula:\\[SD = \\sqrt{\\frac1{n-1}\\sum_{=1}^n(x_i-\\bar x)^2}\\qquad\\text{$\\bar{x}=\\frac1n\\sum_{=1}^nx_i$}\\]words, standard deviation square root 1/(n-1) times sum squared differences sample mean data value. easy vector arithmetic R:Let’s break . inside, data - mean(data) subtracts mean data value one time:squared ( ... )^2 , operates one time:Finally, vector summed, scaled 1/(n-1), square rooted get standard deviation. can check correct comparing built-sd() function.","code":"\ndata * 2[1]  6 12 12  4  8  2 10\ndata^2[1]  9 36 36  4 16  1 25\natan(data)[1] 1.2490458 1.4056476 1.4056476 1.1071487 1.3258177 0.7853982 1.3734008\nround(log2(data))[1] 2 3 3 1 2 0 2\n2^data[1]  8 64 64  4 16  2 32\n# log(10) with various bases; note the Inf due to base 1\nlog(10, base = data)[1] 2.095903 1.285097 1.285097 3.321928 1.660964      Inf 1.430677\n# implementing sd() using vector arithmetic syntax\nn <- length(data)\nsqrt((1 / (n - 1)) * sum((data - mean(data))^2))[1] 1.9518\ndata - mean(data)[1] -0.8571429  2.1428571  2.1428571 -1.8571429  0.1428571 -2.8571429  1.1428571\n(data - mean(data))^2[1] 0.73469388 4.59183673 4.59183673 3.44897959 0.02040816 8.16326531 1.30612245\nsd(data)[1] 1.9518"},{"path":"data-vectors.html","id":"logical-vectors","chapter":"3 Data Vectors","heading":"3.3 Logical vectors","text":"“vectorized” operations also work logical comparisons, produce logical vectors. example, can ask R observations even:can ask values within 1 standard deviation mean:Remember section 2.3.4 math turns TRUE 1 FALSE 0? turns extremely useful. example, can use sum() count many values even:can ask proportion data within 1 standard deviation mean, involves taking sum logical comparison dividing length, .e. computing mean:Remember: whenever vector TRUE/FALSE values—usually result logical comparison—can use sum() count many TRUE, mean() compute proportion TRUE values. can course also use numeric operations, just remember TRUE\\(\\rightarrow1\\), FALSE\\(\\rightarrow0\\).","code":"\n# recall %% gives the division remainder\ndata %% 2 == 0[1] FALSE  TRUE  TRUE  TRUE  TRUE FALSE FALSE\n# recall & is the AND operator\n# note the inequality checks EACH value of data against the other side\n(mean(data) - sd(data) <= data) & (data <= mean(data) + sd(data))[1]  TRUE FALSE FALSE  TRUE  TRUE FALSE  TRUE\n# sum(logical vector) counts the number of TRUEs\n# here, we find 4 data values are even\nsum(data %% 2 == 0)[1] 4\n# mean(logical vector) = sum(logical vector) / length(logical vector)\n# thus, it's a shortcut for calculating proportion of TRUEs\n# here, we find 57% of the data is within 1 sd of the mean\nmean(\n  (mean(data) - sd(data) <= data) & (data <= mean(data) + sd(data))\n)[1] 0.5714286"},{"path":"data-vectors.html","id":"other-constructors","chapter":"3 Data Vectors","heading":"3.4 Other constructors","text":"far, ’ve learned construct vectors using c() function, example data<-c(3,6,6,2,4,1,5). common ways construct .One easiest, just need sequence integers, use : operator:seq() function something similar, except also additional arguments specify step size length.specifies many numbers total (note: ONE arguments can set time).Vectors can also created rep() function lets repeat contents. two arguments: times controls many times repeat entire input, controls many times repeat element input vector. can specify either arguments.16 Note rep() can used repeat objects , just numbers.Finally, can mix match constructors, using combination c(), :, seq(), rep() heart’s content.","code":"\n1:5[1] 1 2 3 4 5\n10:-10 [1]  10   9   8   7   6   5   4   3   2   1   0  -1  -2  -3  -4  -5  -6  -7  -8  -9\n[21] -10\nseq(1, 5)[1] 1 2 3 4 5\nseq(0, 100, by = 10) [1]   0  10  20  30  40  50  60  70  80  90 100\nseq(0, 1, length.out = 101)  [1] 0.00 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15\n [17] 0.16 0.17 0.18 0.19 0.20 0.21 0.22 0.23 0.24 0.25 0.26 0.27 0.28 0.29 0.30 0.31\n [33] 0.32 0.33 0.34 0.35 0.36 0.37 0.38 0.39 0.40 0.41 0.42 0.43 0.44 0.45 0.46 0.47\n [49] 0.48 0.49 0.50 0.51 0.52 0.53 0.54 0.55 0.56 0.57 0.58 0.59 0.60 0.61 0.62 0.63\n [65] 0.64 0.65 0.66 0.67 0.68 0.69 0.70 0.71 0.72 0.73 0.74 0.75 0.76 0.77 0.78 0.79\n [81] 0.80 0.81 0.82 0.83 0.84 0.85 0.86 0.87 0.88 0.89 0.90 0.91 0.92 0.93 0.94 0.95\n [97] 0.96 0.97 0.98 0.99 1.00\n# repeat a single number\nrep(2, 5)[1] 2 2 2 2 2\n# repeat a vector, specifying both times and each\nrep(1:3, times = 3, each = 4) [1] 1 1 1 1 2 2 2 2 3 3 3 3 1 1 1 1 2 2 2 2 3 3 3 3 1 1 1 1 2 2 2 2 3 3 3 3\n# you can also let times be a vector, as well as repeat other objects\nrep(c(TRUE, FALSE), times = c(2, 4))[1]  TRUE  TRUE FALSE FALSE FALSE FALSE\nrep(c(1, 3, 7:9, seq(10, 12, by = 0.5)), each = 2) [1]  1.0  1.0  3.0  3.0  7.0  7.0  8.0  8.0  9.0  9.0 10.0 10.0 10.5 10.5 11.0 11.0\n[17] 11.5 11.5 12.0 12.0"},{"path":"data-vectors.html","id":"multiple-vectors-vector-recycling","chapter":"3 Data Vectors","heading":"3.5 Multiple vectors + vector recycling","text":"may surprise learn vectorized operations also work multiple vectors! vectors aren’t length, shorter vectors repeated match length longest vector. called recycling. Example:class, never need loop exercises (hence ’s considered bonus topic covered notes instead left optional additional reading).Instead, always look solution using vectorized operations. R, vectorized operations basically always MUCH faster loops, due low-level parallelization optimizations.","code":"\n# define some vectors for demo\n# x1, x2 are both length 6 vectors\n# y and z have lengths 3 and 2\nx1 <- 0:5         # x1:  0, 1, 2, 3, 4, 5\nx2 <- -2:3        # x2: -2,-1, 0, 1, 2, 3\ny  <- 1:3         #  y:  1, 2, 3\nz  <- c(-1, 1)    #  z: -1, 1\n# sum vectors one element at a time\nx1 + x2[1] -2  0  2  4  6  8\n# take powers, again one element at a time from each vector\nx2^x1[1]   1  -1   0   1  16 243\n# take differences, one element at a time, recycling y\nx1 - y[1] -1 -1 -1  2  2  2\n# log y with x1+2 as base, again recycling y\nlog(y, base = x1 + 2)[1] 0.0000000 0.6309298 0.7924813 0.0000000 0.3868528 0.5645750\n# more complex operation that recycles multiple vectors,\n# as well as some numbers (which are just length 1 vectors)\n2^abs(x1 * z) - x2^y - median(data)[1] -1 -3  0  3  8  1\n# these also work with other numeric/logical functions we've seen so far\n# here, left side is a length 6 vector, right side is a length 2 vector,\n# so right side is recycled three times then compared with left\nx2 <= atan(z) * mean(x1)[1]  TRUE  TRUE FALSE  TRUE FALSE FALSE"},{"path":"data-vectors.html","id":"in-membership","chapter":"3 Data Vectors","heading":"3.6 %in% (Membership)","text":"One notable exception %% operator, “vectorizes” left side. example, suppose want know elements z x1. ’s :want ask elements z x1, must prepend expression ! negate :Note difference z == x1, recycles z, checks element-wise equality:another common point confusion first time R users. Make sure understand difference checking vector membership, .e. element one vector also contained somewhere another vector, vs checking element--element equality, .e. checking 1st elements , 2nd elements , 3rd elements , etc. (possibly recycling). See StackOverflow page examples.Going forward, continue use vectorized functions vector recycling code examples, sometimes without drawing attention , sake brevity. Pretty soon, concepts also feel like second nature !","code":"\nz %in% x1[1] FALSE  TRUE\n!z %in% x1[1]  TRUE FALSE\nz == x1[1] FALSE  TRUE FALSE FALSE FALSE FALSE"},{"path":"data-vectors.html","id":"vector-subsetting","chapter":"3 Data Vectors","heading":"3.7 Vector subsetting","text":"Let’s also quickly cover vector subsetting. R, many ways extract subset (.e. just portion) vector. 2 important things remember throughout R subsetting objects:R indexes 1, 0. words, R starts counting position objects 1.Bounds inclusive. words, R generally includes start end bounds subsetting.Knowing , let’s learn subsetting examples. pair useful built-objects vectors letters LETTERS, contain respectively 26 lowercase uppercase letters English alphabet. letters make character vector (discuss detail next section).can extract elements vector [] operator, giving either vector numeric positions, vector TRUE/FALSE values, negative vector exclusions (.e. anything except). Examples:","code":"\nletters [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\" \"t\"\n[21] \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\n# giving numeric positions of desired elements\n# remember numbers are numeric vectors of length 1\nletters[1][1] \"a\"\n# of course this also works with longer vectors\nletters[5:10][1] \"e\" \"f\" \"g\" \"h\" \"i\" \"j\"\n# naturally you can use more complex syntax if needed,\n# as long as the result is a numeric vector,\n# repeating indices give duplicate values\nletters[c(1, 24:26, rep(5, 8))] [1] \"a\" \"x\" \"y\" \"z\" \"e\" \"e\" \"e\" \"e\" \"e\" \"e\" \"e\" \"e\"\n# you can also use a logical vector, here we check if\n# each position is even, returning every second letter\nletters[1:26 %% 2 == 0] [1] \"b\" \"d\" \"f\" \"h\" \"j\" \"l\" \"n\" \"p\" \"r\" \"t\" \"v\" \"x\" \"z\"\n# logical vectors will be recycled if necessary, so this also works\nletters[c(FALSE, TRUE)] [1] \"b\" \"d\" \"f\" \"h\" \"j\" \"l\" \"n\" \"p\" \"r\" \"t\" \"v\" \"x\" \"z\"\n# using negative vectors is like saying \"anything EXCEPT\"\nletters[-1] [1] \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\" \"t\" \"u\"\n[21] \"v\" \"w\" \"x\" \"y\" \"z\"\n# again, this also works with vectors of negatives\nletters[-1:-10] [1] \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\" \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\n# of course this is equivalent to\nletters[-(1:10)] [1] \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\" \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\n# note the parentheses there, without it you get -1,0,1,...,10\n# which raises an error (what we want is -1,-2,...,-10)\n# this is because positive and negative position syntax cannot be mixed\nletters[-1:10]Error in letters[-1:10] : only 0's may be mixed with negative subscripts"},{"path":"data-vectors.html","id":"sortingreordering","chapter":"3 Data Vectors","heading":"3.8 Sorting/reordering","text":"Sometimes, may need sort/reorder vectors. already saw previous section can reorder vectors subsetting vector positions. vector positions exhausts vector without repeating (.e. returns element vector exactly ), result reordering vector.can course also R sort vector . two main functions sorting: sort(), expect returns vector elements rearranged lowest highest (unless set argument decreasing = TRUE opposite); order(), simply returns order elements go (.e. vector positions belong) sorted lowest highest (, unless set decreasing = TRUE).final function sometimes handy rev() function, reverses vector.general, R operations change input object place. E.g. sort(data2) returns COPY data2 elements sorted; actually change data2. true functions R, exceptions. example, observe:want object updated place, explicitly tell R overwrite assignment <- operator, like :’s often considered bad practice overwrite input like , since can destructive , used caution, can easily lead errors road. recommend whenever possible writing output new object instead, like :general, R inputs outputs totally independent objects special “connections.”17. want operation saved, make sure remember assign output something!","code":"\n# defining a new data2 vector to use for examples,\n# trust me, this will REALLY help clarify what's happening in a minute\ndata2 <- data * 10\ndata2[1] 30 60 60 20 40 10 50\n# ok, now let's proceed with the demos, first up:\n# manual reordering, e.g. swapping the first and last elements\nn <- length(data2)\ndata2[c(n, 2:(n-1), 1)][1] 50 60 60 20 40 10 30\n# simply sort the data in ascending order\nsort(data2)[1] 10 20 30 40 50 60 60\n# sort in descending order\nsort(data2, decreasing = TRUE)[1] 60 60 50 40 30 20 10\n# return the order of positions that WOULD sort it\norder(data2)[1] 6 4 1 5 7 2 3\n# passing this as a subsetting vector gives the sorted vector\ndata2[order(data2)][1] 10 20 30 40 50 60 60\n# reverse the vector\nrev(data2)[1] 50 10 40 20 60 60 30\n# original data2 vector\ndata2[1] 30 60 60 20 40 10 50\n# sort data2\nsort(data2)[1] 10 20 30 40 50 60 60\n# is it changed?\ndata2[1] 30 60 60 20 40 10 50\n# overwrite data2 with the sorted copy (discouraged syntax)\ndata2 <- sort(data2)\n# now it's changed\ndata2[1] 10 20 30 40 50 60 60\n# save sorted data2 to new object (encouraged syntax)\ndata2_sorted <- sort(data2)\ndata2_sorted[1] 10 20 30 40 50 60 60"},{"path":"data-vectors.html","id":"character-vectors","chapter":"3 Data Vectors","heading":"3.9 Character vectors","text":"letters vector last section one example character vector. can create character vector also c() rep() ’ve seen . creating characters, can use either single ' double \" quote character, difference.","code":"\n# creating a demo character vector, e.g. these are my friends!\nfriends <- c(\"Alice\", \"Bob\", \"Charlie\", \"Donny\", \"Emmy\",\n             \"Francine\", \"Genevieve\", \"Heinemann\")\nfriends[1] \"Alice\"     \"Bob\"       \"Charlie\"   \"Donny\"     \"Emmy\"      \"Francine\" \n[7] \"Genevieve\" \"Heinemann\"\n# you can also use rep, e.g. I can assign my friends into 2 groups\ngroups <- rep(LETTERS[1:2], time = 4)\ngroups[1] \"A\" \"B\" \"A\" \"B\" \"A\" \"B\" \"A\" \"B\""},{"path":"data-vectors.html","id":"basic-string-functions","chapter":"3 Data Vectors","heading":"3.9.1 Basic string functions","text":"Base R number common functions working strings: nchar() getting number characters, tolower()/toupper() convert case, substr() extracting substrings, paste()/paste0() concatenate (e.g. “glue” together) strings, strrep() repeating characters string.","code":"\n# get the number of characters in each name\nnchar(friends)[1] 5 3 7 5 4 8 9 9\n# convert names to all upper or all lower\ntoupper(friends)[1] \"ALICE\"     \"BOB\"       \"CHARLIE\"   \"DONNY\"     \"EMMY\"      \"FRANCINE\" \n[7] \"GENEVIEVE\" \"HEINEMANN\"\ntolower(friends)[1] \"alice\"     \"bob\"       \"charlie\"   \"donny\"     \"emmy\"      \"francine\" \n[7] \"genevieve\" \"heinemann\"\n# get the first 3 characters of each name\nsubstr(friends, 1, 3)[1] \"Ali\" \"Bob\" \"Cha\" \"Don\" \"Emm\" \"Fra\" \"Gen\" \"Hei\"\n# get the last 3 characters of each name;\n# remember R always includes bounds, so to get the last three,\n# we want to get n-2,n-1,n where n is the number of characters\n# note this is done once again with our old friend, vectorization!\nsubstr(friends, nchar(friends) - 2, nchar(friends))[1] \"ice\" \"Bob\" \"lie\" \"nny\" \"mmy\" \"ine\" \"eve\" \"ann\"\n# remove the first and last characters of each name\nsubstr(friends, 2, nchar(friends) - 1)[1] \"lic\"     \"o\"       \"harli\"   \"onn\"     \"mm\"      \"rancin\"  \"eneviev\" \"eineman\"\n# paste can \"glue\" on single or (recycled) vectors of strings\npaste(friends, \"is my friend\")[1] \"Alice is my friend\"     \"Bob is my friend\"       \"Charlie is my friend\"  \n[4] \"Donny is my friend\"     \"Emmy is my friend\"      \"Francine is my friend\" \n[7] \"Genevieve is my friend\" \"Heinemann is my friend\"\npaste(\"My friend\", friends, \"is in group\", groups)[1] \"My friend Alice is in group A\"     \"My friend Bob is in group B\"      \n[3] \"My friend Charlie is in group A\"   \"My friend Donny is in group B\"    \n[5] \"My friend Emmy is in group A\"      \"My friend Francine is in group B\" \n[7] \"My friend Genevieve is in group A\" \"My friend Heinemann is in group B\"\n# paste0(...) is a shortcut for paste(..., sep=\"\")\n# sep sets the separator between each string (default: a space \" \")\npaste0(friends, \"123\")[1] \"Alice123\"     \"Bob123\"       \"Charlie123\"   \"Donny123\"     \"Emmy123\"     \n[6] \"Francine123\"  \"Genevieve123\" \"Heinemann123\"\npaste(friends, \"123\", sep = \"_\")[1] \"Alice_123\"     \"Bob_123\"       \"Charlie_123\"   \"Donny_123\"     \"Emmy_123\"     \n[6] \"Francine_123\"  \"Genevieve_123\" \"Heinemann_123\"\n# paste also has an argument called collapse, which sets a separator,\n# then uses that separator to collapse the vector into a single string\npaste(friends, collapse = \", \")[1] \"Alice, Bob, Charlie, Donny, Emmy, Francine, Genevieve, Heinemann\"\n# repeat characters in each string a set number of times\nstrrep(friends, 3)[1] \"AliceAliceAlice\"             \"BobBobBob\"                  \n[3] \"CharlieCharlieCharlie\"       \"DonnyDonnyDonny\"            \n[5] \"EmmyEmmyEmmy\"                \"FrancineFrancineFrancine\"   \n[7] \"GenevieveGenevieveGenevieve\" \"HeinemannHeinemannHeinemann\"\n# of course, this can also be vectorized!\nstrrep(friends, 1:8)[1] \"Alice\"                                                                   \n[2] \"BobBob\"                                                                  \n[3] \"CharlieCharlieCharlie\"                                                   \n[4] \"DonnyDonnyDonnyDonny\"                                                    \n[5] \"EmmyEmmyEmmyEmmyEmmy\"                                                    \n[6] \"FrancineFrancineFrancineFrancineFrancineFrancine\"                        \n[7] \"GenevieveGenevieveGenevieveGenevieveGenevieveGenevieveGenevieve\"         \n[8] \"HeinemannHeinemannHeinemannHeinemannHeinemannHeinemannHeinemannHeinemann\""},{"path":"data-vectors.html","id":"pattern-string-functions","chapter":"3 Data Vectors","heading":"3.9.2 Pattern string functions","text":"also functions working patterns. don’t need master functions, basic demos may prove helpful. Primarily, grep()/grepl() pattern matching, sub()/gsub() pattern replacing. prefix/suffix matching startsWith()/endsWith() also occasionally useful.noted patterns fairly short (mostly one single character) simplicity example, patterns can many characters long necessary.functions (well several listed grep() help page), actually accept complex pattern syntax search pattern. advanced search pattern syntax called “regular expressions” “regex” short. can things like match groups characters, match repeated characters groups, match specific locations words sentences, .class cover regular expressions real detail due limited time, feel free explore cheat sheet well two additional articles matter.","code":"\n# which friends (by position) have a lowercase \"e\" in their name?\ngrep(\"e\", friends)[1] 1 3 6 7 8\n# alternatively, return a TRUE/FALSE vector result instead for each element\ngrepl(\"e\", friends)[1]  TRUE FALSE  TRUE FALSE FALSE  TRUE  TRUE  TRUE\n# you can use either one to subset the original vector to get actual names\nfriends[grep(\"e\", friends)][1] \"Alice\"     \"Charlie\"   \"Francine\"  \"Genevieve\" \"Heinemann\"\n# you can disable case sensitivity, which adds Emmy to the results\nfriends[grep(\"e\", friends, ignore.case = TRUE)][1] \"Alice\"     \"Charlie\"   \"Emmy\"      \"Francine\"  \"Genevieve\" \"Heinemann\"\n# you can use sub() to replace patterns\n# here we can create a set of variant spellings, changing -y to -ie\nsub(\"y\", \"ie\", friends)[1] \"Alice\"     \"Bob\"       \"Charlie\"   \"Donnie\"    \"Emmie\"     \"Francine\" \n[7] \"Genevieve\" \"Heinemann\"\n# sub() can only replace once (inside each element),\n# but gsub() can replace ALL occurrences\nsub(\"n\", \"m\", friends)[1] \"Alice\"     \"Bob\"       \"Charlie\"   \"Domny\"     \"Emmy\"      \"Framcine\" \n[7] \"Gemevieve\" \"Heimemann\"\ngsub(\"n\", \"m\", friends)[1] \"Alice\"     \"Bob\"       \"Charlie\"   \"Dommy\"     \"Emmy\"      \"Framcime\" \n[7] \"Gemevieve\" \"Heimemamm\"\n# which friends have a name that endsWith() \"y\"?\n# (startsWith() does the opposite)\nendsWith(friends, \"y\")[1] FALSE FALSE FALSE  TRUE  TRUE FALSE FALSE FALSE"},{"path":"data-vectors.html","id":"additional-stringr-functions","chapter":"3 Data Vectors","heading":"3.9.3 Additional stringr functions","text":"stringr, one core Tidyverse packages, contains alternative set functions working strings. Many similar purpose base R versions (although subtle differences). E.g. str_length() nchar(), str_to_lower()/str_to_upper() replicate tolower()/toupper(), str_replace() similar sub(), str_sub() extends substr(), etc. ’s full list doppelgänger stringr functions.However, useful stringr functions counterparts base R (least whose counterparts require much complex expressions). small curation .","code":"\n# since stringr is a \"core\" tidyverse package,\n# you can load it (+other core packages) with library(tidyverse)\n# you can also just load stringr by itself if that's all you need\nlibrary(stringr)\n# count how many times a pattern occurs\nstr_count(friends, \"e\")[1] 1 0 1 0 0 1 4 2\n# change strings to title case, i.e. first letter uppercase, all else lower\nstr_to_title(toupper(friends))[1] \"Alice\"     \"Bob\"       \"Charlie\"   \"Donny\"     \"Emmy\"      \"Francine\" \n[7] \"Genevieve\" \"Heinemann\"\n# \"pad\" a vector of strings to a constant length\nstr_pad(friends, width = 12, side = \"right\", pad = \".\")[1] \"Alice.......\" \"Bob.........\" \"Charlie.....\" \"Donny.......\" \"Emmy........\"\n[6] \"Francine....\" \"Genevieve...\" \"Heinemann...\""},{"path":"data-vectors.html","id":"comparing-strings","chapter":"3 Data Vectors","heading":"3.9.4 Comparing strings","text":"Strings, like numbers, can also logically compared R using ==, !=, <, <=, >, >= operators (also vectorized course). Checking equality self-explanatory, inequalities evaluate dictionary sorting order, .e. order might appear dictionary, except generalized include just letters also number symbols.snippet code (worry learning right now) prints “dictionary” sorting order ordinary keyboard characters typable standard US English keyboard layout ascending order.ordering depends platform; order *nix systems (.e. Mac/Linux). Windows orders '- !\"#$%&()*,./:;?@[\\]^_`{|}~+<=>0123...yYzZ instead.Characters sorted order sequence characters, characters earlier sequence “less ” later characters. Strings first character sorted second character; second character also , sorted third, (just like normal dictionaries)Note however nothingness, .e. absence character (string ends), comes character, makes sense otherwise “app” appear “apple”. series examples demonstrating string sorting.Using newfound wisdom, can now conclusively settle age old debates!","code":"\n# print out the result\ncat(\n  # sort the characters\n  sort(\n    # flatten list output to a big vector of characters\n    unlist(\n      # split symbols into individual characters\n      strsplit(\n        # make a vector of all ordinary keyboard characters\n        c(letters, LETTERS, 0:9, \"`~!@#$%^&*()_+-=[]\\\\{}|;':\\\",./<>? \"),\n        \"\"\n      )\n    )\n  ),\n  sep = \"\"\n)\n _-,;:!?.'\"()[]{}@*/\\%`^+<=>|~$0123456789aAbBcCdDeEfFgGhHiIjJkKlLmMnNoOpPqQrRsStTuUvVwWxXyYzZ\n\n\"apple\" == \"apple\"[1] TRUE\n# note equality also implies both >= and <=\n\"apple\" >= \"apple\"[1] TRUE\n# remember R is case sensitive, so these are different\n\"apple\" != \"Apple\"[1] TRUE\n# comparing apples and oranges\n\"apple\" == \"orange\"[1] FALSE\n\"apple\" < \"orange\"[1] TRUE\n# numbers and symbols can also dictionary-sort like letters\n# note these numeral characters have NO numeric meaning!\n\"42\" < \"43\"[1] TRUE\n\"1 pm\" < \"2 pm\"[1] TRUE\n\"STAT240\" < \"STAT340\"[1] TRUE\n# however symbols come before numbers, thus\n\"1,000\" < \"1000\"[1] TRUE\n\"-3.00\" < \"-3.14\"[1] TRUE\n# and remember ending a string comes before any other character\n\"-3\" < \"-3.14\"[1] TRUE\n# what is the greatest state? (head prints the first 6)\nhead(sort(state.name, decreasing = TRUE))[1] \"Wyoming\"       \"Wisconsin\"     \"West Virginia\" \"Washington\"    \"Virginia\"     \n[6] \"Vermont\"      \n# note by definition of inequalities, we can also use min/max\n# which will find the first and last alphabetically\nc(min(state.name), max(state.name))[1] \"Alabama\" \"Wyoming\"\n# is the pen mightier than the sword?\n\"pen\" > \"sword\"[1] FALSE\n# is Windows better than Mac?\n\"Windows\" > \"Mac\"[1] TRUE\n# and most importantly, did the chicken come before the egg?\n\"chicken\" < \"egg\"[1] TRUE"},{"path":"data-vectors.html","id":"ordered-data","chapter":"3 Data Vectors","heading":"3.9.5 Bonus: ordered data","text":"Ordered categorical data (also called ordinals) extremely common, ’s worth briefly mentioning , even ’s considered mostly outside scope course. characters natural ordering present, ’s recommended use factor() convert , setting ordered = TRUE using levels = c(...) specify ordering levels ascending order (low high).example, suppose following data vector dosage level data subjects:Naturally, ordered Low < Medium < High currently ordering structure. can fix like :can see now ordering structure R understands levels compare . ordering also automatically respected later plots analysis, ’ll soon see.","code":"\ndoses <- c(\"Low\", \"High\", \"Medium\", \"Low\", \"High\")\ndoses <- factor(doses, levels = c(\"Low\", \"Medium\", \"High\"), ordered = TRUE)\ndoses[1] Low    High   Medium Low    High  \nLevels: Low < Medium < High"},{"path":"data-vectors.html","id":"coercion","chapter":"3 Data Vectors","heading":"3.10 Coercion (converting types)","text":"Sometimes, read data may need converted ’s usable. E.g. let’s say read list prices catalog get following character vector:Since R doesn’t natively understand dollar signs comma grouping, must start character vector. can check type vector using .numeric(), .logical(), .character() functions.data “cleaned-” can coerce (.e. convert) vector types corresponding .numeric(), .logical(), .character() functions. case however, data yet “cleaned-” coercion operation give error.R, ’s important remember reinvent wheel; actions already associated package/function, ’s probably better can write (’re beginner). , may tempting write parsing function using sub()/gsub() replace dollar commas coerce, ’s better option.readr another one core Tidyverse packages. ’s designed make ingesting data easy possible.One set readr functions useful parse_number() parse_logical() functions (converting string trivial can basically always done using .character() function). functions quite smart can ignore extra characters just extract relevant numerical info.also work things like percent symbols, note simply ignores symbol instead treating dividing 100.See help page parse_number() examples usage notes.","code":"\nprices_raw <- c(\"$1,000\", \"$1,500\", \"$850\", \"$2,000\")\nprices_raw[1] \"$1,000\" \"$1,500\" \"$850\"   \"$2,000\"\nis.character(prices_raw)[1] TRUE\nas.numeric(prices_raw)Warning: NAs introduced by coercion[1] NA NA NA NA\n# since readr is also a \"core\" tidyverse package,\n# you can use library(tidyverse) or library(readr)\nlibrary(readr)\nprices <- parse_number(prices_raw)\nprices[1] 1000 1500  850 2000\nis.numeric(prices)[1] TRUE\n# demonstrate parsing percentages\nparse_number(c(\"30%\", \"100%\", \"1,500%\"))[1]   30  100 1500"},{"path":"data-vectors.html","id":"date-vectors","chapter":"3 Data Vectors","heading":"3.11 Date vectors","text":"Finally, let’s talk date vectors (note talking date+time values, just dates). R, dates actually stored number, representing number days January 1st 1970, used reference date called Epoch.run examples, ’re going load lubridate package, designed make working dates super easy also part Tidyverse. However, ’s actually core package, means MUST loaded separately time wish use !Ok, let’s start demo creating date object. Let’s use today’s date (Sep 28, 2024 last compile) example. today() function handy .can see even though date object \"Date\" class, actually \"double\" type, means behind scenes, ’s secretly stored number.18 unclass() object, .e. strip away \"Date\" property, can see ’s just number 19994 underneath, can check fact Sep 28, 2024 indeed 19994 days Jan 1 1970.R conforms ISO-8601 standards, .e. dates ALWAYS show \"YYYY-MM-DD\" (even though ’re stored numerically). arguably best format dates, ’s unique format chronological order lexicographical order identical, extremely useful property.Also note despite date appearing character, character. Using identical() (compares two objects ) show false. Furthermore, .numeric() confirms date converts 19994 expected, whereas string \"2024-09-28\" converted returns NA.just warn even though may print similarly, date objects date-like strings , avoid errors unexpected behavior, make sure properly convert date data true date objects.","code":"\nlibrary(lubridate)\n# create today as an example date object\ndate <- today()\ndate[1] \"2024-09-28\"\n# looks like a date\nclass(date)[1] \"Date\"\nis.Date(date) & !is.numeric(date)[1] TRUE\n# but it's secretly a number underneath!\nunclass(date)[1] 19994\n# we can reverse this too, start with a number,\n# then change the class to \"Date\", and voila!\nx <- 19994\nclass(x) <- \"Date\"\nx[1] \"2024-09-28\"\ndate[1] \"2024-09-28\"\nis.character(date)[1] FALSE\nidentical(date, \"2024-09-28\")[1] FALSE\nc(as.numeric(date), as.numeric(\"2024-09-28\"))Warning: NAs introduced by coercion[1] 19994    NA"},{"path":"data-vectors.html","id":"parsing-dates","chapter":"3 Data Vectors","heading":"3.11.1 Parsing dates","text":"cases (specifically, dates dataset already represented standard ISO-8601 format) R automagically parse (.e. convert) dates . cases, may need manually parse . continue use lubridate, since robust user-friendly functions working dates.lubridate, parser functions mdy(), dmy(), ymd() (well rarer siblings ydm(), myd(), dym()) used parse date data proper date objects. difference functions order expect see date components, e.g. mdy() used data ordered month, day, year (common US), dmy() used date data data ordered day, month, year (generally preferred outside US). functions extremely robust automagically recognize wide range formats, course ’re vectorized! ’s examples:can see, just need tell R order expect date components handle rest! demonstrated mdy() dmy() functions since far common formats, functions behave .One last parser. Sometimes data gives dates decimal, e.g. 2024-09-28 2024.74 since ’s 272nd day year means ’s (272-1)/366*100%=74% way year.19 R also dedicated function . date_decimal() converts decimal date+time object, can round nearest date round_date(...,unit=\"day\") drop time component date() converts date+time objects pure date objects (, covering date+time objects due complexity & limited time).also reverse function decimal_date() converts date back decimal.","code":"\nmdy(c(\n  \"9/28/24, 09-28-2024, 092824, Sep 28 '24, Saturday, September 28th, 2024\"\n))[1] \"2024-09-28\" \"2024-09-28\" \"2024-09-28\" \"2024-09-28\" \"2024-09-28\"\ndmy(c(\n  \"28/9/24, 28-09-2024, 280924, 28 Sep '24, Saturday, 28th of September, 2024\"\n))[1] \"2024-09-28\" \"2024-09-28\" \"2024-09-28\" \"2024-09-28\" \"2024-09-28\"\n# generate a vector of elapsed 21st century dates\n# in decimal format for demo purposes\n# (here, runif uniformly samples 4 numbers from 2000 to 2024.74)\ndates2 <- runif(4, 2000, 2024.74)\ndates2[1] 2006.569 2009.207 2014.173 2022.469\n# convert decimals to dates\ndates2 <- date(round_date(date_decimal(dates2), unit = \"day\"))\ndates2[1] \"2006-07-28\" \"2009-03-17\" \"2014-03-05\" \"2022-06-21\"\ndecimal_date(dates2)[1] 2006.570 2009.205 2014.173 2022.468"},{"path":"data-vectors.html","id":"aside-rs-calendar","chapter":"3 Data Vectors","heading":"3.11.2 Aside: R’s calendar","text":"Quick aside. R extremely robust calendar, don’t need worry “babysitting” R. Notably, R knows exactly years leap aren’t.Fun fact: R’s calendar rigorous Excel’s calendar, since correctly treats 1900 non-leap, unlike Excel. course probably immaterial 21st century, just think ’s amusing bit trivia.","code":"\n# the most recent leap year is 2024, since it's divisible by 4\nmdy(\"Feb 29, 2024\")[1] \"2024-02-29\"\n# however, years like 1900 or 2100 are not leap,\n# since they're also divisible by 100\nmdy(c(\"Feb 29, 1900\", \"Feb 29, 2100\"))Warning: 2 failed to parse.[1] NA NA\n# but 2000 is leap, since it's also divisible by 400\nmdy(\"Feb 29, 2000\")[1] \"2000-02-29\"\n# you can also use the leap_year() function instead\n# is the year that a given date is in leap?\nleap_year(date)[1] TRUE\n# which of these given years are leap?\nleap_year(c(1900, 2000, 2024, 2100))[1] FALSE  TRUE  TRUE FALSE"},{"path":"data-vectors.html","id":"getset-components","chapter":"3 Data Vectors","heading":"3.11.3 Get/set components","text":"Lubridate provides many get/set functions (often called getters setters) getting setting different components (.e. properties) associated date. common ones include year(), month(), day(), wday() (day week), quarter().Let’s continue using generated dates2 object , except add today 2024-09-28 vector first element.functions (makes sense) like month() wday() additional arguments like label abbr control output format option output names instead numbers. , recommend briefly check help page every new function learn additional options.system different language, may see code output non-English names months days week. R uses system’s locale determine output values. extremely easy fix; simply run line code console, close restart Rstudio changes permanently take effect.work? adds line invisible(Sys.setlocale(\"LC_TIME\",\"C\")) \"~/.Rprofile\" file, run every time R starts . added line invisibly sets \"LC_TIME\" locale variable \"C\", tells lubridate use English outputs.first line output actual output names. list “levels” second line just shows set possible values outputted. return object another example “ordered factor”. purposes can mostly treated similar character/string vector. (want string operations output, make sure convert fully character first .character()!)getters extremely useful data cleaning well data visualization, since can much pleasant , example, see monthly breakdown Jan, Feb, …, Dec instead 1, 2, …, 12.getters can also used “setters”, .e. used set components. example:works getters , feel free experiment . also several getter/setter functions qday() day quarter, week() week number, semester() 1st 2nd semester year.","code":"\n# add in today, then print (to remind us what it contains)\ndates2 <- c(date, dates2)\ndates2[1] \"2024-09-28\" \"2006-07-28\" \"2009-03-17\" \"2014-03-05\" \"2022-06-21\"\n# extract the year, month, day, wday, quarter\nyear(dates2)[1] 2024 2006 2009 2014 2022\nmonth(dates2)[1] 9 7 3 3 6\nday(dates2)[1] 28 28 17  5 21\n# wday starts counting from Sunday, i.e. 1=Sunday, 2=Monday, etc.\nwday(dates2)[1] 7 6 3 4 3\nquarter(dates2)[1] 3 3 1 1 2\n# output month as abbreviated names instead (abbr = TRUE by default)\nmonth(dates2, label = TRUE)[1] Sep Jul Mar Mar Jun\n12 Levels: Jan < Feb < Mar < Apr < May < Jun < Jul < Aug < Sep < Oct < ... < Dec\n# output day of week as full, unabridged names\nwday(dates2, label = TRUE, abbr = FALSE)[1] Saturday  Friday    Tuesday   Wednesday Tuesday  \n7 Levels: Sunday < Monday < Tuesday < Wednesday < Thursday < ... < Saturday\nwrite('\\ninvisible(Sys.setlocale(\"LC_TIME\",\"C\"))\\n',\"~/.Rprofile\",1,T)\n# make a copy to use here, since this destroys the original vector\nnew_dates2 <- dates2\n# change year of all dates to 2000\nyear(new_dates2) <- 2000\nnew_dates2[1] \"2000-09-28\" \"2000-07-28\" \"2000-03-17\" \"2000-03-05\" \"2000-06-21\"\n# of course this is also vectorized!\nyear(new_dates2) <- 2000:2004\nnew_dates2[1] \"2000-09-28\" \"2001-07-28\" \"2002-03-17\" \"2003-03-05\" \"2004-06-21\""},{"path":"data-vectors.html","id":"date-math","chapter":"3 Data Vectors","heading":"3.11.4 Date math","text":"Since dates represented internally number days since reference point, math dates turns extremely easy. can add/subtract days, make sequences, run logical comparisons, even use statistical summary functions.","code":"\n# get tomorrow by adding +1 to today\ndate + 1[1] \"2024-09-29\"\n# what date was 1000 days ago?\ndate - 1000[1] \"2022-01-02\"\n# how many days has it been since y2k?\n# note that subtracting dates gives a \"difftime\" class object\n# you can convert this to a number using the familiar as.numeric()\nas.numeric(date - mdy(\"1/1/00\"))[1] 9037\n# make a sequence of dates from today to the end of the month\nseq(date, mdy(\"9/30/24\"), by = 1)[1] \"2024-09-28\" \"2024-09-29\" \"2024-09-30\"\n# make a sequence of every Saturday from today to the end of the year\nseq(date, mdy(\"12/31/24\"), by = 7) [1] \"2024-09-28\" \"2024-10-05\" \"2024-10-12\" \"2024-10-19\" \"2024-10-26\" \"2024-11-02\"\n [7] \"2024-11-09\" \"2024-11-16\" \"2024-11-23\" \"2024-11-30\" \"2024-12-07\" \"2024-12-14\"\n[13] \"2024-12-21\" \"2024-12-28\"\n# has independence day already happened this year?\nmdy(\"7/4/24\") <= date[1] TRUE\n# what is the earliest date in the dates2 vector?\nmin(dates2)[1] \"2006-07-28\"\n# organize dates2 in chronological order\nsort(dates2)[1] \"2006-07-28\" \"2009-03-17\" \"2014-03-05\" \"2022-06-21\" \"2024-09-28\"\n# is today in dates2?\ndate %in% dates2[1] TRUE\n# some statistical functions can also be run on dates\n# e.g. we can find the mean and median date of dates2\nmean(dates2)[1] \"2015-06-07\"\nmedian(dates2)[1] \"2014-03-05\"\n# we can even find the standard deviation of dates,\n# though this does NOT return a date itself but rather a number of days\nsd(dates2)[1] 2916.58"},{"path":"data-vectors.html","id":"printing-dates","chapter":"3 Data Vectors","heading":"3.11.5 Printing dates","text":"final note, let’s briefly discuss printing dates. can use format() print dates pretty way. Different ways printing component represented using %... codes. Examples:full list percent codes can found help page strptime(), base R function parsing date/time objects.","code":"\n# print today as mm/dd/yy which is common in the US\nformat(date, \"%m/%d/%y\")[1] \"09/28/24\"\n# another way, slightly more written out\nformat(date, \"%b %d, %Y\")[1] \"Sep 28, 2024\"\n# fully written out, including weekday\nformat(date, \"%A, %B %e, %Y\")[1] \"Saturday, September 28, 2024\""},{"path":"data-frames.html","id":"data-frames","chapter":"4 Data Frames","heading":"4 Data Frames","text":"Moving vectors, next important data structure R data frame. Think data frame similar matrix, (ideally) column vector single type representing variable attribute, row observation sample.’s actually really helpful think data frame collection parallel vectors length, column type. E.g. suppose survey sample college students; maybe ’d sex column character type, GPA column numeric type, birthday column date type, column declared major logical type.","code":""},{"path":"data-frames.html","id":"creating-dfs","chapter":"4 Data Frames","heading":"4.1 Creating data frames","text":"2 common ways creating new data frame manually: data.frame() base R, tibble() tibble package, another core Tidyverse packages. extremely similar, recommend tibble() due nice extra features better printing, referencing columns creation, stricter subsetting rules. Example:Note following:syntax inside tibble() always column_name = vector_of_data, next_column_name = next_vector_of_data, ... vector must length.vectors pre-created; can create go along.can reference another column immediately creating inside function, e.g. date_of_birth created, immediately used next line help create age (way age approximately computed number days since birth divided 365.24, approximate number days year, rounded following convention).Data frames can, almost always contain many columns different type. However, usual single column—still vector!—can contain SINGLE type data inside , e.g. column numbers characters simultaneously.Printing df either just writing new line, print() function (thing) show first rows, also info like\ncolumn (row) names,\nnumber rows columns (displayed rows x cols),\ntype column (dbl, chr, lgl, date, others beyond scope)\ncolumn (row) names,number rows columns (displayed rows x cols),type column (dbl, chr, lgl, date, others beyond scope)can create column constants recycling single value\nNote: design, tibble() recycle length-1 vectors. help avoid errors improve syntax legibility.\nNote: design, tibble() recycle length-1 vectors. help avoid errors improve syntax legibility.","code":"\n# import the tibble and lubridate libraries\n# again, tibble is core tidyverse, so library(tidyverse) will also work\n# but lubridate is not core so needs to be imported manually\nlibrary(tibble)\nlibrary(lubridate)\n# manually create an example data frame\ndf <- tibble(\n  name = c(\"Alice\", \"Bob\", \"Charlie\"),\n  sex = c(\"F\", \"M\", \"M\"),\n  date_of_birth = mdy(c(\"9/28/03\", \"7/4/99\", \"10/31/06\")),\n  age = floor(as.numeric(today() - birthday)/365.24),\n  declared_major = c(TRUE, TRUE, FALSE),\n  school = \"UW-Madison\"\n)\n# print df\ndf# A tibble: 3 × 6\n  name    sex   date_of_birth   age declared_major school    \n  <chr>   <chr> <date>        <dbl> <lgl>          <chr>     \n1 Alice   F     2003-09-28       21 TRUE           UW-Madison\n2 Bob     M     1999-07-04       25 TRUE           UW-Madison\n3 Charlie M     2006-10-31       17 FALSE          UW-Madison"},{"path":"data-frames.html","id":"importing-data-frames","chapter":"4 Data Frames","heading":"4.2 Importing data frames","text":"course, practice don’t usually create data frames manually like , rather import data files. always, base R ways , continue recommend Tidyverse syntax due better features design.million different data formats, cover 3 common basic ones: CSV, comma separated value files; TSV, tab separated files; XLS(X), Excel (similar spreadsheet software) data files. Notably, cover databases (like SQL derivatives) non-rectangular data formats (like JSON XML), due limitations time/space.","code":""},{"path":"data-frames.html","id":"aside-file-formats-extensions","chapter":"4 Data Frames","heading":"4.2.1 Aside: file formats & extensions","text":"First, small aside. File formats (types) file extensions commonly conflated, distinction important.File format refers internal structure contents. Common formats include simple text (can encoded using variety different encodings ASCII Unicode UTF-8 common), complex documents like PDFs DOCs, images videos, compressed archives, binary executables, specialized (often proprietary) formats.File extensions, contrast just characters added end name file convenience hint computers (users) might expect find inside contents file. bearing actual file format contained inside.Many extensions may fact file format, e.g. .Rmd, .html, .csv, .txt, many examples extensions actually just simple text files (encoding), can opened text editor. Conversely, formats can stored variety different extensions, e.g. MPEG-4 versatile multimedia “container” format may stored .mp4 also .m4a, .m4b, .m4p, .m4r, .m4v depending context., extension exists “hint” contents file. can store text file .mp4 extension want. computer suggest open video player fail, can force open text editor work just fine. Remember file names file contents totally separate things need bearing .important takeaways :data “formats” (like CSV, TSV, JSON, XML) really just simple text files (similar .txt files often created text editor programs). class, say “CSV” generally refer specific way text formatted (.e. values separated commas) inside file, just extension.data formats (like XLS(X) databases) simple text files specialized formats, often need different treatment.Just changing extension file change contents. E.g. changing .csv extension .zip create valid zip file, painting stripes horse turns zebra.Today, many systems default hide file extensions, e.g. file ’s actually named data.csv may appear user just named data. can cause problems, user isn’t aware tries rename file data.csv may actually become data.csv.csv. common cause knit-fail see.highly recommended force device always show extensions can help avoid problems. Instructions Windows Macs.","code":""},{"path":"data-frames.html","id":"importing-functions","chapter":"4 Data Frames","heading":"4.2.2 Importing functions","text":"text-format data files, turn readr suite functions importing , focus :read_csv() used read CSV files columns data separated commas,read_tsv() used read files columns data separated tabs,read_delim() general form read_... functions can used read files type separator.One additional non-text format covered course: XLS(X) spreadsheet data, commonly generated Excel similar spreadsheet software. , different function Tidyverse’s non-core readxl package:read_excel() can used read XLS XLSX spreadsheet dataNote underscores function names. E.g. read_csv() readr read.csv() base R function. similar, readr’s read_csv() minor improvements speed consistency recommended class.Also note readr (tidyverse) loaded, attempting TAB autocomplete read_csv() function instead give read.csv() , remember set working directory load necessary libraries whenever (re)opening Rstudio starting/resuming work.","code":""},{"path":"data-frames.html","id":"eruptions-example","chapter":"4 Data Frames","heading":"4.2.3 Example: US Eruptions","text":"demonstrate basic functionality different functions, ’ve prepared exported dataset 21st century volcanic eruptions (recorded start end date) United States Smithsonian formats listed can practice reading initial format:eruptions_recent.csveruptions_recent.tsveruptions_recent.delimeruptions_recent.xlsx","code":""},{"path":"data-frames.html","id":"csv-file","chapter":"4 Data Frames","heading":"4.2.4 CSV file","text":"example, ’s first lines eruptions_recent.csv CSV file (eruption, volcano name, start stop dates, duration days, certainty confirmed, VEI volcano explosivity index).link dataset, can directly pass read_csv() automagically download file system’s temp directory read . Make sure save data frame sensible name. ’s also usually good idea print first lines check result see everything worked without error.Several things note :diagnostic messages printed reading, well warnings/errors encounters anything unusual (errors/warnings observed ).reading , R try intelligently guess data types column ’re standard format. can see since columns CSV already neat written standard format (e.g. dates YYYY-MM-DD, numbers logicals written common syntax, missing values written NA), everything automagically converted: name left character, start stop parsed dates, duration vei parsed numeric, confirmed became logical.\ncolumns written standard format, may work well () may need data cleaning , touch later.\ncolumns written standard format, may work well () may need data cleaning , touch later.can run just data frame name print first rows. equivalent running print(eruptions_recent).\nPrinting often useful way double check errors. default, first 10 lines printed save space.\nPrinting often useful way double check errors. default, first 10 lines printed save space.look Environment tab now, see loaded data frame.\n, can click arrow see list columns, well names, types, first values.\ncan also click object name open new tab full spreadsheet-like view entire data frame, can inspect data frame, even search values sort columns (note: sorting just preview affect underlying object).\n, can click arrow see list columns, well names, types, first values.can also click object name open new tab full spreadsheet-like view entire data frame, can inspect data frame, even search values sort columns (note: sorting just preview affect underlying object).","code":"volcano,start,stop,duration,confirmed,vei\nKīlauea,2024-06-03,2024-06-03,0,TRUE,NA\nAtka Volcanic Complex,2024-03-27,2024-03-27,0,TRUE,NA\nAhyi,2024-01-01,2024-03-27,86,TRUE,NA\nKanaga,2023-12-18,2023-12-18,0,TRUE,1\nRuby,2023-09-14,2023-09-15,1,TRUE,1\n# import readr\nlibrary(readr)\n# read in CSV file from link\neruptions_recent <- read_csv(\n  \"https://bwu62.github.io/stat240-revamp/data/eruptions_recent.csv\"\n)Rows: 73 Columns: 6\n── Column specification ──────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): volcano\ndbl  (2): duration, vei\nlgl  (1): confirmed\ndate (2): start, stop\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n# print first few lines of result to check\neruptions_recent# A tibble: 73 × 6\n   volcano               start      stop       duration confirmed   vei\n   <chr>                 <date>     <date>        <dbl> <lgl>     <dbl>\n 1 Kīlauea               2024-06-03 2024-06-03        0 TRUE         NA\n 2 Atka Volcanic Complex 2024-03-27 2024-03-27        0 TRUE         NA\n 3 Ahyi                  2024-01-01 2024-03-27       86 TRUE         NA\n 4 Kanaga                2023-12-18 2023-12-18        0 TRUE          1\n 5 Ruby                  2023-09-14 2023-09-15        1 TRUE          1\n 6 Shishaldin            2023-07-11 2023-11-03      115 TRUE          3\n 7 Mauna Loa             2022-11-27 2022-12-10       13 TRUE          0\n 8 Ahyi                  2022-11-18 2023-06-11      205 TRUE          1\n 9 Kīlauea               2021-09-29 2023-09-16      717 TRUE          0\n10 Pavlof                2021-08-05 2022-12-07      489 TRUE          2\n# ℹ 63 more rows"},{"path":"data-frames.html","id":"tsv-file","chapter":"4 Data Frames","heading":"4.2.5 TSV file","text":"functions similar. ’s first lines TSV-version dataset, eruptions_recent.tsv (way notes built doesn’t display tabs properly, view TSV file directly, can see ).read read_tsv() function. time, save space, ’ve disabled diagnostic messages setting show_col_types = FALSE reduced final print checking 5 lines. Otherwise, can see exact result.","code":"volcano start   stop    duration    confirmed   vei\nKīlauea 2024-06-03  2024-06-03  0   TRUE    NA\nAtka Volcanic Complex   2024-03-27  2024-03-27  0   TRUE    NA\nAhyi    2024-01-01  2024-03-27  86  TRUE    NA\nKanaga  2023-12-18  2023-12-18  0   TRUE    1\nRuby    2023-09-14  2023-09-15  1   TRUE    1\n# read in TSV file from link\neruptions_recent <- read_tsv(\n  \"https://bwu62.github.io/stat240-revamp/data/eruptions_recent.tsv\",\n  show_col_types = FALSE\n)\n# print first 5 lines instead of 10 to still check, but save space\nprint(eruptions_recent, n = 5)# A tibble: 73 × 6\n  volcano               start      stop       duration confirmed   vei\n  <chr>                 <date>     <date>        <dbl> <lgl>     <dbl>\n1 Kīlauea               2024-06-03 2024-06-03        0 TRUE         NA\n2 Atka Volcanic Complex 2024-03-27 2024-03-27        0 TRUE         NA\n3 Ahyi                  2024-01-01 2024-03-27       86 TRUE         NA\n4 Kanaga                2023-12-18 2023-12-18        0 TRUE          1\n5 Ruby                  2023-09-14 2023-09-15        1 TRUE          1\n# ℹ 68 more rows"},{"path":"data-frames.html","id":"arbitrary-delimited-file","chapter":"4 Data Frames","heading":"4.2.6 Arbitrary delimited file","text":"data file columns delimited (.e. separated) characters, can use read_delim() function, generalization previous two read . Just set delim argument whatever delimiter , ’re good go. ’s first lines eruptions_recent.delim columns separated vertical bar | characters, followed line code import check result.","code":"volcano|start|stop|duration|confirmed|vei\nKīlauea|2024-06-03|2024-06-03|0|TRUE|\nAtka Volcanic Complex|2024-03-27|2024-03-27|0|TRUE|\nAhyi|2024-01-01|2024-03-27|86|TRUE|\nKanaga|2023-12-18|2023-12-18|0|TRUE|1\nRuby|2023-09-14|2023-09-15|1|TRUE|1\n# read in | delimited file from link\neruptions_recent <- read_delim(\n  \"https://bwu62.github.io/stat240-revamp/data/eruptions_recent.delim\",\n  delim = \"|\",\n  show_col_types = FALSE\n)\n# print first 5 lines\nprint(eruptions_recent, n = 5)# A tibble: 73 × 6\n  volcano               start      stop       duration confirmed   vei\n  <chr>                 <date>     <date>        <dbl> <lgl>     <dbl>\n1 Kīlauea               2024-06-03 2024-06-03        0 TRUE         NA\n2 Atka Volcanic Complex 2024-03-27 2024-03-27        0 TRUE         NA\n3 Ahyi                  2024-01-01 2024-03-27       86 TRUE         NA\n4 Kanaga                2023-12-18 2023-12-18        0 TRUE          1\n5 Ruby                  2023-09-14 2023-09-15        1 TRUE          1\n# ℹ 68 more rows"},{"path":"data-frames.html","id":"xlsx-file","chapter":"4 Data Frames","heading":"4.2.7 XLS(X) file","text":"Data also commonly encountered XLS/XLSX spreadsheet file, can read readxl’s read_excel() function. eruptions_recent.xlsx file dataset exported XLSX. Since XLSX text format, can’t embedded , ’s first rows look like opened Excel:Unfortunately, readxl support URLs data must downloaded loading.Oops, looks like start/stop read datetime instead date. ’ll learn later fix , now ’re moving .","code":"\n# load readxl, which is NOT core tidyverse, so must be imported explicitly\nlibrary(readxl)\n# I already have the file downloaded to data/\n# inside my current working directory\ndir.exists(\"data/\")[1] TRUE\nfile.exists(\"data/eruptions_recent.xlsx\")[1] TRUE\neruptions_recent <- read_xlsx(\"data/eruptions_recent.xlsx\")\n# print first 5 lines\nprint(eruptions_recent, n = 5)# A tibble: 73 × 6\n  volcano            start               stop                duration confirmed   vei\n  <chr>              <dttm>              <dttm>                 <dbl> <chr>     <dbl>\n1 Kīlauea            2024-06-03 00:00:00 2024-06-03 00:00:00        0 TRUE         NA\n2 Atka Volcanic Com… 2024-03-27 00:00:00 2024-03-27 00:00:00        0 TRUE         NA\n3 Ahyi               2024-01-01 00:00:00 2024-03-27 00:00:00       86 TRUE         NA\n4 Kanaga             2023-12-18 00:00:00 2023-12-18 00:00:00        0 TRUE          1\n5 Ruby               2023-09-14 00:00:00 2023-09-15 00:00:00        1 TRUE          1\n# ℹ 68 more rows"},{"path":"data-frames.html","id":"extra-arguments","chapter":"4 Data Frames","heading":"4.2.8 Extra arguments","text":"files prepared easily imported without needing additional arguments, general ’s common need set arguments functions get import properly. BRIEF selection useful arguments available, loosely ordered order importance.arguments can used several ways, e.g. may accept either TRUE/FALSE vector numbers strings, etc. may different behavior depending input. highlight common usages , always see help page details!read_csv(), read_tsv(), read_delim() functions readr share single help page, many arguments common (, see help page). useful additional arguments include:col_names controls handling column names.\ndefault value TRUE, first row file used column names,\nset FALSE, placeholder names used, first line file treated data,\nset character vector, vector used column names, first row file treated data.\ndefault value TRUE, first row file used column names,set FALSE, placeholder names used, first line file treated data,set character vector, vector used column names, first row file treated data.col_types controls handling column types.\nbest way set compact, single-word string letter represents order left right column type use:\nd = double (.e. “normal” numeric value)\nn = number, special readr format parses “human readable” non-standard numbers “$1,000” “150%” (closely related parse_number() function section 3.10)\nl = logical, .e. TRUE/FALSE\nD = date, works dates standard format like \"YYYY-MM-DD\"; parse non-standard formats\nc = character, text data well data non-standard format, parsed later\n_ - skip column\n\n\nexample, suppose data frame order left right numeric column, date column, character column, column want skip, non-standard column needs parsed later; set col_types = \"dDc_c\" specify .best way set compact, single-word string letter represents order left right column type use:\nd = double (.e. “normal” numeric value)\nn = number, special readr format parses “human readable” non-standard numbers “$1,000” “150%” (closely related parse_number() function section 3.10)\nl = logical, .e. TRUE/FALSE\nD = date, works dates standard format like \"YYYY-MM-DD\"; parse non-standard formats\nc = character, text data well data non-standard format, parsed later\n_ - skip column\nd = double (.e. “normal” numeric value)n = number, special readr format parses “human readable” non-standard numbers “$1,000” “150%” (closely related parse_number() function section 3.10)l = logical, .e. TRUE/FALSED = date, works dates standard format like \"YYYY-MM-DD\"; parse non-standard formatsc = character, text data well data non-standard format, parsed later_ - skip columnna sets vector values treated missing, default c(\"\", \"NA\"), .e. empty strings \"NA\" treated missing.comment data files comment lines, usually (always) beginning hashtag # character. lines can ignored setting comment = \"#\" example.skip let’s skip set number lines beginning file.n_max allows setting maximum number lines read file.id useful filename contains important information (common importing data split many files). Setting id = TRUE saves name id column.show_col_types can set FALSE silence diagnostic messages shown importing.read_excel() function readxl also useful extra arguments. , similar slightly different, unique (, see help page). Brief selection important arguments:sheet range unique read_excel() control sheet (.e. tabs bottom) range (.e. rectangular region spreadsheet) read data .\nsheet (defaults first sheet) can either name, number indicating position, even included range specification.\nrange (defaults entire range) can specified variety different ways, commonly might something like \"A2:D6\" includes cells columns -D rows 2-6. See page examples syntax.\nsheet (defaults first sheet) can either name, number indicating position, even included range specification.range (defaults entire range) can specified variety different ways, commonly might something like \"A2:D6\" includes cells columns -D rows 2-6. See page examples syntax.col_names behaves exactly : default TRUE uses first row names, FALSE uses generic placeholder names, can also directly set names character vectorcol_types similar, instead compact string notation, must use character vector specify column type, “numeric”, “logical”, “date”, “text”, “skip” possible valuesna: also behaves accepts vector values represent missing data; difference defaults \"\"skip behaves , let’s skip lines beginning.n_max also behaves sets maximum number lines read.","code":""},{"path":"data-frames.html","id":"paths-file-management","chapter":"4 Data Frames","heading":"4.2.9 Paths & file management","text":"also need briefly discuss paths revisit file management. Previously, download data file import local storage. many first time R users, nontrivial task.R, import downloaded file, must provide valid file path, just reference file’s location system. Paths always relative current working directory. remembered set working directory correctly, Rstudio session runs place current Rmd file (knits ), path also correct, everything work time, errors.data file directory Rmd file, can reference just using name. example, suppose ’re working hw01.Rmd directories look like :Since hw01_data.csv directory hw01.Rmd, can import simply read_csv(\"hw01_data.csv\"), assuming working directory set correctly. However, data file subdirectory called data/, .e. like :, import need write read_csv(\"data/hw01_data.csv\") R know first go data/ directory searching hw01_data.csv load. instead, data file one level , like :, import need write read_csv(\"../hw01_data.csv\") ../ means go directory level (.e. exit current folder) searching hw01_data.csv load.’s important note single correct way manage files, long organized can easily find need. However, strong preference, recommend follow file organization structure introduced section 1.3, .e. setup directories like :, long always following, things always just work:Always put homework/discussion Rmd files homework/hw##/ discussion/ds##/ ## assignment number.Always put data data/ directory, exactly 2 levels hw## ds## directories.Always reference data files like \"../../data/data_file.csv\" tell R go 2 levels current directory, take main STAT240/ directory, descend data/ search data_file.csv.’re trouble finding importing file, additional tips may help:R, can also TAB autocomplete paths. Make sure working directory set, start path \"\", place cursor quotes, hit TAB. see popup menu showing files current directory. , either select subdirectory TAB , type ../ go directory level, repeat steps necessary find file, hit ENTER confirm selection.’re desperate, can also use graphical readr import tool found Environment tab, opens dialog box can browse file, set arguments convenient dropdown menus, see preview data look like settings, best : corner can see code generated can can copy Rmd file. always, make sure working directory set beforehand!Paths R always use forward / slashes, NEVER back \\ slashes, even though back slashes used Windows file systems. just R’s syntax.","code":"..\n└── STAT240/\n    └── homework/\n        └── hw01/\n            ├── hw01.Rmd\n            └── hw01_data.csv..\n└── STAT240/\n    └── homework/\n        └── hw01/\n            ├── hw01.Rmd\n            └── data/\n                 └── hw01_data.csv└── STAT240/\n    └── homework/\n        ├── hw01_data.csv\n        └── hw01/\n            └── hw01.Rmd..\n└── STAT240/\n    │\n    ├── data/\n    │   ├── data_A.csv\n    │   ├── data_B.tsv\n    │   ├── data_C.xlsx\n    │   :    :\n    │\n    ├── discussion/\n    │   │\n    │   ├── ds01/\n    │   │   └── ds01.Rmd\n    │   │\n    │   ├── ds02/\n    │   :   └── ds02.Rmd\n    │\n    ├── homework/\n    │   │\n    │   ├── hw01/\n    │   │   └── hw01.Rmd\n    │   │\n    │   ├── hw02/\n    │   :   └── hw02.Rmd\n    │\n    ├── notes/\n    ├── project/\n    ├── other/\n    :"},{"path":"data-frames.html","id":"working-with-data-frames","chapter":"4 Data Frames","heading":"4.3 Working with data frames","text":"using data frames extensively throughout class. Let’s start learning basic manipulations . First, ’m going reload eruptions_recent dataset using CSV file, correct start/stop columns.","code":"\n# set R to print fewer rows by default, to save space in demos below\noptions(pillar.print_min = 5)\n\n# reload dataset\neruptions_recent <- read_csv(\n  \"https://bwu62.github.io/stat240-revamp/data/eruptions_recent.csv\",\n  show_col_types = FALSE\n)\n# print first few rows\neruptions_recent# A tibble: 73 × 6\n  volcano               start      stop       duration confirmed   vei\n  <chr>                 <date>     <date>        <dbl> <lgl>     <dbl>\n1 Kīlauea               2024-06-03 2024-06-03        0 TRUE         NA\n2 Atka Volcanic Complex 2024-03-27 2024-03-27        0 TRUE         NA\n3 Ahyi                  2024-01-01 2024-03-27       86 TRUE         NA\n4 Kanaga                2023-12-18 2023-12-18        0 TRUE          1\n5 Ruby                  2023-09-14 2023-09-15        1 TRUE          1\n# ℹ 68 more rows"},{"path":"data-frames.html","id":"basic-df","chapter":"4 Data Frames","heading":"4.3.1 Basic operations","text":"basic operations working data frames: nrow(), ncol(), dim() can show number rows /columns; summary() can show quick summary column; names()/colnames() can get set column names; rownames() can get set row names.","code":"\n# get number of rows and columns\nnrow(eruptions_recent)[1] 73\nncol(eruptions_recent)[1] 6\n# get both together using dim()\ndim(eruptions_recent)[1] 73  6\n# show different summary of each column, depending on the column type\nsummary(eruptions_recent)   volcano              start                 stop               duration     \n Length:73          Min.   :2001-02-02   Min.   :2001-04-15   Min.   :   0.0  \n Class :character   1st Qu.:2006-11-25   1st Qu.:2007-03-03   1st Qu.:   6.0  \n Mode  :character   Median :2011-07-19   Median :2012-02-18   Median :  71.0  \n                    Mean   :2012-11-07   Mean   :2013-05-18   Mean   : 192.1  \n                    3rd Qu.:2019-07-23   3rd Qu.:2019-12-07   3rd Qu.: 195.0  \n                    Max.   :2024-06-03   Max.   :2024-07-23   Max.   :1491.0  \n                                                                              \n confirmed            vei       \n Mode :logical   Min.   :0.000  \n FALSE:4         1st Qu.:1.000  \n TRUE :69        Median :2.000  \n                 Mean   :1.864  \n                 3rd Qu.:3.000  \n                 Max.   :4.000  \n                 NA's   :7      \n# show names of the variable columns\n# note names() and colnames() are completely identical for data frames\nnames(eruptions_recent)[1] \"volcano\"   \"start\"     \"stop\"      \"duration\"  \"confirmed\" \"vei\"      \n# you can also set individual, specific, or even all names\nnames(eruptions_recent)[2] <- \"START\"\nnames(eruptions_recent)[c(1, 4:6)] <- c(\"VOLCANO\", \"DURATION\", \"CONFIRMED\", \"VEI\")\nnames(eruptions_recent)[1] \"VOLCANO\"   \"START\"     \"stop\"      \"DURATION\"  \"CONFIRMED\" \"VEI\"      \n# let's reset the names back to their original values\nnames(eruptions_recent) <- c(\n  \"volcano\", \"start\", \"stop\", \"duration\", \"confirmed\", \"vei\"\n)\n# data frames may also have row names, though most don't\n# if there are no row names, they just show as numbers\n# (this is not generally a commonly used feature)\nrownames(eruptions_recent) [1] \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"7\"  \"8\"  \"9\"  \"10\" \"11\" \"12\" \"13\" \"14\" \"15\" \"16\"\n[17] \"17\" \"18\" \"19\" \"20\" \"21\" \"22\" \"23\" \"24\" \"25\" \"26\" \"27\" \"28\" \"29\" \"30\" \"31\" \"32\"\n[33] \"33\" \"34\" \"35\" \"36\" \"37\" \"38\" \"39\" \"40\" \"41\" \"42\" \"43\" \"44\" \"45\" \"46\" \"47\" \"48\"\n[49] \"49\" \"50\" \"51\" \"52\" \"53\" \"54\" \"55\" \"56\" \"57\" \"58\" \"59\" \"60\" \"61\" \"62\" \"63\" \"64\"\n[65] \"65\" \"66\" \"67\" \"68\" \"69\" \"70\" \"71\" \"72\" \"73\""},{"path":"data-frames.html","id":"subsetting-data-frames","chapter":"4 Data Frames","heading":"4.3.2 Subsetting data frames","text":"can extract manipulate subsets data frame along either dimension. commonly, may want use $ either pull single column vector, modify existing column -place, even create new column.can also use [] [[]] subset columns name position, difference [] returns data frame [[]] returns vector directly.[] operator additional usage [rows,cols] rows, cols can vectors specifying subsets name position. Leaving one empty means return .commonly used data science split dataset. example, suppose wanted randomly partition data 80% training 20% testing set. can first use sample(n,x) randomly select x rows n, use positive negative row subsetting syntax get partitions:ever need recombine , just use rbind() bind rows together multiple data frames, long exact columns (name type).","code":"\n# extract the vei column\neruptions_recent$duration [1]    0    0   86    0    1  115   13  205  717  489   39 1155   36  822  154    0\n[17]  195   30  286   39    6   53  110   62  253 1005  125    3    6   23  519  121\n[33]   44 1021    0    0 1491  131    1    3    2  100   71    0  108   19    2   38\n[49]    8    0  256   29  422    4   98    0   98  188  264  139   58  259   71   41\n[65] 1213  509  150  202   63  180    1    1   72\n# change the confirmed column to 1s and 0s in-place\neruptions_recent$confirmed <- as.numeric(eruptions_recent$confirmed)\neruptions_recent# A tibble: 73 × 6\n  volcano               start      stop       duration confirmed   vei\n  <chr>                 <date>     <date>        <dbl>     <dbl> <dbl>\n1 Kīlauea               2024-06-03 2024-06-03        0         1    NA\n2 Atka Volcanic Complex 2024-03-27 2024-03-27        0         1    NA\n3 Ahyi                  2024-01-01 2024-03-27       86         1    NA\n4 Kanaga                2023-12-18 2023-12-18        0         1     1\n5 Ruby                  2023-09-14 2023-09-15        1         1     1\n# ℹ 68 more rows\n# add a new column giving just the year the eruption started in\neruptions_recent$start_year <- year(eruptions_recent$start)\neruptions_recent# A tibble: 73 × 7\n  volcano               start      stop       duration confirmed   vei start_year\n  <chr>                 <date>     <date>        <dbl>     <dbl> <dbl>      <dbl>\n1 Kīlauea               2024-06-03 2024-06-03        0         1    NA       2024\n2 Atka Volcanic Complex 2024-03-27 2024-03-27        0         1    NA       2024\n3 Ahyi                  2024-01-01 2024-03-27       86         1    NA       2024\n4 Kanaga                2023-12-18 2023-12-18        0         1     1       2023\n5 Ruby                  2023-09-14 2023-09-15        1         1     1       2023\n# ℹ 68 more rows\n# extract the vei column, keeping the result as a data frame\neruptions_recent[\"vei\"]# A tibble: 73 × 1\n    vei\n  <dbl>\n1    NA\n2    NA\n3    NA\n4     1\n5     1\n# ℹ 68 more rows\n# extract the same column but by position and directly as a vector\neruptions_recent[[6]] [1] NA NA NA  1  1  3  0  1  0  2  2  2  1  2  0  3  1 NA  3  1  1  1  1  1  3  2  3\n[28]  3  3  2  1  3  3  0  2  2  2  2 NA  2  3  1  2  2  3  2  4  4  1 NA  2  2  2  1\n[55]  1  2  2  1  3  3  1  2  1  2  2  3  2  2  3  1 NA  0  3\n# extract just the first 5 start/stop times\neruptions_recent[1:5, c(\"start\", \"stop\")]# A tibble: 5 × 2\n  start      stop      \n  <date>     <date>    \n1 2024-06-03 2024-06-03\n2 2024-03-27 2024-03-27\n3 2024-01-01 2024-03-27\n4 2023-12-18 2023-12-18\n5 2023-09-14 2023-09-15\n# extract the entire 10th row\neruptions_recent[10, ]# A tibble: 1 × 7\n  volcano start      stop       duration confirmed   vei start_year\n  <chr>   <date>     <date>        <dbl>     <dbl> <dbl>      <dbl>\n1 Pavlof  2021-08-05 2022-12-07      489         1     2       2021\n# you can also use negative indices to remove specific items\n# e.g. this removes rows 1-10 and also removes the 7th column (start_year)\neruptions_recent[-(1:10), -7]# A tibble: 63 × 6\n  volcano       start      stop       duration confirmed   vei\n  <chr>         <date>     <date>        <dbl>     <dbl> <dbl>\n1 Pagan         2021-07-29 2021-09-06       39         1     2\n2 Great Sitkin  2021-05-25 2024-07-23     1155         1     2\n3 Veniaminof    2021-02-28 2021-04-05       36         1     1\n4 Semisopochnoi 2021-02-02 2023-05-05      822         1     2\n5 Kīlauea       2020-12-20 2021-05-23      154         1     0\n# ℹ 58 more rows\n# define total number of rows and 20% for testing data\nn <- nrow(eruptions_recent)\nx <- round(n * 0.2)\n# randomly draw 20% of the row numbers\ntest_rows <- sample(n, x)\ntest_rows [1] 68 39  1 34 43 14 59 51 21 42 54 46 10  7  9\n# split dataset using the subsetting syntax we just learned\neruptions_recent_test  <- eruptions_recent[ test_rows, ]\neruptions_recent_train <- eruptions_recent[-test_rows, ]\neruptions_recent_test# A tibble: 15 × 7\n   volcano                  start      stop       duration confirmed   vei start_year\n   <chr>                    <date>     <date>        <dbl>     <dbl> <dbl>      <dbl>\n 1 Veniaminof               2004-02-16 2004-09-05      202         1     2       2004\n 2 Cleveland                2010-09-11 2010-09-12        1         0    NA       2010\n 3 Kīlauea                  2024-06-03 2024-06-03        0         1    NA       2024\n 4 Mariana Back-Arc Segmen… 2013-02-13 2015-12-01     1021         1     0       2013\n 5 Cleveland                2009-10-02 2009-12-12       71         1     2       2009\n 6 Semisopochnoi            2021-02-02 2023-05-05      822         1     2       2021\n 7 Cleveland                2006-02-06 2006-10-28      264         1     3       2006\n 8 Anatahan                 2007-11-27 2008-08-09      256         1     2       2007\n 9 Great Sitkin             2019-06-01 2019-06-07        6         1     1       2019\n10 Pagan                    2010-05-03 2010-08-11      100         1     1       2010\n11 Pagan                    2006-12-04 2006-12-08        4         1     1       2006\n12 Cleveland                2009-01-02 2009-01-21       19         1     2       2009\n13 Pavlof                   2021-08-05 2022-12-07      489         1     2       2021\n14 Mauna Loa                2022-11-27 2022-12-10       13         1     0       2022\n15 Kīlauea                  2021-09-29 2023-09-16      717         1     0       2021\neruptions_recent_train# A tibble: 58 × 7\n  volcano               start      stop       duration confirmed   vei start_year\n  <chr>                 <date>     <date>        <dbl>     <dbl> <dbl>      <dbl>\n1 Atka Volcanic Complex 2024-03-27 2024-03-27        0         1    NA       2024\n2 Ahyi                  2024-01-01 2024-03-27       86         1    NA       2024\n3 Kanaga                2023-12-18 2023-12-18        0         1     1       2023\n4 Ruby                  2023-09-14 2023-09-15        1         1     1       2023\n5 Shishaldin            2023-07-11 2023-11-03      115         1     3       2023\n# ℹ 53 more rows\n# note the resulting rows will be in a different order,\n# but it's the same data frame we started out with\neruptions_recent_recombined <- rbind(eruptions_recent_test, eruptions_recent_train)\neruptions_recent_recombined# A tibble: 73 × 7\n  volcano                   start      stop       duration confirmed   vei start_year\n  <chr>                     <date>     <date>        <dbl>     <dbl> <dbl>      <dbl>\n1 Veniaminof                2004-02-16 2004-09-05      202         1     2       2004\n2 Cleveland                 2010-09-11 2010-09-12        1         0    NA       2010\n3 Kīlauea                   2024-06-03 2024-06-03        0         1    NA       2024\n4 Mariana Back-Arc Segment… 2013-02-13 2015-12-01     1021         1     0       2013\n5 Cleveland                 2009-10-02 2009-12-12       71         1     2       2009\n# ℹ 68 more rows"},{"path":"data-exploration.html","id":"data-exploration","chapter":"Data Exploration","heading":"Data Exploration","text":"One first important things obtaining dataset explore data thoroughly using combination summary statistics visualizations. Careful data exploration help following:Understand dataset,Discover interesting, sometimes unexpected patterns trends,Identify potential sources problems (e.g. errors, biases, obstacles later analysis),Formulate meaningful questions ask using data, andChoose appropriate path analysis.next section, cover variety data exploration techniques, starting descriptive (.e. summary) statistics, move data visualization (.e. graphing/plotting).","code":""},{"path":"descriptive.html","id":"descriptive","chapter":"5 Descriptive Statistics","heading":"5 Descriptive Statistics","text":"Descriptive statistics people think hear word “statistics”, .e. collection numbers summarize data. often good starting point exploring newly encountered dataset.statistic just number computed sample data, often intended summarize data specific way. Virtually function ingests sample outputs number can referred statistic.","code":""},{"path":"descriptive.html","id":"measures-of-central-tendency","chapter":"5 Descriptive Statistics","heading":"5.1 Measures of central tendency","text":"MANY statistics aim quantify “center” sample. collectively referred measures central tendency, also often called averages short. 3 common averages mean, median, mode.“Average” can refer measure central tendency, .e. average can refer either mean, median, mode (measures). Thus, ’s generally recommended specify measure ’re referring avoid using word “average” (unless ’re strategically ambiguous).","code":""},{"path":"descriptive.html","id":"mean","chapter":"5 Descriptive Statistics","heading":"5.1.1 Mean","text":"arithmetic mean sample, commonly referred just “mean”, people think hear “average”. sum sample divided sample size. Formally, given sample \\(x_1,x_2,\\dots,x_n\\) mean \\(\\bar{x}\\) defined :\\[\\bar{x}=\\frac1n\\sum_{=1}^nx_i=\\frac{x_1+x_2+\\cdots+x_n}n\\]mean may seem natural intuitive central tendency measure, number drawbacks:mean sensitive “outliers” recommended heavily skewed data.mean generally used truly numeric data, .e. data values intrinsically tied quantitative observable.\ncommon example data “truly” numeric ordinal data, commonly generated Likert scales (e.g. strongly disagree, disagree, neutral, agree, strongly agree), star-based review systems (e.g. ★★★★☆).20\ncommon example data “truly” numeric ordinal data, commonly generated Likert scales (e.g. strongly disagree, disagree, neutral, agree, strongly agree), star-based review systems (e.g. ★★★★☆).20Continuing previous 21st century US volcanic eruptions dataset, can use mean() , example, find mean length eruptions days:vector missing values, .e. NA, mean() statistical functions return NA. safety measure, help remind handle missing values appropriately attempting analysis. can tell R ignore NAs proceed setting na.rm = TRUE function.","code":"\n# import all core tidyverse packages, since we will need several\n# (again, this imports readr, tibble, and stringr, as well as several others)\nlibrary(tidyverse)\n# reload dataset\neruptions_recent <- read_csv(\n  \"https://bwu62.github.io/stat240-revamp/data/eruptions_recent.csv\",\n  show_col_types = FALSE\n)\n# compute mean duration of eruptions\nmean(eruptions_recent$duration)[1] 192.1233\n# we can check this agrees with our mathematical definition\nsum(eruptions_recent$duration) / length(eruptions_recent$duration)[1] 192.1233\n# example of NAs causing mean to fail\nmean(c(1, 6, NA, 2))[1] NA\n# setting na.rm = TRUE tells R to safely ignore NAs\nmean(c(1, 6, NA, 2), na.rm = TRUE)[1] 3"},{"path":"descriptive.html","id":"median","chapter":"5 Descriptive Statistics","heading":"5.1.2 Median","text":"median, common alternative mean, defined “middle” number sorted sample. Formally, ’s value greater equal half sample, also less equal half sample. even number observations, median isn’t uniquely defined commonly taken mean middle two numbers.median generally recommended mean following situations:“outliers”, data significantly skewed.data truly numeric, e.g. ordinal data.can use median() find median length eruptions days:Note median length eruptions, 71, significantly smaller mean, 192.1232877, data extremely skewed, .e. extremely long eruptions, pull mean much higher (since ’s sensitive extreme values).’s worth mentioning word “outliers” isn’t well defined formally actually surprisingly tricky subject statistics. , “outlier” just loosely refers observations differ dramatically compared rest data. ’s important remember “outliers” errors; may fact point new information ’re aware .Statistics less sensitive “outliers” called robust. E.g. median robust mean.","code":"\n# compute median duration of eruptions\nmedian(eruptions_recent$duration)[1] 71\n# check to see if it satisfies the formal definition\n# recall from the logical vectors section from Chapter 3 that\n# mean() of a logical vector gives the proportion of TRUEs\nc(\n  mean(\n    eruptions_recent$duration >= median(eruptions_recent$duration)\n  ),\n  mean(\n    eruptions_recent$duration <= median(eruptions_recent$duration)\n  )\n)[1] 0.5068493 0.5205479"},{"path":"descriptive.html","id":"mode","chapter":"5 Descriptive Statistics","heading":"5.1.3 Mode","text":"mode oft-maligned black sheep central tendency family. defined common observation, .e. observation occurs number times sample. ’s primarily intended categorical data (e.g. male vs female) though also relevance distributions (much later).mode course also form “average”. example, statistics show roughly 95% lumberjacks US male. therefore accurate say “average American lumberjack male”. fact, categorical data—ubiquitous—possible measure central tendency.Unfortunately, base R convenient function computing mode (function mode() completely unrelated), can easily either define import Mode() DescTools package","code":"\n# this defines a simple Mode function using mostly commands we already know\n# explanation: table tabulates observations, then\n#              sort(- ...) sorts by descending order, then\n#              names(...)[1] extracts the name of the first item\n# note this function doesn't return multiple modes if there are more than 1\nMode <- \\(x) names(sort(-table(x)))[1]\n# find the volcano with the most number of eruptions\nMode(eruptions_recent$volcano)[1] \"Cleveland\"\n# how many eruptions has Cleveland had since 2001?\nsum(eruptions_recent$volcano == \"Cleveland\")[1] 13\n# the DescTools package also has a Mode function,\n# which correctly handles ties and also gives the frequency\n# make sure to install it before using: install.packages(\"DescTools\")\nDescTools::Mode(eruptions_recent$volcano)[1] \"Cleveland\"\nattr(,\"freq\")\n[1] 13"},{"path":"descriptive.html","id":"modality","chapter":"5 Descriptive Statistics","heading":"5.1.4 Aside: Modality","text":"common distributions 1 mode, .e. unimodal, distributions may 2 modes, case ’re called bimodal (2 modes) multimodal (≥2 modes). ’s example bimodal distribution:","code":""},{"path":"descriptive.html","id":"other-measures","chapter":"5 Descriptive Statistics","heading":"5.1.5 Other measures","text":"mean, median, mode far common measures central tendency, ones need know course. However, thought might worth briefly mentioning averages interesting applications just fun:quadratic mean, also known root mean square, defined sample \\(x_1,\\dots,x_n\\) \\(\\sqrt{\\frac1n(x_1^2+\\cdots+x_n^2)}\\). shows statistical contexts, e.g. standard deviation almost quadratic mean difference observation arithmetic mean, except dividing \\(n-1\\) instead \\(n\\) (corrects small bias called Bessel’s correction). also applications model evaluation, statistical physics, electronics engineering, signal analysis, .geometric mean defined \\(\\sqrt[n]{x_1x_2\\cdots x_n}\\) valid positive-valued data. useful data multiplicative rather additive nature, e.g. growth rates, interest rates, comparisons relative performance benchmarks, etc. many applications finance economics, areas optical engineering, even cinematography.\nNote logarithm geometric mean sample equal arithmetic mean logarithm sample. words, geometric mean viewed log scale “looks like” arithmetic mean linear scale. Log transforms important tool certain contexts, see page brief overview.\nNote logarithm geometric mean sample equal arithmetic mean logarithm sample. words, geometric mean viewed log scale “looks like” arithmetic mean linear scale. Log transforms important tool certain contexts, see page brief overview.harmonic mean defined \\(\\left(\\frac{x_1^{-1}+\\,\\cdots\\,+x_n^{-1}}{n}\\right)^{\\!-1}\\), .e. reciprocal arithmetic mean reciprocals data, also typically used positive-valued data. turns correct mean use certain applications involving rate, ratio, time values. also applications machine learning, physics, finance, even baseball.Collectively, arithmetic, geometric, harmonic means also known Pythagorean means.just short list; host means exist. , need know advanced means; expected know arithmetic mean, median, mode.","code":""},{"path":"descriptive.html","id":"measures-of-spread","chapter":"5 Descriptive Statistics","heading":"5.2 Measures of spread","text":"Arguably next important set summary statistics measures central tendency measures spread, aim quantify “spread ” dataset . Variance standard deviation far common measures, IQR range also sometimes useful.Unlike measures central tendency, measures spread typically location-agnostic, .e. don’t change entire dataset shifted constant. Formally, sample \\(x_1,\\dots,x_n\\) sample \\(x_1+c,\\,\\dots,\\,x_n+c\\) spread \\(c\\).","code":""},{"path":"descriptive.html","id":"variance-and-standard-deviation","chapter":"5 Descriptive Statistics","heading":"5.2.1 Variance (and standard deviation)","text":"Let’s get easy one way first. Standard deviation always defined (positive) square root variance. ’s variance ? variance sample defined :\\[s^2=\\frac1{n-1}\\sum_{=1}^n(x_i-\\bar{x})^2=\\frac{(x_1-\\bar{x})^2+\\cdots+(x_n-\\bar{x})^2}{n-1}\\]Basically, ’s mean squared-distance mean, \\(\\bar{x}\\), except use \\(n-1\\) instead \\(n\\) correct small bias. example, can compute variance duration eruptions, days squared:words, “average” squared difference eruption’s duration mean duration 101.2k days2.Note units variance squared data units. makes inconvenient work , since means directly compared data. instead often work square root, .e. standard deviation:\\[s=\\sqrt{\\frac1{n-1}\\sum_{=1}^n(x_i-\\bar{x})^2}\\]can thought “average” distance mean given observation. can computed using sd():words, “average” distance days duration eruptions mean 318.1 days.Since standard deviation defined square root variance (thus variance always square standard deviation), knowing one quantities enables also easily compute .variance standard deviation common measures spread, like arithmetic mean, also sensitive outliers may suitable highly skewed data.","code":"\n# compute variance of duration\nvar(eruptions_recent$duration)[1] 101204.7\n# compute the standard deviation of duration\nsd(eruptions_recent$duration)[1] 318.1269\n# you can check this is equal to sqrt(var(...))\nsqrt(var(eruptions_recent$duration))[1] 318.1269"},{"path":"descriptive.html","id":"iqr","chapter":"5 Descriptive Statistics","heading":"5.2.2 Interquartile range","text":"interquartile range, also called IQR, distance 1st 3rd quartile. understand , let’s first briefly review percentiles.","code":""},{"path":"descriptive.html","id":"percentiles","chapter":"5 Descriptive Statistics","heading":"5.2.3 Percentiles","text":"Percentiles generalization median. Recall median data point just barely greater equal 50% data. Similarly, \\(p\\)th percentile data point just barely greater equal \\(p\\)% data. Percentiles computed using quantile(x, probs = p) function, x data vector, p desired percentile (vector thereof). example, can compute 0th, 25th, 50th, 75th, 100th percentiles eruption duration :5 numbers correspond min, 1st quartile (\\(Q_1\\)), median, 3rd quartile (\\(Q_3\\)), max respectively, often collectively known five-number summary. \\(Q_1\\) \\(Q_3\\) also frequently called upper lower hinges dataset.difference \\(Q_3-Q_1\\) called interquartile range, often used instead variance/standard deviation outliers/skewness significant concern dataset due increased robustness. IQR can computed IQR() function:","code":"\nquantile(eruptions_recent$duration, probs = c(0, 0.25, 0.5, 0.75, 1))  0%  25%  50%  75% 100% \n   0    6   71  195 1491 \n# compute the interquartile range of eruption durations\nIQR(eruptions_recent$duration)[1] 189"},{"path":"descriptive.html","id":"range","chapter":"5 Descriptive Statistics","heading":"5.2.4 Range","text":"range crudest measures spread, defined difference minimum maximum sample. even sensitive outliers variance/standard deviation, thus less commonly used formal statistical settings. sometimes practical measures extremely small datasets.R, range() function gives minimum maximum vector; get actual range, can use diff() take difference two:","code":"\n# range() gives the min/max vector\nrange(eruptions_recent$duration)[1]    0 1491\n# diff() of range() gives the true statistical range\ndiff(range(eruptions_recent$duration))[1] 1491"},{"path":"descriptive.html","id":"other-measures-1","chapter":"5 Descriptive Statistics","heading":"5.2.5 Other measures","text":"variance, standard deviation, IQR, range measures spread need know course, measures just fun:median absolute deviation MAD exactly sounds like, median absolute value deviation median. ’s robust (.e. outlier-resistant) version standard deviation.Gini coefficient another interesting measure spread (one favorites). ’s one list dimensionless (.e. always “pure” number units) always 0 1 non-negative data. ’s defined half relative mean absolute difference, defined average absolute difference \\(|x_i-x_j|\\) pairs observations divided arithmetic mean. ’s commonly used economics characterize inequality, 0 total equality (e.g. everyone exactly amount wealth) 1 total inequality (e.g. one person wealth everyone else none)., just subset possible measures spread, need know measures; expected know variance, standard deviation, IQR, range.","code":""},{"path":"descriptive.html","id":"skew","chapter":"5 Descriptive Statistics","heading":"5.3 Skew","text":"Another important summary statistic skew dataset. Skew precise mathematical definition beyond scope course. need know difference positive (also called right) skew negative (also called left) skew dataset.side skewness always side longer tail. longer tail positive (right) side, ’s called positive (right) skew. longer tail negative (left) side, ’s called negative (left) skew., 3 example (unimodal) distributions showing kinds skewness, modes aligned.unskewed, symmetric distribution, mode \\(=\\) median \\(=\\) mean.positive, right skewed distribution, mode \\(<\\) median \\(<\\) mean.negative, left skewed distribution, mean \\(<\\) median \\(<\\) mode.shows , already learned, median robust vs mean “outliers”/skew, words, mean affected “outliers”/skew gets “dragged away” skewness.Visually, mode always “peak”, median splits distribution 2 equal areas, mean center mass shape along horizontal axis (.e. “balancing point”).","code":""},{"path":"data-visualization.html","id":"data-visualization","chapter":"6 Data Visualization","heading":"6 Data Visualization","text":"Descriptive statistics good place start, usually plotting data visually best way fully understand dataset core. next chapter, cover variety common plot types useful exploratory analysis.studying plot type, ’s important keep following questions mind:kind data appropriate plot?create plot?interpret plot?","code":""},{"path":"data-visualization.html","id":"ggplot2","chapter":"6 Data Visualization","heading":"6.1 ggplot2","text":"making plots using ggplot2 package also core Tidyverse package. offers robust syntax easily creating modifying plots (link cheat sheet).making ggplot2 plot, ’s important remember everything layer add onto base object using + just like adding numbers. Whether ’re adding plot, faceting structure, changing axes, adding annotations (e.g. title/labels), etc. ’re layers added. may seem strange first, ’ll quickly grasp examples follow.Let’s first import necessary packages. need readr ggplot2 reading plotting data. convenience, ’ll just load core Tidyverse packages.","code":"\n# if you need to, reimport all core tidyverse packages\nlibrary(tidyverse)\n\n# optional: disable showing col_types by default in readr import functions\noptions(readr.show_col_types = FALSE)\n\n# optional: set a prettier theme and colorblind-friendly palette for plots\n#           (also looks better if printed with most printers, even in b/w)\ntheme_set(theme_bw())\noptions(ggplot2.discrete.fill = \\(...) scale_fill_brewer(..., palette = \"Set2\"),\n        ggplot2.discrete.colour = \\(...) scale_color_brewer(..., palette = \"Dark2\"))"},{"path":"data-visualization.html","id":"palmer-penguins","chapter":"6 Data Visualization","heading":"6.2 Palmer penguins","text":"properly demonstrate plots, need slightly feature-rich dataset. Let’s import Palmer penguins dataset readily usable good set variables.21 ’ve removed rows NAs convenience, ’s link file: penguins.csv.column variables intuitively named able guess meaning; see penguins help page info variables well papers detailing data gathering process.","code":"\n# load in the penguins dataset\n# (note: a few rows with NAs have been removed for simplicity)\npenguins <- read_csv(\"https://bwu62.github.io/stat240-revamp/data/penguins.csv\")\n# print the first few rows of the data frame to check;\n# this data frame is now too wide for our screen,\n# you can see some columns are cut off\nprint(penguins, n = 5)# A tibble: 333 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex   \n  <chr>   <chr>              <dbl>         <dbl>             <dbl>       <dbl> <chr> \n1 Adelie  Torgersen           39.1          18.7               181        3750 male  \n2 Adelie  Torgersen           39.5          17.4               186        3800 female\n3 Adelie  Torgersen           40.3          18                 195        3250 female\n4 Adelie  Torgersen           36.7          19.3               193        3450 female\n5 Adelie  Torgersen           39.3          20.6               190        3650 male  \n# ℹ 328 more rows\n# ℹ 1 more variable: year <dbl>\n# let's temporarily increase the width and reprint,\n# so you can see all columns in the data frame\noptions(width = 92)\npenguins# A tibble: 333 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex     year\n   <chr>   <chr>              <dbl>         <dbl>             <dbl>       <dbl> <chr>  <dbl>\n 1 Adelie  Torgersen           39.1          18.7               181        3750 male    2007\n 2 Adelie  Torgersen           39.5          17.4               186        3800 female  2007\n 3 Adelie  Torgersen           40.3          18                 195        3250 female  2007\n 4 Adelie  Torgersen           36.7          19.3               193        3450 female  2007\n 5 Adelie  Torgersen           39.3          20.6               190        3650 male    2007\n 6 Adelie  Torgersen           38.9          17.8               181        3625 female  2007\n 7 Adelie  Torgersen           39.2          19.6               195        4675 male    2007\n 8 Adelie  Torgersen           41.1          17.6               182        3200 female  2007\n 9 Adelie  Torgersen           38.6          21.2               191        3800 male    2007\n10 Adelie  Torgersen           34.6          21.1               198        4400 male    2007\n# ℹ 323 more rows\n# reset width to its original value\noptions(width = 85)\n# another option is the glimpse() function which prints sideways,\n# avoiding the hidden columns due to insufficient width issue\nglimpse(penguins)Rows: 333\nColumns: 8\n$ species           <chr> \"Adelie\", \"Adelie\", \"Adelie\", \"Adelie\", \"Adelie\", \"Adelie…\n$ island            <chr> \"Torgersen\", \"Torgersen\", \"Torgersen\", \"Torgersen\", \"Torg…\n$ bill_length_mm    <dbl> 39.1, 39.5, 40.3, 36.7, 39.3, 38.9, 39.2, 41.1, 38.6, 34.…\n$ bill_depth_mm     <dbl> 18.7, 17.4, 18.0, 19.3, 20.6, 17.8, 19.6, 17.6, 21.2, 21.…\n$ flipper_length_mm <dbl> 181, 186, 195, 193, 190, 181, 195, 182, 191, 198, 185, 19…\n$ body_mass_g       <dbl> 3750, 3800, 3250, 3450, 3650, 3625, 4675, 3200, 3800, 440…\n$ sex               <chr> \"male\", \"female\", \"female\", \"female\", \"male\", \"female\", \"…\n$ year              <dbl> 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 200…"},{"path":"data-visualization.html","id":"one-variable-plots","chapter":"6 Data Visualization","heading":"6.3 One-variable plots","text":"Ok, now ’re finally ready learn plots. start simple one-variable plots, .e. plots can made single column data frame. Depending type variable, may decide end choosing several different plot types. Note plot types can also enhanced visualize two variables, soon demonstrate.","code":""},{"path":"data-visualization.html","id":"histogram","chapter":"6 Data Visualization","heading":"6.3.1 Histogram","text":"Histograms plots numeric values grouped “bins” (.e. intervals) count bin plotted bar. extremely effective visualizing distribution single numeric column, allowing easily see shape, spread, even skewness dataset. Histograms one common plots numeric data.following code makes basic histogram R using ggplot.","code":"\nggplot(penguins, aes(x = flipper_length_mm)) + geom_histogram()"},{"path":"data-visualization.html","id":"interpretation","chapter":"6 Data Visualization","heading":"6.3.1.1 Interpretation","text":"Looking plot, can make key observations:distribution flipper length bimodal, .e. 2 peaks: around 190mm 215mm.peak around 190mm higher (.e. numerous) peak around 215mm, comparable spreads.\ncan mean either group observations prominent population studied, perhaps result kind selection sampling bias.\ncan mean either group observations prominent population studied, perhaps result kind selection sampling bias.two modes, 200-205mm, ’s noticeable “gap” comparatively much fewer observations.vast majority observations around 180-220mm, extremes almost low 170mm just slightly 230mm.","code":""},{"path":"data-visualization.html","id":"explanation-of-syntax","chapter":"6 Data Visualization","heading":"6.3.1.2 Explanation of syntax:","text":"code may seem strange first, ’s quick explanation:ggplot() function creates base “plot object”, kind like setting canvas preparation painting. ggplot() takes 2 arguments order:\nfirst argument penguins data frame used plot. general rule, always put data want plot SINGLE data frame pass ggplot().\nsecond argument aesthetic mapping. Think aesthetics choosing display column variables data frame. ’s brief list common aesthetics can map:\nx controls horizontal axis,\ny controls vertical axis,\ncolor fill control point/line/boundary color inside/fill colors respectively,\nshape size control point shapes sizes respectively,\nlinetype controls type line (.e. solid, dashed, dotted, etc.)\n\nfirst argument penguins data frame used plot. general rule, always put data want plot SINGLE data frame pass ggplot().second argument aesthetic mapping. Think aesthetics choosing display column variables data frame. ’s brief list common aesthetics can map:\nx controls horizontal axis,\ny controls vertical axis,\ncolor fill control point/line/boundary color inside/fill colors respectively,\nshape size control point shapes sizes respectively,\nlinetype controls type line (.e. solid, dashed, dotted, etc.)\nx controls horizontal axis,y controls vertical axis,color fill control point/line/boundary color inside/fill colors respectively,shape size control point shapes sizes respectively,linetype controls type line (.e. solid, dashed, dotted, etc.)base plot object setup data frame aesthetic mapping, simply need “add ” plot layer like geom_histogram() specifies type plot want drawn!\ncan also specify aesthetic mapping plot layer (e.g. inside geom_histogram()), override aesthetic mapping inherits base ggplot() object. Otherwise, aesthetic mapping base ggplot() object used. example, make exact plot:\nggplot(penguins, aes(x = flipper_length_mm)) + geom_histogram()\nggplot(penguins) + geom_histogram(aes(x = flipper_length_mm))\n\ncan also specify aesthetic mapping plot layer (e.g. inside geom_histogram()), override aesthetic mapping inherits base ggplot() object. Otherwise, aesthetic mapping base ggplot() object used. example, make exact plot:\nggplot(penguins, aes(x = flipper_length_mm)) + geom_histogram()\nggplot(penguins) + geom_histogram(aes(x = flipper_length_mm))\nggplot(penguins, aes(x = flipper_length_mm)) + geom_histogram()ggplot(penguins) + geom_histogram(aes(x = flipper_length_mm))Due slightly unusual nature syntax, number common failure modes observed. Make sure take note following:Plot layers ALWAYS added + like numbers. just design syntax. Attempting use anything else give errors!Plot layers ALWAYS added + like numbers. just design syntax. Attempting use anything else give errors!also MUST execute layer like function (). try just add `+ geom_histogramwithout ()`, layer generate correctly give errors!also MUST execute layer like function (). try just add `+ geom_histogramwithout ()`, layer generate correctly give errors!many layers, ’s recommended break multiple lines, incomplete line MUST either unclosed parenthetical ( end unfinished addition +, example:\n\n# ok; R sees incomplete lines\n# continues reading next line\nggplot(penguins,                       # unclosed ( parenthetical\n       aes(x = flipper_length_mm)) +   # unfinished + addition\n  geom_histogram()\n\n# error, since first line incomplete!!\nggplot(penguins, aes(x = flipper_length_mm))\n  + geom_histogram()\nError `+.gg`:\n! use `+` single argument.\nℹ accidentally put `+` new line?many layers, ’s recommended break multiple lines, incomplete line MUST either unclosed parenthetical ( end unfinished addition +, example:Don’t forget incomplete ( somewhere, didn’t finish + statement, R patiently wait replacing normal > prompt + prompt. Finish line hit ESC quit.","code":"\n# this is ok; R sees the incomplete lines\n# and continues reading the next line\nggplot(penguins,                       # unclosed ( parenthetical\n       aes(x = flipper_length_mm)) +   # unfinished + addition\n  geom_histogram()\n# but this will error, since the first line is NOT incomplete!!\nggplot(penguins, aes(x = flipper_length_mm))\n  + geom_histogram()Error in `+.gg`:\n! Cannot use `+` with a single argument.\nℹ Did you accidentally put `+` on a new line?"},{"path":"data-visualization.html","id":"adding-aesthetics","chapter":"6 Data Visualization","heading":"6.3.1.3 Adding aesthetics","text":"ggplot2, can easily add additional aesthetics plot, turning one-variable plots two-variable plots, allowing visualize vary together. Remember histogram shows bimodality? turns represent different species penguins. Let’s use fill aesthetic differentiate species.default, ggplot stack bars position along horizontal axis. Let’s unstack setting position = \"identity\" make bars 50% opaque setting alpha = 0.5 can better see group. set plot layer geom_histogram().already starting look pretty good! can now start easily make interesting observations:species penguin different average22 flipper length, Gentoo penguins largest, Adelie penguins smallest, Chinstrap penguins somewhere .seems far Adelie Gentoo penguins dataset Chinstrap penguins. can investigate later.Aesthetics always mapped columns data frame. Also note columns proper names (.e. letters, numbers, periods, underscores spaces symbols) need quotes \" \" used inside ggplot (well Tidyverse functions).plots can flipped (.e. changed horizontal vertical vice versa) swapping x y aesthetics, .e. using y = ... instead x = ... vice versa. cases may preferred (e.g. dataset long labels) generally ’s matter personal preference/style. Feel free experiment !","code":"\nggplot(penguins, aes(x = flipper_length_mm, fill = species)) +\n  geom_histogram()\nggplot(penguins, aes(x = flipper_length_mm, fill = species)) +\n  geom_histogram(position = \"identity\", alpha = 0.5)"},{"path":"data-visualization.html","id":"title-labels","chapter":"6 Data Visualization","heading":"6.3.1.4 Title & labels","text":"one final thing done plot: title label ! something EVERY plot make, just class throughout data science career.plot annotations (e.g. titles, axes/data labels, legends, etc.) meet following criteria:Accuracy: annotations contain accurate information.Precision: strive precise (e.g. instead “average”, specify mean, median, mode, something else).Concision: strive use words necessary convey important information given context.Grammar/spelling: proper grammar spelling used (abbreviations, needed, standard intuitive).Units: unless ’s extremely obvious (unitless), data units also specified!plots submitted class without annotations annotations meeting criteria may penalized!Annotations hard get right sometimes; practice adding every plot, think critically write read peoples’ plots ’ll get good fast.can add titles/labels adding labs() layer. Inside labs(), can simultaneously set /following:x = \"...\" y = \"...\" sets axes labels x ytitle sets plot titlelabels aesthetics can also set using aesthetic name\nexample, used fill, set legend label fill = \"...\"\nexample, used fill, set legend label fill = \"...\"less frequently used labels include subtitle, caption, alt alt-textFor example:plot now ready use!","code":"\nggplot(penguins, aes(x = flipper_length_mm, fill = species)) +\n  geom_histogram(position = \"identity\", alpha = 0.5) +\n  labs(x = \"Flipper length (mm)\", y = \"Count\", fill = \"Species\",\n    title = \"Flipper length histograms of species in Palmer penguins sample\")"},{"path":"data-visualization.html","id":"extra-options","chapter":"6 Data Visualization","heading":"6.3.1.5 Extra options","text":"90% time, steps went need completely prepare plot use. 10% time, may need configure plot . plot layer function additional specific options can set, usual check help page search online !cover every option every plot type, occasionally, may highlight important options experiment explore . geom_histogram(), besides unstacking bars position = \"identity\" argument showed , may also want control bins set. ’s several ways briefly outlined —note can choose ONE method!can set bins argument set many total bins, used evenly divide range data. E.g. default, bins = 30 used draw 30 bins, generally agreed sensible default, even though can create bins strange decimal bounds (like example, bins (171.91,173.95], (173.95,175.98], …, (230.91,232.95]).\ndata integer-valued (like flipper length ), default method can actually cause problems, bins contain whole numbers others, creating strange artifacts data. example, two consecutive bins (1.8,3.2] (3.2,4.6], even though 1.4 units wide, first covers 2 whole numbers (2 3) whereas second covers 1 whole number (just 4) distort histogram shape.\ndata integer-valued (like flipper length ), default method can actually cause problems, bins contain whole numbers others, creating strange artifacts data. example, two consecutive bins (1.8,3.2] (3.2,4.6], even though 1.4 units wide, first covers 2 whole numbers (2 3) whereas second covers 1 whole number (just 4) distort histogram shape.Alternatively, can also set binwidth boundary arguments start given boundary count given binwidth create bins.\nexample, want make bins (170,175], (175,180], …, (230,235], can set binwidth = 5 boundary = 170 (whole number divisible 5).\nexample, want make bins (170,175], (175,180], …, (230,235], can set binwidth = 5 boundary = 170 (whole number divisible 5).maximum control, can also set breaks equal numeric vector use bin boundaries.\nexample, breaks (170,175], (175,180], …, (230,235] can chosen setting breaks = seq(170, 235, = 5).\nexample, breaks (170,175], (175,180], …, (230,235] can chosen setting breaks = seq(170, 235, = 5).Generally, want choose bins easy visually interpret, try using whole numbers work well base-10 decimal system. also want avoid using many bins can cause problems.Let’s improve plot one final time setting sensible bin widths:now even easier interpret, artifacts previous plots gone. can easily identify average23 group, even identify specific counts specific bins (e.g. can tell example 39 penguins Adelie penguins observed (190,195] bin).","code":"\nggplot(penguins, aes(x = flipper_length_mm, fill = species)) +\n  geom_histogram(position = \"identity\", alpha = 0.5,\n                 binwidth = 5, boundary = 170) +\n  labs(x = \"Flipper length (mm)\", y = \"Count\", fill = \"Species\",\n    title = \"Flipper length histograms of species in Palmer penguins sample\")"},{"path":"data-visualization.html","id":"density-plots","chapter":"6 Data Visualization","heading":"6.3.2 Density plots","text":"common variation histogram density plot, can thought like smoothed-curve version histogram, area curve normalized 1. represents guess entire population distribution looks like based sample drawn. can created adding geom_density() plot layer.Similar histogram, can also add additional aesthetics differentiate species:Note looks similar previously made histogram, Chinstrap distribution longer overshadowed species, since area normalization process effectively removes effect sample size height distribution species.learn lot density plots later inference portion course, now move .can make plot even accessible readers certain vision impairments adding certain additional aesthetics. example, try adding linetype = species aesthetic mapping (don’t forget add label inside labs()), well increasing border thickness adding linewidth = 1 inside geom_density() observe output!","code":"\nggplot(penguins, aes(x = flipper_length_mm)) + geom_density()\nggplot(penguins, aes(x = flipper_length_mm, fill = species)) +\n  geom_density(alpha = 0.5) +\n  labs(x = \"Flipper length (mm)\", y = \"Density\", fill = \"Species\",\n    title = \"Flipper length densities of species in Palmer penguins sample\")"},{"path":"data-visualization.html","id":"box-plots","chapter":"6 Data Visualization","heading":"6.3.3 Box plots","text":"Another common plot numeric values box plot. Box plots simply way showing following 5 summary statistics number line:minimum sample,first quartile \\(Q_1\\), .e. 25th percentile,median,third quartile \\(Q_3\\), .e. 75th percentile, andThe maximum sample.\\(Q_1\\) \\(Q_3\\) form ends “box”, median shown line , min max form “whiskers” stretch either end. Note width box (.e. \\(Q_3-Q_1\\)) IQR.Compared histogram density plot, key advantages drawbacks:’s easier compare specific summary statistics like median quartiles using box plots,However ’s often less effective communicating complex features like modality skew.simplicity sometimes works better comparing many groups without appearing overly complex.Let’s show five number summary fivenum() well corresponding box plot flipper length variable:Note even though can easily identify median, quartiles, min/max, can longer observe bimodality like previously histogram density plot. tradeoff sometimes worth making sometimes .boxplot can also easily adapted highlight difference species, time adding y aesthetic:plot sacrifices distributional complexity density plot, return can easily compare summary statistics group, overall arguably just “looks nicer” opinion.Note 2 Adelie penguins plotted points instead, due common “rule thumb” box plots label points 1.5×IQR away quartile “outliers”. , simply default convention. See help page details, well disable .","code":"\n# get the min, q1, median, q3, and max:\nfivenum(penguins$flipper_length_mm)[1] 172 190 197 213 231\n# turn these into a box plot\nggplot(penguins, aes(x = flipper_length_mm)) + geom_boxplot()\nggplot(penguins, aes(x = flipper_length_mm, y = species)) +\n  geom_boxplot() +\n  labs(x = \"Flipper length (mm)\", y = \"Species\",\n       title = \"Flipper length box plots of species in Palmer penguins sample\")"},{"path":"data-visualization.html","id":"bar-plots","chapter":"6 Data Visualization","heading":"6.3.4 Bar plots","text":"far, discussed visualizing 1 numeric variable, several interesting options shown sections , pros/cons.1 categorical variable, bar plots bars varying heights plotted category real option. Generally, common thing plot (without involving columns) either count proportion category observed sample. Note proportion, pie charts also often used, fallen fashion longer recommended.Confusingly, ggplot2 offers 2 different functions making bar plots geom_bar() geom_col() appear similar !geom_bar() default accepts one aesthetic (either x y ) tally given column, counting number rows category plotting total counts. generally used full original dataset.geom_col() default demands two aesthetics (x y) performs computation simply plots one . generally used summaries dataset, full original dataset.example, can use geom_bar() compute plot total count species sample:wanted make plot using geom_col(), must FIRST summarize dataset computing counts manually, passing species computed values x y aesthetics, like :next chapter, learn efficiently summarize datasets similar “summary” data frames like , allow us fully appreciate versatility geom_col().","code":"\nggplot(penguins, aes(x = species)) + geom_bar() +\n  labs(x = \"Species\", y = \"Count\",\n       title = \"Count of each species in Palmer penguins sample\")\n# we will learn later how to do this more efficiently with tidyverse,\n# but for now we can summarize the counts using base R syntax\npenguins_species_counts <- tibble(\n  species = c(\"Adelie\", \"Chinstrap\", \"Gentoo\"), \n  count = c(\n    sum(penguins$species == \"Adelie\"),\n    sum(penguins$species == \"Chinstrap\"),\n    sum(penguins$species == \"Gentoo\")\n  )\n)\n# check the result\npenguins_species_counts# A tibble: 3 × 2\n  species   count\n  <chr>     <int>\n1 Adelie      146\n2 Chinstrap    68\n3 Gentoo      119\n# now, make the same plot using the summary data frame and geom_col()\nggplot(penguins_species_counts, aes(x = species, y = count)) + geom_col() +\n  labs(x = \"Species\", y = \"Count\",\n       title = \"Count of each species in Palmer penguins sample\")"},{"path":"data-visualization.html","id":"extra-options-1","chapter":"6 Data Visualization","heading":"6.3.4.1 Extra options","text":"geom_bar() two important arguments significantly improve utility. can set stat = \"summary\" fun = \"...\" ... name summary function (e.g. mean, median, sd, var, IQR, range, “summary” function, .e. something ingests vector outputs single value). allow set axis aesthetic well (e.g. y = ...) another column summarized using given function.example, supposed want use bar plot compare median flipper length species. can set stat = \"summary\", fun = \"median\", map y = flipper_length_mm make following plot:","code":"\nggplot(penguins, aes(x = species, y = flipper_length_mm)) +\n  geom_bar(stat = \"summary\", fun = \"median\") +\n  labs(x = \"Species\", y = \"Median flipper length (mm)\",\n       title = \"Median flipper length by species in Palmer penguins sample\")"},{"path":"data-visualization.html","id":"adding-aesthetics-1","chapter":"6 Data Visualization","heading":"6.3.4.2 Adding aesthetics","text":"Bar plots also often good candidates adding additional aesthetics like fill. ’ll show 2 examples : stacked unstacked bar version.default, adding fill creates stacked bar plot, good showing proportions bar respect second categorical variable. example, suppose want show island species came . can adding fill = island aesthetic mapping:can also unstack bars setting position = \"dodge\" inside geom_bar(), making bars appear side side. example, suppose want compare median flipper length species also sex. can easily adding fill = sex aesthetic mapping, well setting position mentioned :","code":"\nggplot(penguins, aes(x = species, fill = island)) + geom_bar() +\n  labs(x = \"Species\", y = \"Count\", fill = \"Island\",\n       title = \"Count of each species (by island) in Palmer penguins sample\")\nggplot(penguins, aes(x = species, y = flipper_length_mm, fill = sex)) +\n  geom_bar(stat = \"summary\", fun = \"median\", position = \"dodge\") +\n  labs(x = \"Species\", y = \"Median flipper length (mm)\", fill = \"Sex\",\n       title = \"Median flipper length by species & sex in Palmer penguins sample\")"},{"path":"data-visualization.html","id":"two-variable-plots","chapter":"6 Data Visualization","heading":"6.4 Two-variable plots","text":"contrast previous types, plot types MUST made least two variables; possible single column.","code":""},{"path":"data-visualization.html","id":"scatter-plot","chapter":"6 Data Visualization","heading":"6.4.1 Scatter plot","text":"Scatter plots perhaps famous plot type, one people well familiar . Scatter plots classic y vs x plot two numeric variables Cartesian coordinates 2-dimensional grid. make scatter plot ggplot2, just need map x y aesthetics two columns, add geom_point() layer.example, suppose want make scatter plot flipper length vs bill depth see correlation two. Note always say y vs x, never x vs y. code:","code":"\nggplot(penguins, aes(y = flipper_length_mm, x = bill_depth_mm)) + geom_point() +\n  labs(x = \"Bill depth (mm)\", y = \"Flipper length (mm)\",\n       title = \"Flipper length vs bill depth for Palmer penguins sample\")"},{"path":"data-visualization.html","id":"adding-aesthetics-2","chapter":"6 Data Visualization","heading":"6.4.1.1 Adding aesthetics","text":"may surprise see two negatively correlated, .e. increase bill depth seems correlate decrease flipper length, vice versa. However, add species plot, see interesting pattern emerge.improve readability, can set color shape aesthetics controlled species column, well slightly increase size points setting size = 2 inside geom_point(), like :Now can clearly see bill depth flipper length fact positively correlated within species, might expect. effect called Simpson’s paradox arises surprisingly often datasets, notably 1973 UC Berkeley accused gender discrimination almost sued.24When making scatter plots, ’s important remember correlation necessarily imply causation. flippers grow longer long bills vice versa? Obviously probably , penguins just grow bigger others species winning genetic lottery bigger features overall.25","code":"\nggplot(penguins, aes(y = flipper_length_mm, x = bill_depth_mm,\n                     color = species, shape = species)) +\n  geom_point(size = 2) +\n  labs(x = \"Bill depth (mm)\", y = \"Flipper length (mm)\",\n       color = \"Species\", shape = \"Species\",\n       title = \"Flipper length vs bill depth by species for Palmer penguins sample\")"},{"path":"data-visualization.html","id":"smoothed-trend-curveslines","chapter":"6 Data Visualization","heading":"6.4.2 Smoothed trend curves/lines","text":"can also add smoothed trend curve/line (depending context) plot highlight direction correlation within species group. adding additional geom_smooth() layer plot. default, plot smoothed trend curve (using LOESS smoothing) group:clearly right ; data shows strong signs linearity. can force geom_smooth() fit plot linear regression models species setting method = \"lm\". can also turn unnecessarily cluttering gray error margins se = FALSE get much improved plot:Note since x, y, color set base ggplot() object, subsequent layers automagically inherit aesthetics; geom_point() geom_smooth() know use aesthetic mappings construct plot layers. Trend curves don’t make use shape aesthetic applies scatter plot layer, ’s simply ignored geom_smooth().good time point difference mapping aesthetic base object vs mapping plot layer.last example code chunk , note set x, y, color, shape aesthetics base ggplot() object, inherited geom_point() geom_smooth() layers. instead don’t want one inherit certain aesthetics, can set directly layer instead.example, suppose species points differing color shape, don’t want different trend line species, rather 1 single trend line across points. can easily achieve setting color shape inside geom_point() instead ggplot(). cause geom_smooth() inherit x y ggplot() single trend line made species:","code":"\nggplot(penguins, aes(y = flipper_length_mm, x = bill_depth_mm,\n                     color = species, shape = species)) +\n  geom_point(size = 2) + geom_smooth() +\n  labs(x = \"Bill depth (mm)\", y = \"Flipper length (mm)\",\n       color = \"Species\", shape = \"Species\",\n       title = \"Flipper length vs bill depth by species for Palmer penguins sample\")\nggplot(penguins, aes(y = flipper_length_mm, x = bill_depth_mm,\n                     color = species, shape = species)) +\n  geom_point(size = 2) + geom_smooth(method = \"lm\", se = FALSE) +\n  labs(x = \"Bill depth (mm)\", y = \"Flipper length (mm)\",\n       color = \"Species\", shape = \"Species\",\n       title = \"Flipper length vs bill depth by species for Palmer penguins sample\")\nggplot(penguins, aes(y = flipper_length_mm, x = bill_depth_mm)) +\n  geom_point(aes(color = species, shape = species), size = 2) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(x = \"Bill depth (mm)\", y = \"Flipper length (mm)\",\n       color = \"Species\", shape = \"Species\",\n       title = \"Flipper length vs bill depth by species for Palmer penguins\")"},{"path":"data-visualization.html","id":"line-plots","chapter":"6 Data Visualization","heading":"6.4.3 Line plots","text":"specific datasets, especially chronological datasets variable plotted time, may make sense directly connect individual data point points form line (trace) plot. Note smoothed trend plot shown since line plot smoothing performed!Unfortunately, Palmer penguins dataset isn’t best example last plot type, ’m temporarily borrowing another dataset example. chunk imports enrollment.csv contains historic U.S. college enrollment data sex., row pair male female college enrollment counts (millions) specific year. can obviously just make scatter plot enrollment vs year, additional aesthetics differentiating male female data points, like :However, chronological nature data means data point specific predecessor successor, .e. point (except end points) specific points comes chronological order. Thus, makes sense connect points single continuous line sex. can done using geom_line() instead. can also drop shape aesthetic since doesn’t apply lines:default line appears thin may hard read people. can add linewidth = 1.2 geom_line() increase thickness. can also add another aesthetic linetype = sex additional disambiguation ’s extremely clear line corresponds sex:can see since late 70’s, college enrollment female students consistently outpaced male students.purposes course, “line plot” “trace plot” refer geom_line(), “smoothed line” “trend line” “straight line” refer geom_smooth(method = \"lm\"). Take care mix !","code":"\nenrollment <- read_csv(\"https://bwu62.github.io/stat240-revamp/data/enrollment.csv\")\n# show a glimpse of the dataset\nglimpse(enrollment)Rows: 146\nColumns: 3\n$ year              <dbl> 1947, 1947, 1948, 1948, 1949, 1949, 1950, 1950, 1951, 195…\n$ sex               <chr> \"male\", \"female\", \"male\", \"female\", \"male\", \"female\", \"ma…\n$ enrolled_millions <dbl> 1.659249, 0.678977, 1.709367, 0.694029, 1.721572, 0.72332…\nggplot(enrollment, aes(x = year, y = enrolled_millions,\n                       color = sex, shape = sex)) +\n  geom_point(size = 2) +\n  labs(x = \"Time\", y = \"Enrolled (millions)\",\n       color = \"Sex\", shape = \"Sex\",\n       title = \"U.S. College enrollment by sex\")\nggplot(enrollment, aes(x = year, y = enrolled_millions, color = sex)) +\n  geom_line() +\n  labs(x = \"Time\", y = \"Enrolled (millions)\", color = \"Sex\",\n       title = \"U.S. College enrollment by sex\")\nggplot(enrollment, aes(x = year, y = enrolled_millions,\n                       color = sex, linetype = sex)) +\n  geom_line(linewidth = 1.2) +\n  labs(x = \"Time\", y = \"Enrolled (millions)\",\n       color = \"Sex\", linetype = \"Sex\",\n       title = \"U.S. College enrollment by sex\")"},{"path":"data-visualization.html","id":"bonus-area-plots","chapter":"6 Data Visualization","heading":"6.4.4 Bonus: area plots","text":"wanted throw bonus plot type . kind composition--time data also commonly shown stacked area plot can made geom_area(). ’ve also added scale_fill_manual() configuration layer manually specify color palette use intuitive colors category.Compared line plots one line per category, stacked area plot advantage easily showing relative proportions categories well total sum categories, comes cost able easily compare individual categories . tradeoff, usual.","code":"\nggplot(enrollment, aes(x = year, y = enrolled_millions, fill = sex)) +\n  geom_area() + scale_fill_manual(values = c(\"#fb9a99\", \"#a6cee3\")) +\n  labs(x = \"Time\", y = \"Enrolled (millions)\", fill = \"Sex\",\n       title = \"U.S. College enrollment by sex\")"},{"path":"data-visualization.html","id":"aside-time-axis","chapter":"6 Data Visualization","heading":"6.4.5 Aside: time axis","text":"Note previous example used just year number horizontal axis (since data already summarized annual totals) can course also use dates axis. quick example, can load FRED U.S. unemployment rate dataset plot .superficially look previous plot, however zoom plot just last year data, can see horizontal axis fact special date type axis:choppiness data summarized monthly.","code":"\nunemployment <- read_csv(\"https://fred.stlouisfed.org/graph/fredgraph.csv?id=UNRATE\")\nglimpse(unemployment)Rows: 920\nColumns: 2\n$ DATE   <date> 1948-01-01, 1948-02-01, 1948-03-01, 1948-04-01, 1948-05-01, 1948-06…\n$ UNRATE <dbl> 3.4, 3.8, 4.0, 3.9, 3.5, 3.6, 3.6, 3.9, 3.8, 3.7, 3.8, 4.0, 4.3, 4.7…\nggplot(unemployment, aes(x = DATE, y = UNRATE)) + geom_line() +\n  labs(x = \"Time\", y = \"Unemployment rate (%)\",\n       title = \"U.S. Unemployment rate\")\n# plot just the last 12 months of data\nn = nrow(unemployment)\nggplot(unemployment[(n-11):n,], aes(x = DATE, y = UNRATE)) + geom_line() +\n  labs(x = \"Time\", y = \"Unemployment rate (%)\",\n       title = \"U.S. Unemployment rate\")"},{"path":"data-visualization.html","id":"facet-subplots","chapter":"6 Data Visualization","heading":"6.5 Facet subplots","text":"Another way incorporate additional aesthetics use facets, .e. instead everything one plot, breaking multiple subplots visualize extra dimensions dataset.two primary functions :facet_wrap() creates series subplots along ONE additional categorical column one panel category, allows plots wrap onto multiple rows, way sentence can wrap onto multiple lines. best want incorporate single additional variable many levels wouldn’t fit onto one row.facet_grid() creates grid subplots along one two additional categorical column(s). can make either row subplots, column subplots, even matrix , incorporating two additional columns visualizations.Let’s demonstrate briefly.","code":""},{"path":"data-visualization.html","id":"facet_wrap","chapter":"6 Data Visualization","heading":"6.5.1 facet_wrap()","text":"Going back penguins dataset, suppose wanted look relationship body mass flipper length. start making plot:Maybe decide also incorporate species variable, can see differences different species:interesting patterns start emerge. Suppose want take step also incorporate sex, see adds anything interesting picture. change example mapping set shape = sex, think results plot ’s little complicated hard read:better way may facet_wrap() species variable, switch using color shape differentiate sex. syntax add faceting layer facet_wrap() argument ~species automagically split species facet subplot. can also set ncol = 2 control /wrap plots:","code":"\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm)) + geom_point()\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm,\n                     color = species, shape = species)) +\n  geom_point(size = 2)\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm,\n                     color = species, shape = sex)) +\n  geom_point(size = 2) +\n  labs(x = \"Body mass (g)\", y = \"Flipper length (mm)\",\n       title = \"Flipper length vs body mass (by species & sex) for Palmer penguins\")\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm,\n                     color = sex, shape = sex)) +\n  geom_point(size = 2) + facet_wrap(~species, ncol = 2) +\n  labs(x = \"Body mass (g)\", y = \"Flipper length (mm)\", color = \"Sex\", shape = \"Sex\",\n       title = \"Flipper length vs body mass (by species & sex) for Palmer penguins\")"},{"path":"data-visualization.html","id":"facet_grid","chapter":"6 Data Visualization","heading":"6.5.2 facet_grid()","text":"Suppose wanted look closely distribution flipper lengths species sex. can start plot made previously section 6.3.2:Suppose want also add sex variable interest, also want closely scrutinize distributions. One way can done add faceting layer facet_grid() argument sex ~ species construct matrix plots one row sex one column species:can also replace one side ~ b syntax period . facet direction. example, sex ~ . make matrix plots one row sex, single column together, whereas . ~ species make matrix plots one column species, one row together.can demonstrate . time can reassign variable faceted (.e. one replaced .) back fill aesthetic. second plot, also flipped x y make better use tall-orientation available plot space.default, facet_wrap() facet_grid() match x y axes across subplots. can turn either setting scales argument faceting function either free_x free_y free one axis, free free axes.","code":"\nggplot(penguins, aes(x = flipper_length_mm, fill = species)) +\n  geom_density(alpha = 0.5) +\n  labs(x = \"Flipper length (mm)\", y = \"Density\", fill = \"Species\",\n       title = \"Flipper length densities of species in Palmer penguins\")\nggplot(penguins, aes(x = flipper_length_mm)) + geom_density() +\n  facet_grid(sex ~ species) +\n  labs(x = \"Flipper length (mm)\", y = \"Density\",\n       title = \"Flipper length densities (by species & sex) in Palmer penguins\")\nggplot(penguins, aes(x = flipper_length_mm, fill = species)) +\n  geom_density(alpha = 0.5) + facet_grid(sex ~ .) +\n  labs(x = \"Flipper length (mm)\", y = \"Density\", fill = \"Species\",\n       title = \"Flipper length densities (by species & sex) in Palmer penguins\")\nggplot(penguins, aes(y = flipper_length_mm, fill = sex)) +\n  geom_density(alpha = 0.5) + facet_grid(. ~ species) +\n  labs(x = \"Flipper length (mm)\", y = \"Density\", fill = \"Sex\",\n       title = \"Flipper length densities (by species & sex) in Palmer penguins\")"},{"path":"data-visualization.html","id":"scales","chapter":"6 Data Visualization","heading":"6.6 Scales","text":"Generally, default axes fine, need can modify scale layers. Scales control every aesthetic displayed plot, scales every aesthetic. Aesthetics added plot automatically come scale layer default settings, can replace custom-tuned scale settings adding another scale .Every scale layer following name pattern: scale_aes_type aes type name aesthetic type scale used. example, ’re making density plot set x = flipper_length_mm controlled scale_x_continuous() flipper_length_mm column continuous, numeric type variable. However making bar plot set x = species controlled scale_x_discrete() since species discrete, categorical type variable.also apply aesthetics. set fill = species color = sex default controlled scale_fill_discrete() scale_color_discrete() since discrete. automatic color choosing functions like scale_fill_brewer() scale_color_brewer() use excellent Brewer color palettes, can also set scale_fill_manual() scale_color_manual().tidyverse loaded, try typing scale_ console use autocomplete popup (doesn’t appear automatically, use TAB trigger ) explore different scale layers available. Hover scale function read short summary well scan available arguments. need details, check help page!don’t time go detail every possible scale function; see page scales read help pages particular function info! ’s example scale layers used modify last plot made just faceted species:","code":"\nggplot(penguins, aes(y = flipper_length_mm, fill = sex)) +\n  geom_density(alpha = 0.5) + facet_grid(. ~ species) +\n  ggtitle(\"Flipper length densities (by species & sex) in Palmer penguins sample\") +\n  xlab(\"Density\") + ylab(\"Flipper length (mm)\") +\n  scale_x_continuous(\n    limits = c(0, 0.1),              # set limits\n    breaks = seq(0, 0.08, 0.02),     # set breaks\n    expand = c(0, 0)                 # remove padding (extra spacing at either end)\n    # if you need to transform x, you can also set transform = something (see help!)\n  ) +\n  scale_y_continuous(\n    minor_breaks = seq(170, 230, 2), # set minor breaks\n    expand = c(0, 0)                 # remove padding here as well\n  ) +\n  scale_fill_manual(\n    values = c(\"red\", \"blue\")        # set custom colors, full list of possible names:\n  )                                  # www.stat.columbia.edu/~tzheng/files/Rcolor.pdf"},{"path":"data-visualization.html","id":"other-geoms","chapter":"6 Data Visualization","heading":"6.7 Other geoms","text":"Many geoms exist (see ggplot2 cheat sheet full list). just extremely useful ones know .","code":""},{"path":"data-visualization.html","id":"straight-lines","chapter":"6 Data Visualization","heading":"6.7.1 Straight lines","text":"Sometimes may want draw specific lines annotate plot. can use geom_hline(yintercept = ...), geom_vline(xintercept = ...), geom_abline(slope = ..., intercept = ...) manually draw horizontal, vertical, arbitrary lines top another plot. can also directly set things like color, alpha, linetype, linewidth inside function control style. need multiple lines, can use vector inputs, add multiple layers. example:","code":"\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm,\n                     color = species, shape = species)) +\n  geom_point(size = 2) +\n  geom_hline(yintercept = c(190, 210), color = \"navyblue\", linetype = \"dashed\") +\n  geom_vline(xintercept = 4500, linewidth = 2, alpha = 0.5) +\n  geom_abline(slope = 0.015, intercept = 140, color = \"magenta\", size = 1)"},{"path":"data-visualization.html","id":"functions","chapter":"6 Data Visualization","heading":"6.7.2 Functions","text":"Functions can easily plotted geom_function(fun = ...) ... target function. can added either top existing plot another layer, plotted new plot, case base object ggplot() requires additional arguments.function isn’t predefined, can easily define \\(x) ... example:function exists, need modify arguments, can use args = list(...) arguments specified inside directly passed chose function, example:","code":"\nggplot() + geom_function(\n  fun = \\(x) x^2 + 1,      # define x²+1\n  xlim = c(-2, 2),         # set limits\n  n = 1001                 # increase number of points used in drawing\n)                          # (improves smoothness of resulting curve)\n# plot the normal distribution with mean 10 sd 2\nggplot() + geom_function(\n  fun = dnorm,                     # dnorm() is the normal distribution function\n  args = list(mean = 10, sd = 2),  # set mean and sd arguments inside dnorm()\n  xlim = c(4, 16),                 # set limits\n  n = 1001                         # increase number of points\n)"},{"path":"data-visualization.html","id":"bonus-pairs-plot","chapter":"6 Data Visualization","heading":"6.8 Bonus: pairs plot","text":"didn’t know put ’m inserting end chapter . ’s bonus plot type called pairs plot, every variable data frame plotted every variable. primary purpose plot rapidly orient new dataset ’re just starting explore. ’s usually recommended limit 5-6 variables max pairs plot, lest become chaotic.many different implementations , one best GGally::ggpairs(). plot type automatically determined based variable types can density, histogram, point, bar, box, , additionally summary statistics like correlations given appropriate.plot recommended initial exploratory plot; used purposeful setting like report since lacks direction/focus.","code":"\n# to run this chunk, you need to have the package GGally installed\n# first, we subset out just a few columns (otherwise it gets too crazy)\n# aes(color = species) is optional but improves the plot greatly\npenguins_subset <- penguins[\n  c(\"species\", \"body_mass_g\", \"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\")\n]\nGGally::ggpairs(penguins_subset, aes(color = species))"},{"path":"data-visualization.html","id":"further-readings","chapter":"6 Data Visualization","heading":"6.9 Further readings","text":"beyond scope course, ’s links want learn :haven’t already, make sure check ggplot2 cheat sheet.need help picking plot, Data Viz nice flow chart links example R code.also recommend scanning Data Viz page caveats, .e. common pitfalls data science.can add additional text annotations plots necessary.can also modify coordinate systems, example make polar plots especially effective cyclical directional data.also plot themes can try .’s gallery R plots want learn advanced types plots see examples make .","code":""},{"path":"data-transformation.html","id":"data-transformation","chapter":"Data Transformation","heading":"Data Transformation","text":"next section, learn perform basic data transformation procedures commonly used clean “tidy” data convenient useful format whatever purpose needs serve. loosely broken several sections.First, learn basics dplyr, another core Tidyverse packages, including things like renaming variables, subsetting rows columns, adding editing columns, making summaries., proceed advanced topics like grouping operations, combining different data frames along rows columns, pivoting using tidyr, yet another core Tidyverse package.","code":""},{"path":"intro-to-dplyr.html","id":"intro-to-dplyr","chapter":"7 Intro to dplyr","heading":"7 Intro to dplyr","text":"dplyr core Tidyverse package transforming raw datasets clean usable format (link cheat sheet). functions versatile, performant, consistent user friendly syntax. traits make highly suitable data science levels.","code":"\n# import all core tidyverse packages\nlibrary(tidyverse)\n# optional: change default print to 5 rows to save vertical space, and\n#           disable showing col_types by default in readr import functions\noptions(pillar.print_min = 5, readr.show_col_types = FALSE)\n# optional: change default ggplot theme options (personal preference)\nsource(\"https://bwu62.github.io/stat240-revamp/ggplot_theme_options.R\")"},{"path":"intro-to-dplyr.html","id":"syntax-design","chapter":"7 Intro to dplyr","heading":"7.1 Syntax design","text":"First, think ’s important briefly comment syntax design dplyr avoid confusion later . functions covered chapter satisfy following design principles:Functions dplyr designed work data frames, objects (e.g. vectors).\nrun vector, must first wrapped inside data frame (see section 4.1).\nrun vector, must first wrapped inside data frame (see section 4.1).Functions dplyr able run pipes like %>% |> (soon).Functions dplyr, modify input, must always manually save output.","code":""},{"path":"intro-to-dplyr.html","id":"pipes","chapter":"7 Intro to dplyr","heading":"7.2 Pipes","text":"dplyr functions setup first argument input data frame. words, ’re always run like f(df, ...) f dplyr function, df data frame wish operate , ... can arguments. also applies Tidyverse functions, e.g. recall first argument ggplot() must also data frame.design makes easy chain many functions together pipes %>% |>, basically used pass left-side expression first argument function. class, stick %>% consistency, can use |> prefer. example,x %>% f equivalent f(x)x %>% f(y) equivalent f(x, y)26Why useful? Suppose start data frame df want run functions f, g, h order. can course following:quickly becomes awkward, due many nested parentheticals. much cleaner syntax use %>% pipe df one function next, resulting much cleaner equivalent syntax:much neater also significantly easier modify debug. can also easily specify additional arguments. example, suppose f, g, h need additional arguments = 1, b = 2, c = 3 order. Compare two equivalent syntax options:long function chain accepts data frame first argument outputs data frame result, can string together many functions need perform several data operations single step.magrittr help page additional usage tips %>%, pass left side different argument position, using %>% create simple functions, advanced pipes. outside scope course, read discretion!","code":"h(g(f(df)))df %>% f %>% g %>% hh(g(f(df, a = 1), b = 2), c = 3)df %>% f(a = 1) %>% g(b = 2) %>% g(c = 3)"},{"path":"intro-to-dplyr.html","id":"data-example","chapter":"7 Intro to dplyr","heading":"7.3 Data example","text":"now, ’re going continue using Palmer penguins dataset penguins.csv example data frame. Let’s load data :","code":"\n# load in the familiar penguins dataset\npenguins <- read_csv(\"https://bwu62.github.io/stat240-revamp/data/penguins.csv\")\n# print the first few rows of the data frame to check\n# again this data frame is too wide, and some columns are cut off\nprint(penguins, n = 5)# A tibble: 333 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex   \n  <chr>   <chr>              <dbl>         <dbl>             <dbl>       <dbl> <chr> \n1 Adelie  Torgersen           39.1          18.7               181        3750 male  \n2 Adelie  Torgersen           39.5          17.4               186        3800 female\n3 Adelie  Torgersen           40.3          18                 195        3250 female\n4 Adelie  Torgersen           36.7          19.3               193        3450 female\n5 Adelie  Torgersen           39.3          20.6               190        3650 male  \n# ℹ 328 more rows\n# ℹ 1 more variable: year <dbl>"},{"path":"intro-to-dplyr.html","id":"column-wise-functions","chapter":"7 Intro to dplyr","heading":"7.4 Column-wise functions","text":"begin column-wise dplyr functions, .e. functions primarily focus manipulating columns certain ways. many , 4 important following:select() selecting subset columns work ,rename() renaming columns,mutate() editing adding columns, without reducing number rows,summarize() computing data summaries, often using statistical functions like mean, median, sd, etc. results reducing number rows.","code":""},{"path":"intro-to-dplyr.html","id":"select","chapter":"7 Intro to dplyr","heading":"7.4.1 select()","text":"select() used subset columns data frame often one first operations used loading dataset (remove columns unnecessary analysis).flexible syntax: can use subset either numeric position, name, ranges, exclusion, even using special selector functions. can also used reorder columns. examples:’s worth reminding df %>% select(...) modify original input df, instead effectively makes copy df runs instead. Example:want save result df %>% select(...) must manually save output <-. general, always recommend saving NEW object instead overwriting original object non-destructive (.e. lose data) less likely create code errors later . ’s also easier debug.note applies functions page, .e. modify input, desired changes must always manually saved!","code":"\n# select just species, sex, flipper length, and body mass\npenguins %>%\n  select(species, sex, flipper_length_mm, body_mass_g)# A tibble: 333 × 4\n  species sex    flipper_length_mm body_mass_g\n  <chr>   <chr>              <dbl>       <dbl>\n1 Adelie  male                 181        3750\n2 Adelie  female               186        3800\n3 Adelie  female               195        3250\n4 Adelie  female               193        3450\n5 Adelie  male                 190        3650\n# ℹ 328 more rows\n# note this is syntactically equivalent to the following:\nselect(penguins, species, sex, flipper_length_mm, body_mass_g)# A tibble: 333 × 4\n  species sex    flipper_length_mm body_mass_g\n  <chr>   <chr>              <dbl>       <dbl>\n1 Adelie  male                 181        3750\n2 Adelie  female               186        3800\n3 Adelie  female               195        3250\n4 Adelie  female               193        3450\n5 Adelie  male                 190        3650\n# ℹ 328 more rows\n# you can also select by position, or with a range, or both\n# e.g. we can select the 1st, 3rd to 5th, and year columns:\npenguins %>%\n  select(1, 3:5, year)# A tibble: 333 × 5\n  species bill_length_mm bill_depth_mm flipper_length_mm  year\n  <chr>            <dbl>         <dbl>             <dbl> <dbl>\n1 Adelie            39.1          18.7               181  2007\n2 Adelie            39.5          17.4               186  2007\n3 Adelie            40.3          18                 195  2007\n4 Adelie            36.7          19.3               193  2007\n5 Adelie            39.3          20.6               190  2007\n# ℹ 328 more rows\n# you can also use ranges with names\n# e.g. select from 1st to island, then body mass to last col\npenguins %>%\n  select(1:island, body_mass_g:last_col())# A tibble: 333 × 5\n  species island    body_mass_g sex     year\n  <chr>   <chr>           <dbl> <chr>  <dbl>\n1 Adelie  Torgersen        3750 male    2007\n2 Adelie  Torgersen        3800 female  2007\n3 Adelie  Torgersen        3250 female  2007\n4 Adelie  Torgersen        3450 female  2007\n5 Adelie  Torgersen        3650 male    2007\n# ℹ 328 more rows\n# you can also select by excluding specific columns with !\n# e.g. select everything except island and everything after body mass\npenguins %>%\n  select(-island, -(body_mass_g:last_col()), body_mass_g)# A tibble: 333 × 5\n  species bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  <chr>            <dbl>         <dbl>             <dbl>       <dbl>\n1 Adelie            39.1          18.7               181        3750\n2 Adelie            39.5          17.4               186        3800\n3 Adelie            40.3          18                 195        3250\n4 Adelie            36.7          19.3               193        3450\n5 Adelie            39.3          20.6               190        3650\n# ℹ 328 more rows\n# select with selector functions, see ?starts_with help page for details,\n# you can also use & as AND, | as OR, ! as NOT during selection\n# e.g. get cols that start with \"s\", or end with \"mm\" or \"g\",\n#      but do NOT contain \"length\" anywhere in the name\npenguins %>%\n  select(\n    (starts_with(\"s\") | ends_with(c(\"mm\", \"g\"))) & !contains(\"length\")\n  )# A tibble: 333 × 4\n  species sex    bill_depth_mm body_mass_g\n  <chr>   <chr>          <dbl>       <dbl>\n1 Adelie  male            18.7        3750\n2 Adelie  female          17.4        3800\n3 Adelie  female          18          3250\n4 Adelie  female          19.3        3450\n5 Adelie  male            20.6        3650\n# ℹ 328 more rows\n# notice in all examples above, columns are always returned in order\n# select() can therefore also be used to reorder columns\n# e.g. move year, island, species, sex cols in front of everything else\n#      (here, everything() selects all the other cols in original order)\npenguins %>%\n  select(year, island, species, sex, everything())# A tibble: 333 × 8\n   year island    species sex    bill_length_mm bill_depth_mm flipper_length_mm\n  <dbl> <chr>     <chr>   <chr>           <dbl>         <dbl>             <dbl>\n1  2007 Torgersen Adelie  male             39.1          18.7               181\n2  2007 Torgersen Adelie  female           39.5          17.4               186\n3  2007 Torgersen Adelie  female           40.3          18                 195\n4  2007 Torgersen Adelie  female           36.7          19.3               193\n5  2007 Torgersen Adelie  male             39.3          20.6               190\n# ℹ 328 more rows\n# ℹ 1 more variable: body_mass_g <dbl>\n# show starting data frame\nprint(penguins)# A tibble: 333 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex   \n  <chr>   <chr>              <dbl>         <dbl>             <dbl>       <dbl> <chr> \n1 Adelie  Torgersen           39.1          18.7               181        3750 male  \n2 Adelie  Torgersen           39.5          17.4               186        3800 female\n3 Adelie  Torgersen           40.3          18                 195        3250 female\n4 Adelie  Torgersen           36.7          19.3               193        3450 female\n5 Adelie  Torgersen           39.3          20.6               190        3650 male  \n# ℹ 328 more rows\n# ℹ 1 more variable: year <dbl>\n# select a subset of columns\npenguins %>% select(species, flipper_length_mm)# A tibble: 333 × 2\n  species flipper_length_mm\n  <chr>               <dbl>\n1 Adelie                181\n2 Adelie                186\n3 Adelie                195\n4 Adelie                193\n5 Adelie                190\n# ℹ 328 more rows\n# check original input is unchanged\nprint(penguins)# A tibble: 333 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex   \n  <chr>   <chr>              <dbl>         <dbl>             <dbl>       <dbl> <chr> \n1 Adelie  Torgersen           39.1          18.7               181        3750 male  \n2 Adelie  Torgersen           39.5          17.4               186        3800 female\n3 Adelie  Torgersen           40.3          18                 195        3250 female\n4 Adelie  Torgersen           36.7          19.3               193        3450 female\n5 Adelie  Torgersen           39.3          20.6               190        3650 male  \n# ℹ 328 more rows\n# ℹ 1 more variable: year <dbl>\n# saving to a new object with a descriptive name is ALWAYS recommended!\npenguins_fewcols <- penguins %>% select(species, flipper_length_mm)\nprint(penguins_fewcols)# A tibble: 333 × 2\n  species flipper_length_mm\n  <chr>               <dbl>\n1 Adelie                181\n2 Adelie                186\n3 Adelie                195\n4 Adelie                193\n5 Adelie                190\n# ℹ 328 more rows\n# overwriting the original input is STRONGLY discouraged\n# because it's destructive and often causes problems later\npenguins <- penguins %>% select(species, flipper_length_mm)\nprint(penguins)# A tibble: 333 × 2\n  species flipper_length_mm\n  <chr>               <dbl>\n1 Adelie                181\n2 Adelie                186\n3 Adelie                195\n4 Adelie                193\n5 Adelie                190\n# ℹ 328 more rows\n# reload data frame since we need it for other examples\npenguins <- read_csv(\"https://bwu62.github.io/stat240-revamp/data/penguins.csv\")"},{"path":"intro-to-dplyr.html","id":"rename","chapter":"7 Intro to dplyr","heading":"7.4.2 rename()","text":"rename() used rename columns. another common operation right loading dataset. Examples:outside scope, can also apply function many/columns using rename_with(). example:","code":"\n# rename species as species_name, and island as island_name\npenguins %>%\n  rename(species_name = species, island_name = island)# A tibble: 333 × 8\n  species_name island_name bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  <chr>        <chr>                <dbl>         <dbl>             <dbl>       <dbl>\n1 Adelie       Torgersen             39.1          18.7               181        3750\n2 Adelie       Torgersen             39.5          17.4               186        3800\n3 Adelie       Torgersen             40.3          18                 195        3250\n4 Adelie       Torgersen             36.7          19.3               193        3450\n5 Adelie       Torgersen             39.3          20.6               190        3650\n# ℹ 328 more rows\n# ℹ 2 more variables: sex <chr>, year <dbl>\n# if you want to use irregular names, i.e. names with spaces or symbols,\n# you must surround them with \" \" quotes\npenguins %>%\n  rename(\"Bill Length (mm)\" = bill_length_mm)# A tibble: 333 × 8\n  species island `Bill Length (mm)` bill_depth_mm flipper_length_mm body_mass_g sex  \n  <chr>   <chr>               <dbl>         <dbl>             <dbl>       <dbl> <chr>\n1 Adelie  Torge…               39.1          18.7               181        3750 male \n2 Adelie  Torge…               39.5          17.4               186        3800 fema…\n3 Adelie  Torge…               40.3          18                 195        3250 fema…\n4 Adelie  Torge…               36.7          19.3               193        3450 fema…\n5 Adelie  Torge…               39.3          20.6               190        3650 male \n# ℹ 328 more rows\n# ℹ 1 more variable: year <dbl>\n# if you have a data frame with an extremely long and awkward name,\n# you can also use selector functions to help you rename it\n# (see ?starts_with help page for more details/examples)\ndf_badname <- tibble(\n  x = 1:3,\n  \"Really long (and awkward) name with !@#$% symbols\" = 4:6\n)\ndf_badname# A tibble: 3 × 2\n      x `Really long (and awkward) name with !@#$% symbols`\n  <int>                                               <int>\n1     1                                                   4\n2     2                                                   5\n3     3                                                   6\ndf_badname %>%\n  rename(y = starts_with(\"Really\") & ends_with(\"symbols\"))# A tibble: 3 × 2\n      x     y\n  <int> <int>\n1     1     4\n2     2     5\n3     3     6\npenguins %>%\n  rename_with(toupper)# A tibble: 333 × 8\n  SPECIES ISLAND    BILL_LENGTH_MM BILL_DEPTH_MM FLIPPER_LENGTH_MM BODY_MASS_G SEX   \n  <chr>   <chr>              <dbl>         <dbl>             <dbl>       <dbl> <chr> \n1 Adelie  Torgersen           39.1          18.7               181        3750 male  \n2 Adelie  Torgersen           39.5          17.4               186        3800 female\n3 Adelie  Torgersen           40.3          18                 195        3250 female\n4 Adelie  Torgersen           36.7          19.3               193        3450 female\n5 Adelie  Torgersen           39.3          20.6               190        3650 male  \n# ℹ 328 more rows\n# ℹ 1 more variable: YEAR <dbl>"},{"path":"intro-to-dplyr.html","id":"mutate","chapter":"7 Intro to dplyr","heading":"7.4.3 mutate()","text":"mutate() used either change existing column, add new columns. ’s easy function introduce tough one master. basic syntax df %>% mutate(col1 = expr1, col2 = expr2, ...) col1, col2, … columns changed/added (depending already exists) expr1, expr2, … R expressions.key thing remember expressions can vector computation using one columns data frame produces vector length single value (gets recycled).convenience, let’s select just columns continue demonstration:Now, ’s example applications mutate() using penguins2A notable function extremely useful inside mutate() case_when() can calculate different values depending certain conditions.27 basic syntax df %>% mutate(new_col = case_when(cond1 ~ expr1, cond2 ~ expr2, ...)) cond1, cond2, … logical condition vectors checked one one given order, expr1, expr2, … R expressions activated condition matches.example, suppose want create new column differently depending sex bill depth:’s worth restating vectorized operation columns can used inside mutate(), long result -length vector (single value recycled). includes essentially every function chapter 3!dplyr cheat sheet page 2 small list functions may useful inside mutate() advanced situations, cumsum() finding cumulative sums columns (.e. “running” sum), lag() lead() creating lagged leading vector useful computing changes time series data, na_if() selectively replacing specific values NA, several ranking functions like dense_rank() min_rank(), many .","code":"\npenguins2 <- penguins %>%\n  select(species, sex, bill_length_mm, bill_depth_mm)\nprint(penguins2)# A tibble: 333 × 4\n  species sex    bill_length_mm bill_depth_mm\n  <chr>   <chr>           <dbl>         <dbl>\n1 Adelie  male             39.1          18.7\n2 Adelie  female           39.5          17.4\n3 Adelie  female           40.3          18  \n4 Adelie  female           36.7          19.3\n5 Adelie  male             39.3          20.6\n# ℹ 328 more rows\n# we can easily add columns of constants\npenguins2 %>%\n  mutate(study = \"Palmer\", century = 21, true = TRUE)# A tibble: 333 × 7\n  species sex    bill_length_mm bill_depth_mm study  century true \n  <chr>   <chr>           <dbl>         <dbl> <chr>    <dbl> <lgl>\n1 Adelie  male             39.1          18.7 Palmer      21 TRUE \n2 Adelie  female           39.5          17.4 Palmer      21 TRUE \n3 Adelie  female           40.3          18   Palmer      21 TRUE \n4 Adelie  female           36.7          19.3 Palmer      21 TRUE \n5 Adelie  male             39.3          20.6 Palmer      21 TRUE \n# ℹ 328 more rows\n# we can also change existing columns using the same syntax,\n# e.g. we can capitalize and abbreviate sex to M and F\npenguins2 %>%\n  mutate(sex = substr(toupper(sex), 1, 1))# A tibble: 333 × 4\n  species sex   bill_length_mm bill_depth_mm\n  <chr>   <chr>          <dbl>         <dbl>\n1 Adelie  M               39.1          18.7\n2 Adelie  F               39.5          17.4\n3 Adelie  F               40.3          18  \n4 Adelie  F               36.7          19.3\n5 Adelie  M               39.3          20.6\n# ℹ 328 more rows\n# we can also use multiple columns in expressions\n# e.g. we can roughly estimate the volume of each bill,\n# see: https://allisonhorst.github.io/palmerpenguins/#bill-dimensions\npenguins2 %>%\n  mutate(bill_vol_mm3 = pi * (bill_depth_mm / 2)^2 * bill_length_mm)# A tibble: 333 × 5\n  species sex    bill_length_mm bill_depth_mm bill_vol_mm3\n  <chr>   <chr>           <dbl>         <dbl>        <dbl>\n1 Adelie  male             39.1          18.7       10739.\n2 Adelie  female           39.5          17.4        9393.\n3 Adelie  female           40.3          18         10255.\n4 Adelie  female           36.7          19.3       10737.\n5 Adelie  male             39.3          20.6       13098.\n# ℹ 328 more rows\n# you can also break this into steps, using intermediate variables\n# note intermediate variables can be used immediately in the same mutate() call\npenguins2 %>% mutate(\n  bill_cross_section_mm2 = pi * (bill_depth_mm / 2)^2,\n  bill_vol_mm3           = bill_cross_section_mm2 * bill_length_mm\n)# A tibble: 333 × 6\n  species sex    bill_length_mm bill_depth_mm bill_cross_section_mm2 bill_vol_mm3\n  <chr>   <chr>           <dbl>         <dbl>                  <dbl>        <dbl>\n1 Adelie  male             39.1          18.7                   275.       10739.\n2 Adelie  female           39.5          17.4                   238.        9393.\n3 Adelie  female           40.3          18                     254.       10255.\n4 Adelie  female           36.7          19.3                   293.       10737.\n5 Adelie  male             39.3          20.6                   333.       13098.\n# ℹ 328 more rows\n# you can even mix summary functions into your expression\n# e.g. standardize bill length and depth by subtracting mean and dividing by sd\npenguins2 %>% mutate(\n  bill_length_std = (bill_length_mm - mean(bill_length_mm)) / sd(bill_length_mm),\n  bill_depth_std  = (bill_depth_mm - mean(bill_depth_mm)) / sd(bill_depth_mm)\n)# A tibble: 333 × 6\n  species sex    bill_length_mm bill_depth_mm bill_length_std bill_depth_std\n  <chr>   <chr>           <dbl>         <dbl>           <dbl>          <dbl>\n1 Adelie  male             39.1          18.7          -0.895          0.780\n2 Adelie  female           39.5          17.4          -0.822          0.119\n3 Adelie  female           40.3          18            -0.675          0.424\n4 Adelie  female           36.7          19.3          -1.33           1.08 \n5 Adelie  male             39.3          20.6          -0.858          1.74 \n# ℹ 328 more rows\n# you can of course create columns of other data types\npenguins2 %>% mutate(\n  small_bill = bill_length_mm < 39 | bill_depth_mm < 18,\n  fake_dates = seq(today(), today() + nrow(penguins) - 1, by = 1)\n)# A tibble: 333 × 6\n  species sex    bill_length_mm bill_depth_mm small_bill fake_dates\n  <chr>   <chr>           <dbl>         <dbl> <lgl>      <date>    \n1 Adelie  male             39.1          18.7 FALSE      2024-09-28\n2 Adelie  female           39.5          17.4 TRUE       2024-09-29\n3 Adelie  female           40.3          18   FALSE      2024-09-30\n4 Adelie  female           36.7          19.3 TRUE       2024-10-01\n5 Adelie  male             39.3          20.6 FALSE      2024-10-02\n# ℹ 328 more rows\n# use case_when() inside a mutate() depending on some conditions\n# .default sets the \"default\" result, when no conditions match OR when we have NAs\npenguins2 %>% mutate(\n  new_col = case_when(\n    sex == \"male\" & bill_depth_mm <= 19 ~ bill_length_mm * 100,\n    sex == \"male\" & bill_depth_mm > 19 ~ bill_length_mm * -1,\n    sex == \"female\" ~ round(log((bill_length_mm / bill_depth_mm)^2), 2),\n    .default = 0\n  )\n)# A tibble: 333 × 5\n  species sex    bill_length_mm bill_depth_mm new_col\n  <chr>   <chr>           <dbl>         <dbl>   <dbl>\n1 Adelie  male             39.1          18.7 3910   \n2 Adelie  female           39.5          17.4    1.64\n3 Adelie  female           40.3          18      1.61\n4 Adelie  female           36.7          19.3    1.29\n5 Adelie  male             39.3          20.6  -39.3 \n# ℹ 328 more rows"},{"path":"intro-to-dplyr.html","id":"summarize","chapter":"7 Intro to dplyr","heading":"7.4.4 summarize()","text":"summarize() similar mutate() except MUST use summary functions, .e. function always reduce vector single value. , can use arbitrary function combination functions columns data frame, result can type (e.g. numeric, character, logical, date, etc.), long result singular.basic syntax df %>% summarize(col1 = expr1, col2 = expr2, ...) col1, col2, … names new summary columns, expr1, expr2, … R expressions reduce single value. Example:last function chunk n() special function takes arguments returns number rows.28A common applications summarize() data exploration:’s also common use summarize() compute statistical results. example can calculate 95% confidence intervals mean bill length depth (ignoring species/sex) something cover detail later course:, think ’s important stress expression involving columns results single value can used inside summarize(). dplyr cheat sheet page 2 examples useful summarizing functions first(), last(), nth() getting first, last, n-th observations group respectively. Feel free read .","code":"\n# let's compute several summary statistics of bill length\npenguins2 %>% summarize(\n  mean_length   = mean(bill_length_mm),\n  median_length = median(bill_length_mm),\n  sd_length     = sd(bill_length_mm),\n  iqr_length    = IQR(bill_length_mm),\n  max_length    = max(bill_length_mm),\n  min_length    = min(bill_length_mm),\n  n             = n()\n)# A tibble: 1 × 7\n  mean_length median_length sd_length iqr_length max_length min_length     n\n        <dbl>         <dbl>     <dbl>      <dbl>      <dbl>      <dbl> <int>\n1        44.0          44.5      5.47        9.1       59.6       32.1   333\n# compute a few other summaries to explore the data\n# note similar to mutate, we can immediately use a summarized column\npenguins2 %>% summarize(\n  n            = n(),\n  n_male       = sum(sex == \"male\"),\n  pct_male     = 100 * n_male / n,\n  n_female     = sum(sex == \"female\"),\n  pct_female   = 100 * n_female / n,\n  pct_NA       = 100 * mean(\n    is.na(species) | is.na(sex) | is.na(bill_length_mm) | is.na(bill_depth_mm)\n  ), # get proportion of rows with NA (mean of logicals gives proportion of TRUEs)\n  q90_len      = quantile(bill_length_mm, 0.90),\n  pmed_len     = mean(bill_length_mm <= median(bill_length_mm)),\n  correlation  = cor(bill_length_mm, bill_depth_mm)\n)# A tibble: 1 × 9\n      n n_male pct_male n_female pct_female pct_NA q90_len pmed_len correlation\n  <int>  <int>    <dbl>    <int>      <dbl>  <dbl>   <dbl>    <dbl>       <dbl>\n1   333    168     50.5      165       49.5      0    50.8    0.502      -0.229\n# we first compute some intermediate statistics,\n# then use those to compute the intervals\npenguins2 %>% summarize(\n  n            = n(),\n  mean_length  = mean(bill_length_mm),\n  sd_length    = sd(bill_length_mm),\n  mean_depth   = mean(bill_depth_mm),\n  sd_depth     = sd(bill_depth_mm),\n  length_95_ci = paste(\n    round(mean_length + c(-1, 1) * 1.96 * sd_length / sqrt(n), 2),\n    collapse = \",\"\n  ),\n  depth_95_ci  = paste(\n    round(mean_depth  + c(-1, 1) * 1.96 * sd_depth  / sqrt(n), 2),\n    collapse = \",\"\n  )\n)# A tibble: 1 × 7\n      n mean_length sd_length mean_depth sd_depth length_95_ci depth_95_ci\n  <int>       <dbl>     <dbl>      <dbl>    <dbl> <chr>        <chr>      \n1   333        44.0      5.47       17.2     1.97 43.41,44.58  16.95,17.38"},{"path":"intro-to-dplyr.html","id":"row-wise-functions","chapter":"7 Intro to dplyr","heading":"7.5 Row-wise functions","text":"Let’s move now row-wise functions, .e. functions primarily focus manipulating rows certain ways. , many , 3 important:filter() filtering rows keep,slice() (plus sibling functions) slicing specific rows,arrange() sorting rows.","code":""},{"path":"intro-to-dplyr.html","id":"filter","chapter":"7 Intro to dplyr","heading":"7.5.1 filter()","text":"filter() used filter rows keep. Note wording ; rows meet conditions KEPT, dropped. frequent point confusion beginners.Similar mutate() summarize(), can filter constructing logical expression using combination columns, long result vector TRUE/FALSE values, one row. end, rows TRUE returned output.Let’s return using original penguins data frame. ’s filtering examples:","code":"\n# filter to get penguins >=6kg\npenguins %>%\n  filter(body_mass_g >= 6000)# A tibble: 4 × 8\n  species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex  \n  <chr>   <chr>           <dbl>         <dbl>             <dbl>       <dbl> <chr>\n1 Gentoo  Biscoe           49.2          15.2               221        6300 male \n2 Gentoo  Biscoe           59.6          17                 230        6050 male \n3 Gentoo  Biscoe           51.1          16.3               220        6000 male \n4 Gentoo  Biscoe           48.8          16.2               222        6000 male \n# ℹ 1 more variable: year <dbl>\n# combining multiple filtering conditions using & and |\npenguins %>% filter(\n  (species == \"Adelie\" | species == \"Gentoo\") &\n    island %in% c(\"Biscoe\", \"Dream\") & year < 2008\n)# A tibble: 62 × 8\n  species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex   \n  <chr>   <chr>           <dbl>         <dbl>             <dbl>       <dbl> <chr> \n1 Adelie  Biscoe           37.8          18.3               174        3400 female\n2 Adelie  Biscoe           37.7          18.7               180        3600 male  \n3 Adelie  Biscoe           35.9          19.2               189        3800 female\n4 Adelie  Biscoe           38.2          18.1               185        3950 male  \n5 Adelie  Biscoe           38.8          17.2               180        3800 male  \n# ℹ 57 more rows\n# ℹ 1 more variable: year <dbl>\n# you can of course use more complex functions and expressions,\n# you can also use , to separate multiple conditions in filter() instead of &\n# e.g. this code gets rows with no \"e\" in the species name, and also\n# bill depth is higher than median but flipper length is lower than median\npenguins %>% filter(\n  !grepl(\"e\", species),\n  bill_depth_mm > median(bill_depth_mm),\n  flipper_length_mm < median(flipper_length_mm)\n)# A tibble: 24 × 8\n  species   island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex   \n  <chr>     <chr>           <dbl>         <dbl>             <dbl>       <dbl> <chr> \n1 Chinstrap Dream            46.5          17.9               192        3500 female\n2 Chinstrap Dream            50            19.5               196        3900 male  \n3 Chinstrap Dream            51.3          19.2               193        3650 male  \n4 Chinstrap Dream            45.4          18.7               188        3525 female\n5 Chinstrap Dream            46.1          18.2               178        3250 female\n# ℹ 19 more rows\n# ℹ 1 more variable: year <dbl>\n# an example of an even more complicated expression,\n# this line gets penguins with body mass and bill length\n# within a 1 SD circle centered around the mean of both,\n# then plots the result to visually inspect\n# note the result df can be directly piped into ggplot()\npenguins %>%\n  filter(\n    ((body_mass_g - mean(body_mass_g)) / sd(body_mass_g))^2 +\n      ((bill_length_mm - mean(bill_length_mm)) / sd(bill_length_mm))^2 <= 1\n  ) %>%\n  ggplot(aes(x = bill_length_mm, y = body_mass_g)) + geom_point() +\n  labs(title = \"Filter demo (points in a 1-SD circle around mean of x,y)\",\n       x = \"Bill length (mm)\", y = \"Body mass (g)\") +\n  coord_fixed(.0067) # make the plot window a square"},{"path":"intro-to-dplyr.html","id":"slice","chapter":"7 Intro to dplyr","heading":"7.5.2 slice()","text":"several slice...() functions dplyr slicing specific rows, similar filter() specialized. main one slice() used select position (.e. row number). Examples:slice_head() slice_tail() specifically slice rows top bottom, either number n proportion prop. Examples:slice_min() slice_max() used slice rows contain min/max values specific variable. example, suppose want get penguin smallest body mass:ties, default tied rows printed, e.g. suppose want 3 penguins longest flipper lengths:looks like 7 different Gentoo penguins tied 2nd place, returned! can disable argument, ’s recommended keep default behavior .can also set prop instead n return percent. E.g. let’s get top 1% penguins bill length:","code":"\n# slice rows 11-15\npenguins %>% slice(11:15)# A tibble: 5 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex   \n  <chr>   <chr>              <dbl>         <dbl>             <dbl>       <dbl> <chr> \n1 Adelie  Torgersen           36.6          17.8               185        3700 female\n2 Adelie  Torgersen           38.7          19                 195        3450 female\n3 Adelie  Torgersen           42.5          20.7               197        4500 male  \n4 Adelie  Torgersen           34.4          18.4               184        3325 female\n5 Adelie  Torgersen           46            21.5               194        4200 male  \n# ℹ 1 more variable: year <dbl>\n# slice every 10th row\npenguins %>% slice(seq(0, nrow(penguins), 10))# A tibble: 33 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex   \n  <chr>   <chr>              <dbl>         <dbl>             <dbl>       <dbl> <chr> \n1 Adelie  Torgersen           34.6          21.1               198        4400 male  \n2 Adelie  Biscoe              38.8          17.2               180        3800 male  \n3 Adelie  Dream               36.4          17                 195        3325 female\n4 Adelie  Dream               37            16.9               185        3000 female\n5 Adelie  Biscoe              41.4          18.6               191        3700 male  \n# ℹ 28 more rows\n# ℹ 1 more variable: year <dbl>\n# remove the first 200 rows\npenguins %>% slice(-(1:200))# A tibble: 133 × 8\n  species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex   \n  <chr>   <chr>           <dbl>         <dbl>             <dbl>       <dbl> <chr> \n1 Gentoo  Biscoe           45            15.4               220        5050 male  \n2 Gentoo  Biscoe           43.8          13.9               208        4300 female\n3 Gentoo  Biscoe           45.5          15                 220        5000 male  \n4 Gentoo  Biscoe           43.2          14.5               208        4450 female\n5 Gentoo  Biscoe           50.4          15.3               224        5550 male  \n# ℹ 128 more rows\n# ℹ 1 more variable: year <dbl>\n# get the first 25 rows\npenguins %>% slice_head(n = 25)# A tibble: 25 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex   \n  <chr>   <chr>              <dbl>         <dbl>             <dbl>       <dbl> <chr> \n1 Adelie  Torgersen           39.1          18.7               181        3750 male  \n2 Adelie  Torgersen           39.5          17.4               186        3800 female\n3 Adelie  Torgersen           40.3          18                 195        3250 female\n4 Adelie  Torgersen           36.7          19.3               193        3450 female\n5 Adelie  Torgersen           39.3          20.6               190        3650 male  \n# ℹ 20 more rows\n# ℹ 1 more variable: year <dbl>\n# get the last 10% of rows\npenguins %>% slice_tail(prop = 0.1)# A tibble: 33 × 8\n  species   island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex   \n  <chr>     <chr>           <dbl>         <dbl>             <dbl>       <dbl> <chr> \n1 Chinstrap Dream            47.5          16.8               199        3900 female\n2 Chinstrap Dream            47.6          18.3               195        3850 female\n3 Chinstrap Dream            52            20.7               210        4800 male  \n4 Chinstrap Dream            46.9          16.6               192        2700 female\n5 Chinstrap Dream            53.5          19.9               205        4500 male  \n# ℹ 28 more rows\n# ℹ 1 more variable: year <dbl>\n# get smallest penguin by mass\npenguins %>% slice_min(body_mass_g, n = 1)# A tibble: 1 × 8\n  species   island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex   \n  <chr>     <chr>           <dbl>         <dbl>             <dbl>       <dbl> <chr> \n1 Chinstrap Dream            46.9          16.6               192        2700 female\n# ℹ 1 more variable: year <dbl>\n# get 3 penguins with longest flippers\npenguins %>% slice_max(flipper_length_mm, n = 3)# A tibble: 8 × 8\n  species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex  \n  <chr>   <chr>           <dbl>         <dbl>             <dbl>       <dbl> <chr>\n1 Gentoo  Biscoe           54.3          15.7               231        5650 male \n2 Gentoo  Biscoe           50            16.3               230        5700 male \n3 Gentoo  Biscoe           59.6          17                 230        6050 male \n4 Gentoo  Biscoe           49.8          16.8               230        5700 male \n5 Gentoo  Biscoe           48.6          16                 230        5800 male \n6 Gentoo  Biscoe           52.1          17                 230        5550 male \n7 Gentoo  Biscoe           51.5          16.3               230        5500 male \n8 Gentoo  Biscoe           55.1          16                 230        5850 male \n# ℹ 1 more variable: year <dbl>\n# get top 1% of penguins by bill length\npenguins %>% slice_max(bill_length_mm, prop = 0.01)# A tibble: 3 × 8\n  species   island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex   \n  <chr>     <chr>           <dbl>         <dbl>             <dbl>       <dbl> <chr> \n1 Gentoo    Biscoe           59.6          17                 230        6050 male  \n2 Chinstrap Dream            58            17.8               181        3700 female\n3 Gentoo    Biscoe           55.9          17                 228        5600 male  \n# ℹ 1 more variable: year <dbl>"},{"path":"intro-to-dplyr.html","id":"arrange","chapter":"7 Intro to dplyr","heading":"7.5.3 arrange()","text":"arrange() used sort rows. Note since sorts rows, change data frame “meaningful” way (generally, order rows/columns considered “meaningful” change). ’s primarily used visual appeal, .e. neater presentation dataset.syntax df %>% arrange(expr1, expr2, ...) expr1, expr2, … can simply column, vector expression using columns data frame (similar mutate() filter()) whose resultant values used sorting rows. important notes:next expression used break ties previous expressions, otherwise ’s ignored! E.g. two rows can sorted expr1, used. However two rows tied expr1, expr2 (exists) used try break tie, . also frequent point confusion beginners.Default order always ascending, .e. small large, Z, earlier later, FALSE TRUE. descending order, wrap expression desc().Rows completely tied may returned order.29Examples arrange():","code":"\n# sort penguins by ascending flipper length\npenguins %>% arrange(flipper_length_mm)# A tibble: 333 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex   \n  <chr>   <chr>              <dbl>         <dbl>             <dbl>       <dbl> <chr> \n1 Adelie  Biscoe              37.9          18.6               172        3150 female\n2 Adelie  Biscoe              37.8          18.3               174        3400 female\n3 Adelie  Torgersen           40.2          17                 176        3450 female\n4 Adelie  Dream               39.5          16.7               178        3250 female\n5 Adelie  Dream               37.2          18.1               178        3900 male  \n# ℹ 328 more rows\n# ℹ 1 more variable: year <dbl>\n# sort penguins by descending flipper length\npenguins %>% arrange(desc(flipper_length_mm))# A tibble: 333 × 8\n  species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex  \n  <chr>   <chr>           <dbl>         <dbl>             <dbl>       <dbl> <chr>\n1 Gentoo  Biscoe           54.3          15.7               231        5650 male \n2 Gentoo  Biscoe           50            16.3               230        5700 male \n3 Gentoo  Biscoe           59.6          17                 230        6050 male \n4 Gentoo  Biscoe           49.8          16.8               230        5700 male \n5 Gentoo  Biscoe           48.6          16                 230        5800 male \n# ℹ 328 more rows\n# ℹ 1 more variable: year <dbl>\n# since mathematical expressions are allowed, this is also equivalent\npenguins %>% arrange(-flipper_length_mm)# A tibble: 333 × 8\n  species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex  \n  <chr>   <chr>           <dbl>         <dbl>             <dbl>       <dbl> <chr>\n1 Gentoo  Biscoe           54.3          15.7               231        5650 male \n2 Gentoo  Biscoe           50            16.3               230        5700 male \n3 Gentoo  Biscoe           59.6          17                 230        6050 male \n4 Gentoo  Biscoe           49.8          16.8               230        5700 male \n5 Gentoo  Biscoe           48.6          16                 230        5800 male \n# ℹ 328 more rows\n# ℹ 1 more variable: year <dbl>\n# sort first by island, then by descending species (if there are ties)\npenguins %>% arrange(island, desc(species))# A tibble: 333 × 8\n  species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex   \n  <chr>   <chr>           <dbl>         <dbl>             <dbl>       <dbl> <chr> \n1 Gentoo  Biscoe           46.1          13.2               211        4500 female\n2 Gentoo  Biscoe           50            16.3               230        5700 male  \n3 Gentoo  Biscoe           48.7          14.1               210        4450 female\n4 Gentoo  Biscoe           50            15.2               218        5700 male  \n5 Gentoo  Biscoe           47.6          14.5               215        5400 male  \n# ℹ 328 more rows\n# ℹ 1 more variable: year <dbl>\n# again, any expression is possible,\n# let's sort first by number of SDs away from mean body mass,\n# then by descending last letter of species name for ties,\n# then by ascending approximate bill volume if there are further ties\npenguins %>% arrange(\n  abs(body_mass_g - mean(body_mass_g)) / sd(body_mass_g),\n  desc(substr(species, nchar(species), nchar(species))),\n  pi * (bill_depth_mm / 2)^2 * bill_length_mm\n)# A tibble: 333 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex   \n  <chr>   <chr>              <dbl>         <dbl>             <dbl>       <dbl> <chr> \n1 Gentoo  Biscoe              45.3          13.8               208        4200 female\n2 Gentoo  Biscoe              45.5          13.9               210        4200 female\n3 Gentoo  Biscoe              45.8          14.6               210        4200 female\n4 Adelie  Torgersen           35.1          19.4               193        4200 male  \n5 Adelie  Torgersen           46            21.5               194        4200 male  \n# ℹ 328 more rows\n# ℹ 1 more variable: year <dbl>"},{"path":"intro-to-dplyr.html","id":"other-row-functions","chapter":"7 Intro to dplyr","heading":"7.5.4 Other row functions","text":"Besides , ’s row operations may sometimes need, distinct() removing duplicates add_row() manually adding new observations. may occasionally show later contexts, now please feel free explore .","code":""},{"path":"intro-to-dplyr.html","id":"missing-values","chapter":"7 Intro to dplyr","heading":"7.6 Missing values","text":"ending chapter, let’s briefly discuss handling missing values, .e. NAs R. Missing values unfortunately common data science usually tricky handle well due many associated pitfalls. briefly discuss missing values theoretical perspective, practical R handling perspective.","code":""},{"path":"intro-to-dplyr.html","id":"why-missing","chapter":"7 Intro to dplyr","heading":"7.6.1 Why missing?","text":"working missing values, ’s important ask : “data missing?” Usually, impossible answer definitively, different observations may missing different reasons.Without getting scope, broadly speaking data can missing either relevant reason relevant reason.30For example, suppose ’m setting weather station several sensors, small budget, buy cheap pressure sensor isn’t properly weather-proofed prone producing NAs rains. NAs missing relevant reason; ’s systematic pattern behind missingness. Since rain pressure closely related, means pattern missingness meaningful, removing NAs add significant bias data.Now, suppose replace different cheap pressure sensor weather-proof just slightly buggy overall, every hour ’s independently 1% chance just randomly read NA. data missing relevant reason, .e. pattern missingness meaningful, can simply remove NAs.working data ALWAYS look pattern NAs ask ’s evidence relevant reason missingness. remove NAs clear pattern, otherwise risk introducing systematic biases analysis results., extremely simplified, sufficient now. general, STAT 240 encounter datasets ’s probably ok drop NA values, assume datasets real world.","code":""},{"path":"intro-to-dplyr.html","id":"nas-in-r","chapter":"7 Intro to dplyr","heading":"7.6.2 NAs in R","text":"Let’s now briefly discuss R techniques handling NAs. First ’s important review difference NA NaN R:NA means absence observation, .e. data point recorded.NaN usually result mathematically invalid operation, like 0/0, 0*Inf, Inf-Inf.\nNote sqrt(-1) log(-1) also return NaN since input type real type. Replace -1 0-1i trigger complex evaluation.\nNote sqrt(-1) log(-1) also return NaN since input type real type. Replace -1 0-1i trigger complex evaluation.Even though ’re exact , NA NaN considered missing R can handled together using operations covered . ’s also worth noting NA \"NA\", .e. string made letters \"N\" \"\"general expressions involving NA result NA output (though notable exceptions, particularly character types).","code":"\n# check if two objects are the exact same\nidentical(NA, NA)[1] TRUE\nidentical(NA, NaN)[1] FALSE\nidentical(NA, \"NA\")[1] FALSE"},{"path":"intro-to-dplyr.html","id":"identifying-nas","chapter":"7 Intro to dplyr","heading":"7.6.3 Identifying NAs","text":"NAs (also NaNs) vector can identified using .na() produces TRUE/FALSE vector corresponding value NA :Since ordinary vectorized function, can used inside compatible dplyr function , mutate(), summarize(), filter(), arrange(). demonstrate , let’s create demo data frame mix data types well missing values.common rudimentary checking missingness aforementioned summary() function section 4.3.1. Note base R summary(), Tidyverse summarize() just covered . Note however reports NAs columns, depending type.better way pipe summarize() use .na() either sum() count mean() proportion missing values. can also add ! front .na() get count/proportion non-missing values. 4 combinations shown :just want apply one function columns, can use summarize_all() shortcut exactly . example, can apply function \\(x) mean(.na(x))*100 get percent missing column:check help page summarize_all() ’ll notice function tagged  basically means can keep using , ’s new recommended alternative syntax.31 function, new recommendation use across() instead, bit outside scope, read discretion.course can also use filter() inspect rows missing values () columns. Examples:One thing, notice ’s actually another form missingness df.demo? data frame appears contain daily observations, \"2024-01-05\" appears missing completely data frame. sneaky situation data missing existing data frame completely surprisingly common can sometimes hard identify (since ’s NAs date column detect).One easy way fix use complete() full_seq() tidyr, yet another core Tidyverse package. combination can used generate complete() data frame generating full_seq()–uence values specified column. columns filled NAs default. Example:","code":"\n# demo missing vector, note both NA/NaN count as missing\nx <- c(3, 8, NA, 2, NaN)\n# which values are NA?\nis.na(x)[1] FALSE FALSE  TRUE FALSE  TRUE\n# get only non-NA values\nx[!is.na(x)][1] 3 8 2\n# demo data frame with missing values\ndf.demo <- tibble(\n  date = ymd(\"24.1.1\") + c(0:3, 5),\n  x = c(NA, rep(c(\"A\", \"B\"), 2)),\n  y = c(NA, 1, 2, NA, 3),\n  z = c(NA, TRUE, FALSE, NA, NA)\n)\ndf.demo# A tibble: 5 × 4\n  date       x         y z    \n  <date>     <chr> <dbl> <lgl>\n1 2024-01-01 <NA>     NA NA   \n2 2024-01-02 A         1 TRUE \n3 2024-01-03 B         2 FALSE\n4 2024-01-04 A        NA NA   \n5 2024-01-06 B         3 NA   \nsummary(df.demo)      date                 x                   y           z          \n Min.   :2024-01-01   Length:5           Min.   :1.0   Mode :logical  \n 1st Qu.:2024-01-02   Class :character   1st Qu.:1.5   FALSE:1        \n Median :2024-01-03   Mode  :character   Median :2.0   TRUE :1        \n Mean   :2024-01-03                      Mean   :2.0   NA's :3        \n 3rd Qu.:2024-01-04                      3rd Qu.:2.5                  \n Max.   :2024-01-06                      Max.   :3.0                  \n                                         NA's   :2                    \n# get the count/proportion of missing/non-missing values\ndf.demo %>% summarize(\n  num_date_na   = sum(is.na(date)),\n  prop_x_na     = mean(is.na(x)),\n  num_y_not_na  = sum(!is.na(y)),\n  prop_z_not_na = mean(!is.na(z)),\n  nrows         = n() # add number of rows for convenience\n)# A tibble: 1 × 5\n  num_date_na prop_x_na num_y_not_na prop_z_not_na nrows\n        <int>     <dbl>        <int>         <dbl> <int>\n1           0       0.2            3           0.4     5\n# get percent missing in each column\ndf.demo %>% summarize_all(\\(x) mean(is.na(x)) * 100)# A tibble: 1 × 4\n   date     x     y     z\n  <dbl> <dbl> <dbl> <dbl>\n1     0    20    40    60\n# get rows with missing x\ndf.demo %>% filter(is.na(x))# A tibble: 1 × 4\n  date       x         y z    \n  <date>     <chr> <dbl> <lgl>\n1 2024-01-01 <NA>     NA NA   \n# get rows with missing x or y\ndf.demo %>% filter(is.na(x) | is.na(y))# A tibble: 2 × 4\n  date       x         y z    \n  <date>     <chr> <dbl> <lgl>\n1 2024-01-01 <NA>     NA NA   \n2 2024-01-04 A        NA NA   \n# get rows where y is missing but x is NOT missing\ndf.demo %>% filter(is.na(y) & !is.na(x))# A tibble: 1 × 4\n  date       x         y z    \n  <date>     <chr> <dbl> <lgl>\n1 2024-01-04 A        NA NA   \n# get rows where ANY variable is missing\n# this uses if_any() which checks if any given cols satisfy a condition\ndf.demo %>% filter(if_any(everything(), is.na))# A tibble: 3 × 4\n  date       x         y z    \n  <date>     <chr> <dbl> <lgl>\n1 2024-01-01 <NA>     NA NA   \n2 2024-01-04 A        NA NA   \n3 2024-01-06 B         3 NA   \n# this generates a full sequence of dates\n# the argument 1 indicates the sequence increases by 1 each observation\ndf.demo %>% complete(date = full_seq(date, 1))# A tibble: 6 × 4\n  date       x         y z    \n  <date>     <chr> <dbl> <lgl>\n1 2024-01-01 <NA>     NA NA   \n2 2024-01-02 A         1 TRUE \n3 2024-01-03 B         2 FALSE\n4 2024-01-04 A        NA NA   \n5 2024-01-05 <NA>     NA NA   \n6 2024-01-06 B         3 NA   \n# to show ONLY rows that were added using this operation,\n# we can first create a dummy column filled with some value,\n# complete the data frame, then filter to where the dummy column is NA\ndf.demo %>%\n  mutate(preexisting = TRUE) %>%\n  complete(date = full_seq(date, 1)) %>%\n  filter(is.na(preexisting))# A tibble: 1 × 5\n  date       x         y z     preexisting\n  <date>     <chr> <dbl> <lgl> <lgl>      \n1 2024-01-05 <NA>     NA NA    NA         "},{"path":"intro-to-dplyr.html","id":"dropping-nas","chapter":"7 Intro to dplyr","heading":"7.6.4 Dropping NAs","text":"mentioned , limited scope class, usually rows NAs can just dropped simplicity. easiest way use drop_na(col1, col2, ...) col1, col2, … columns care dropping NAs . left empty, drop_na() drop rows column contains NA. Examples:Make sure drop NAs absolutely necessary; avoid -dropping! E.g. suppose want use x y analysis. drop rows z missing since probably won’t impede work.another common pitfall students. general extremely “lazy” dropping, .e. use drop_na() absolutely necessary .","code":"\n# drop only rows where x is missing\ndf.demo %>% drop_na(x)# A tibble: 4 × 4\n  date       x         y z    \n  <date>     <chr> <dbl> <lgl>\n1 2024-01-02 A         1 TRUE \n2 2024-01-03 B         2 FALSE\n3 2024-01-04 A        NA NA   \n4 2024-01-06 B         3 NA   \n# drop rows where x and y are missing\ndf.demo %>% drop_na(x, y)# A tibble: 3 × 4\n  date       x         y z    \n  <date>     <chr> <dbl> <lgl>\n1 2024-01-02 A         1 TRUE \n2 2024-01-03 B         2 FALSE\n3 2024-01-06 B         3 NA   \n# drop rows where ANY values are missing\ndf.demo %>% drop_na()# A tibble: 2 × 4\n  date       x         y z    \n  <date>     <chr> <dbl> <lgl>\n1 2024-01-02 A         1 TRUE \n2 2024-01-03 B         2 FALSE"},{"path":"intro-to-dplyr.html","id":"replacing-nas","chapter":"7 Intro to dplyr","heading":"7.6.5 Replacing NAs","text":"rare circumstances, may want replace NAs values. course can kind conditional replacement using mutate() case_when(), can also use mutate() specialized tidyr function replace_na(). Examples :datasets, NAs may coded using certain obviously invalid values, e.g. -9999. can course also mutated using case_when(), ’s special function na_if() just purpose:","code":"\n# suppose we need to replace NAs in y column with 0\n# using mutate and case_when:\ndf.demo %>% mutate(\n  y = case_when(\n    is.na(y) ~ 0,\n    .default = y\n  )\n)# A tibble: 5 × 4\n  date       x         y z    \n  <date>     <chr> <dbl> <lgl>\n1 2024-01-01 <NA>      0 NA   \n2 2024-01-02 A         1 TRUE \n3 2024-01-03 B         2 FALSE\n4 2024-01-04 A         0 NA   \n5 2024-01-06 B         3 NA   \n# same thing but using replace_na instead of case_when:\ndf.demo %>% mutate(y = replace_na(y, 0))# A tibble: 5 × 4\n  date       x         y z    \n  <date>     <chr> <dbl> <lgl>\n1 2024-01-01 <NA>      0 NA   \n2 2024-01-02 A         1 TRUE \n3 2024-01-03 B         2 FALSE\n4 2024-01-04 A         0 NA   \n5 2024-01-06 B         3 NA   \ndf.demo <- df.demo %>% mutate(w = c(-9999, -9999, 20, 30, -9999))\ndf.demo# A tibble: 5 × 5\n  date       x         y z         w\n  <date>     <chr> <dbl> <lgl> <dbl>\n1 2024-01-01 <NA>     NA NA    -9999\n2 2024-01-02 A         1 TRUE  -9999\n3 2024-01-03 B         2 FALSE    20\n4 2024-01-04 A        NA NA       30\n5 2024-01-06 B         3 NA    -9999\ndf.demo %>% mutate(w = na_if(w, -9999))# A tibble: 5 × 5\n  date       x         y z         w\n  <date>     <chr> <dbl> <lgl> <dbl>\n1 2024-01-01 <NA>     NA NA       NA\n2 2024-01-02 A         1 TRUE     NA\n3 2024-01-03 B         2 FALSE    20\n4 2024-01-04 A        NA NA       30\n5 2024-01-06 B         3 NA       NA"},{"path":"advanced-operations.html","id":"advanced-operations","chapter":"8 Advanced Operations","heading":"8 Advanced Operations","text":"chapter, cover advanced, yet incredibly useful data tidying operations like grouping, joining, binding, pivoting. Along way, also make extensive use dplyr functions learned previous chapter.","code":""},{"path":"advanced-operations.html","id":"grouping","chapter":"8 Advanced Operations","heading":"8.1 Grouping","text":"Often, need apply dplyr’s various operations like mutate(), summarize(), slicing function across entire dataset groups. important technique across data science, whether ’s data cleaning exploration visualization modeling.default, data frames grouped created imported. can create grouping structure group_by() function. basic syntax df %>% group_by(col1, col2, ...) col1, col2, … variables whose values used determine groups. can group just 1 variable, 2 variables, many variables needed. Rows values chosen columns grouped together.grouping, operations normally run across rows now run across group. ’s simple examples using familiar penguins dataset start:","code":"\n# import tidyverse, import magrittr (for extra %T>% pipe),\n# tweak some readr/ggplot options (optional), and load dataset\nlibrary(tidyverse)\nlibrary(magrittr)\noptions(readr.show_col_types = FALSE)\nsource(\"https://bwu62.github.io/stat240-revamp/ggplot_theme_options.R\")\npenguins <- read_csv(\"https://bwu62.github.io/stat240-revamp/data/penguins.csv\")\n# group by species and get mean/median/sd body mass + sample size of each group\npenguins %>%\n  group_by(species) %>%\n  summarize(\n    mean_mass   = mean(body_mass_g),\n    median_mass = median(body_mass_g),\n    sd_mass     = sd(body_mass_g),\n    n           = n()\n  )# A tibble: 3 × 5\n  species   mean_mass median_mass sd_mass     n\n  <chr>         <dbl>       <dbl>   <dbl> <int>\n1 Adelie        3706.        3700    459.   146\n2 Chinstrap     3733.        3700    384.    68\n3 Gentoo        5092.        5050    501.   119\n# we can also group by multiple, e.g. group by spcies + sex\npenguins %>%\n  group_by(species, sex) %>%\n  summarize(\n    mean_mass   = mean(body_mass_g),\n    median_mass = median(body_mass_g),\n    sd_mass     = sd(body_mass_g),\n    n           = n()\n  )# A tibble: 6 × 6\n# Groups:   species [3]\n  species   sex    mean_mass median_mass sd_mass     n\n  <chr>     <chr>      <dbl>       <dbl>   <dbl> <int>\n1 Adelie    female     3369.        3400    269.    73\n2 Adelie    male       4043.        4000    347.    73\n3 Chinstrap female     3527.        3550    285.    34\n4 Chinstrap male       3939.        3950    362.    34\n5 Gentoo    female     4680.        4700    282.    58\n6 Gentoo    male       5485.        5500    313.    61\n# we can of course also mutate within groups\n# e.g. convert bill length in mm to number of SDs\n#      away from species group mean\n# to better show the result, I'm forcing it to print all rows in order\n# but hiding the output in a collapsible box for style\npenguins %>%\n  select(species, sex, bill_length_mm) %>%\n  group_by(species) %>%\n  mutate(\n    n = n(),\n    bill_length_std = (bill_length_mm - mean(bill_length_mm)) / sd(bill_length_mm)\n  ) %>%\n  arrange(species, bill_length_std) %>%\n  print(n = Inf)# A tibble: 333 × 5\n# Groups:   species [3]\n    species   sex    bill_length_mm     n bill_length_std\n    <chr>     <chr>           <dbl> <int>           <dbl>\n  1 Adelie    female           32.1   146        -2.53   \n  2 Adelie    female           33.1   146        -2.15   \n  3 Adelie    female           33.5   146        -2.00   \n  4 Adelie    female           34     146        -1.81   \n  5 Adelie    female           34.4   146        -1.66   \n  6 Adelie    female           34.5   146        -1.62   \n  7 Adelie    male             34.6   146        -1.59   \n  8 Adelie    female           34.6   146        -1.59   \n  9 Adelie    female           35     146        -1.44   \n 10 Adelie    female           35     146        -1.44   \n 11 Adelie    male             35.1   146        -1.40   \n 12 Adelie    female           35.2   146        -1.36   \n 13 Adelie    female           35.3   146        -1.32   \n 14 Adelie    female           35.5   146        -1.25   \n 15 Adelie    female           35.5   146        -1.25   \n 16 Adelie    female           35.6   146        -1.21   \n 17 Adelie    female           35.7   146        -1.17   \n 18 Adelie    female           35.7   146        -1.17   \n 19 Adelie    female           35.7   146        -1.17   \n 20 Adelie    female           35.9   146        -1.10   \n 21 Adelie    female           35.9   146        -1.10   \n 22 Adelie    female           36     146        -1.06   \n 23 Adelie    female           36     146        -1.06   \n 24 Adelie    female           36     146        -1.06   \n 25 Adelie    female           36     146        -1.06   \n 26 Adelie    female           36.2   146        -0.985  \n 27 Adelie    female           36.2   146        -0.985  \n 28 Adelie    female           36.2   146        -0.985  \n 29 Adelie    male             36.3   146        -0.948  \n 30 Adelie    female           36.4   146        -0.910  \n 31 Adelie    female           36.4   146        -0.910  \n 32 Adelie    female           36.5   146        -0.873  \n 33 Adelie    female           36.5   146        -0.873  \n 34 Adelie    female           36.6   146        -0.835  \n 35 Adelie    female           36.6   146        -0.835  \n 36 Adelie    female           36.7   146        -0.798  \n 37 Adelie    female           36.7   146        -0.798  \n 38 Adelie    female           36.8   146        -0.760  \n 39 Adelie    female           36.9   146        -0.723  \n 40 Adelie    female           37     146        -0.685  \n 41 Adelie    female           37     146        -0.685  \n 42 Adelie    male             37.2   146        -0.610  \n 43 Adelie    male             37.2   146        -0.610  \n 44 Adelie    female           37.3   146        -0.572  \n 45 Adelie    male             37.3   146        -0.572  \n 46 Adelie    female           37.3   146        -0.572  \n 47 Adelie    male             37.5   146        -0.497  \n 48 Adelie    female           37.6   146        -0.460  \n 49 Adelie    male             37.6   146        -0.460  \n 50 Adelie    female           37.6   146        -0.460  \n 51 Adelie    male             37.7   146        -0.422  \n 52 Adelie    female           37.7   146        -0.422  \n 53 Adelie    male             37.7   146        -0.422  \n 54 Adelie    female           37.8   146        -0.385  \n 55 Adelie    male             37.8   146        -0.385  \n 56 Adelie    male             37.8   146        -0.385  \n 57 Adelie    female           37.9   146        -0.347  \n 58 Adelie    female           37.9   146        -0.347  \n 59 Adelie    female           38.1   146        -0.272  \n 60 Adelie    female           38.1   146        -0.272  \n 61 Adelie    female           38.1   146        -0.272  \n 62 Adelie    female           38.1   146        -0.272  \n 63 Adelie    male             38.2   146        -0.234  \n 64 Adelie    male             38.2   146        -0.234  \n 65 Adelie    male             38.3   146        -0.197  \n 66 Adelie    female           38.5   146        -0.122  \n 67 Adelie    male             38.6   146        -0.0841 \n 68 Adelie    female           38.6   146        -0.0841 \n 69 Adelie    female           38.6   146        -0.0841 \n 70 Adelie    female           38.7   146        -0.0466 \n 71 Adelie    male             38.8   146        -0.00900\n 72 Adelie    male             38.8   146        -0.00900\n 73 Adelie    female           38.8   146        -0.00900\n 74 Adelie    female           38.9   146         0.0286 \n 75 Adelie    female           38.9   146         0.0286 \n 76 Adelie    female           39     146         0.0661 \n 77 Adelie    female           39     146         0.0661 \n 78 Adelie    male             39     146         0.0661 \n 79 Adelie    male             39.1   146         0.104  \n 80 Adelie    male             39.2   146         0.141  \n 81 Adelie    male             39.2   146         0.141  \n 82 Adelie    male             39.2   146         0.141  \n 83 Adelie    male             39.3   146         0.179  \n 84 Adelie    female           39.5   146         0.254  \n 85 Adelie    female           39.5   146         0.254  \n 86 Adelie    female           39.5   146         0.254  \n 87 Adelie    male             39.6   146         0.291  \n 88 Adelie    female           39.6   146         0.291  \n 89 Adelie    female           39.6   146         0.291  \n 90 Adelie    male             39.6   146         0.291  \n 91 Adelie    female           39.6   146         0.291  \n 92 Adelie    male             39.7   146         0.329  \n 93 Adelie    male             39.7   146         0.329  \n 94 Adelie    female           39.7   146         0.329  \n 95 Adelie    male             39.7   146         0.329  \n 96 Adelie    male             39.8   146         0.367  \n 97 Adelie    male             40.1   146         0.479  \n 98 Adelie    female           40.2   146         0.517  \n 99 Adelie    male             40.2   146         0.517  \n100 Adelie    female           40.2   146         0.517  \n101 Adelie    female           40.3   146         0.554  \n102 Adelie    male             40.3   146         0.554  \n103 Adelie    female           40.5   146         0.629  \n104 Adelie    male             40.5   146         0.629  \n105 Adelie    male             40.6   146         0.667  \n106 Adelie    male             40.6   146         0.667  \n107 Adelie    male             40.6   146         0.667  \n108 Adelie    male             40.6   146         0.667  \n109 Adelie    male             40.7   146         0.705  \n110 Adelie    male             40.8   146         0.742  \n111 Adelie    male             40.8   146         0.742  \n112 Adelie    male             40.9   146         0.780  \n113 Adelie    female           40.9   146         0.780  \n114 Adelie    male             41     146         0.817  \n115 Adelie    female           41.1   146         0.855  \n116 Adelie    male             41.1   146         0.855  \n117 Adelie    male             41.1   146         0.855  \n118 Adelie    male             41.1   146         0.855  \n119 Adelie    male             41.1   146         0.855  \n120 Adelie    male             41.1   146         0.855  \n121 Adelie    male             41.1   146         0.855  \n122 Adelie    male             41.3   146         0.930  \n123 Adelie    male             41.3   146         0.930  \n124 Adelie    male             41.4   146         0.967  \n125 Adelie    male             41.4   146         0.967  \n126 Adelie    male             41.5   146         1.01   \n127 Adelie    male             41.5   146         1.01   \n128 Adelie    male             41.6   146         1.04   \n129 Adelie    male             41.8   146         1.12   \n130 Adelie    male             42     146         1.19   \n131 Adelie    male             42.1   146         1.23   \n132 Adelie    female           42.2   146         1.27   \n133 Adelie    male             42.2   146         1.27   \n134 Adelie    male             42.3   146         1.31   \n135 Adelie    male             42.5   146         1.38   \n136 Adelie    male             42.7   146         1.46   \n137 Adelie    male             42.8   146         1.49   \n138 Adelie    male             42.9   146         1.53   \n139 Adelie    male             43.1   146         1.61   \n140 Adelie    male             43.2   146         1.64   \n141 Adelie    male             43.2   146         1.64   \n142 Adelie    male             44.1   146         1.98   \n143 Adelie    male             44.1   146         1.98   \n144 Adelie    male             45.6   146         2.54   \n145 Adelie    male             45.8   146         2.62   \n146 Adelie    male             46     146         2.70   \n147 Chinstrap female           40.9    68        -2.38   \n148 Chinstrap female           42.4    68        -1.93   \n149 Chinstrap female           42.5    68        -1.90   \n150 Chinstrap female           42.5    68        -1.90   \n151 Chinstrap female           43.2    68        -1.69   \n152 Chinstrap female           43.5    68        -1.60   \n153 Chinstrap female           45.2    68        -1.09   \n154 Chinstrap female           45.2    68        -1.09   \n155 Chinstrap female           45.4    68        -1.03   \n156 Chinstrap female           45.5    68        -0.998  \n157 Chinstrap female           45.6    68        -0.968  \n158 Chinstrap female           45.7    68        -0.938  \n159 Chinstrap female           45.7    68        -0.938  \n160 Chinstrap female           45.9    68        -0.879  \n161 Chinstrap female           46      68        -0.849  \n162 Chinstrap female           46.1    68        -0.819  \n163 Chinstrap female           46.2    68        -0.789  \n164 Chinstrap female           46.4    68        -0.729  \n165 Chinstrap female           46.4    68        -0.729  \n166 Chinstrap female           46.5    68        -0.699  \n167 Chinstrap female           46.6    68        -0.669  \n168 Chinstrap female           46.7    68        -0.639  \n169 Chinstrap female           46.8    68        -0.609  \n170 Chinstrap female           46.9    68        -0.579  \n171 Chinstrap female           47      68        -0.549  \n172 Chinstrap female           47.5    68        -0.399  \n173 Chinstrap female           47.6    68        -0.369  \n174 Chinstrap female           48.1    68        -0.220  \n175 Chinstrap male             48.5    68        -0.100  \n176 Chinstrap male             49      68         0.0498 \n177 Chinstrap male             49      68         0.0498 \n178 Chinstrap male             49.2    68         0.110  \n179 Chinstrap male             49.3    68         0.140  \n180 Chinstrap male             49.5    68         0.199  \n181 Chinstrap male             49.6    68         0.229  \n182 Chinstrap male             49.7    68         0.259  \n183 Chinstrap female           49.8    68         0.289  \n184 Chinstrap male             50      68         0.349  \n185 Chinstrap female           50.1    68         0.379  \n186 Chinstrap male             50.2    68         0.409  \n187 Chinstrap female           50.2    68         0.409  \n188 Chinstrap male             50.3    68         0.439  \n189 Chinstrap male             50.5    68         0.499  \n190 Chinstrap female           50.5    68         0.499  \n191 Chinstrap male             50.6    68         0.529  \n192 Chinstrap male             50.7    68         0.559  \n193 Chinstrap male             50.8    68         0.589  \n194 Chinstrap male             50.8    68         0.589  \n195 Chinstrap male             50.9    68         0.619  \n196 Chinstrap female           50.9    68         0.619  \n197 Chinstrap male             51      68         0.649  \n198 Chinstrap male             51.3    68         0.739  \n199 Chinstrap male             51.3    68         0.739  \n200 Chinstrap male             51.3    68         0.739  \n201 Chinstrap male             51.4    68         0.768  \n202 Chinstrap male             51.5    68         0.798  \n203 Chinstrap male             51.7    68         0.858  \n204 Chinstrap male             51.9    68         0.918  \n205 Chinstrap male             52      68         0.948  \n206 Chinstrap male             52      68         0.948  \n207 Chinstrap male             52      68         0.948  \n208 Chinstrap male             52.2    68         1.01   \n209 Chinstrap male             52.7    68         1.16   \n210 Chinstrap male             52.8    68         1.19   \n211 Chinstrap male             53.5    68         1.40   \n212 Chinstrap male             54.2    68         1.61   \n213 Chinstrap male             55.8    68         2.09   \n214 Chinstrap female           58      68         2.74   \n215 Gentoo    female           40.9   119        -2.15   \n216 Gentoo    female           41.7   119        -1.89   \n217 Gentoo    female           42     119        -1.79   \n218 Gentoo    female           42.6   119        -1.60   \n219 Gentoo    female           42.7   119        -1.57   \n220 Gentoo    female           42.8   119        -1.54   \n221 Gentoo    female           42.9   119        -1.50   \n222 Gentoo    female           43.2   119        -1.41   \n223 Gentoo    female           43.3   119        -1.37   \n224 Gentoo    female           43.3   119        -1.37   \n225 Gentoo    female           43.4   119        -1.34   \n226 Gentoo    female           43.5   119        -1.31   \n227 Gentoo    female           43.5   119        -1.31   \n228 Gentoo    female           43.6   119        -1.28   \n229 Gentoo    female           43.8   119        -1.21   \n230 Gentoo    female           44     119        -1.15   \n231 Gentoo    male             44.4   119        -1.02   \n232 Gentoo    female           44.5   119        -0.988  \n233 Gentoo    female           44.9   119        -0.859  \n234 Gentoo    female           44.9   119        -0.859  \n235 Gentoo    male             45     119        -0.827  \n236 Gentoo    female           45.1   119        -0.795  \n237 Gentoo    female           45.1   119        -0.795  \n238 Gentoo    female           45.1   119        -0.795  \n239 Gentoo    male             45.2   119        -0.762  \n240 Gentoo    female           45.2   119        -0.762  \n241 Gentoo    male             45.2   119        -0.762  \n242 Gentoo    female           45.2   119        -0.762  \n243 Gentoo    female           45.3   119        -0.730  \n244 Gentoo    female           45.3   119        -0.730  \n245 Gentoo    female           45.4   119        -0.698  \n246 Gentoo    female           45.5   119        -0.666  \n247 Gentoo    female           45.5   119        -0.666  \n248 Gentoo    male             45.5   119        -0.666  \n249 Gentoo    female           45.5   119        -0.666  \n250 Gentoo    female           45.7   119        -0.601  \n251 Gentoo    female           45.8   119        -0.569  \n252 Gentoo    female           45.8   119        -0.569  \n253 Gentoo    female           46.1   119        -0.473  \n254 Gentoo    male             46.1   119        -0.473  \n255 Gentoo    female           46.2   119        -0.440  \n256 Gentoo    male             46.2   119        -0.440  \n257 Gentoo    female           46.2   119        -0.440  \n258 Gentoo    male             46.3   119        -0.408  \n259 Gentoo    male             46.4   119        -0.376  \n260 Gentoo    female           46.4   119        -0.376  \n261 Gentoo    female           46.5   119        -0.344  \n262 Gentoo    female           46.5   119        -0.344  \n263 Gentoo    female           46.5   119        -0.344  \n264 Gentoo    female           46.5   119        -0.344  \n265 Gentoo    female           46.6   119        -0.312  \n266 Gentoo    male             46.7   119        -0.279  \n267 Gentoo    male             46.8   119        -0.247  \n268 Gentoo    male             46.8   119        -0.247  \n269 Gentoo    female           46.8   119        -0.247  \n270 Gentoo    female           46.9   119        -0.215  \n271 Gentoo    female           47.2   119        -0.118  \n272 Gentoo    female           47.2   119        -0.118  \n273 Gentoo    male             47.3   119        -0.0863 \n274 Gentoo    female           47.4   119        -0.0541 \n275 Gentoo    female           47.5   119        -0.0219 \n276 Gentoo    female           47.5   119        -0.0219 \n277 Gentoo    female           47.5   119        -0.0219 \n278 Gentoo    male             47.6   119         0.0103 \n279 Gentoo    female           47.7   119         0.0425 \n280 Gentoo    male             47.8   119         0.0747 \n281 Gentoo    male             48.1   119         0.171  \n282 Gentoo    female           48.2   119         0.203  \n283 Gentoo    male             48.2   119         0.203  \n284 Gentoo    male             48.4   119         0.268  \n285 Gentoo    male             48.4   119         0.268  \n286 Gentoo    female           48.4   119         0.268  \n287 Gentoo    male             48.5   119         0.300  \n288 Gentoo    female           48.5   119         0.300  \n289 Gentoo    male             48.6   119         0.332  \n290 Gentoo    female           48.7   119         0.364  \n291 Gentoo    male             48.7   119         0.364  \n292 Gentoo    male             48.7   119         0.364  \n293 Gentoo    male             48.8   119         0.397  \n294 Gentoo    male             49     119         0.461  \n295 Gentoo    female           49.1   119         0.493  \n296 Gentoo    female           49.1   119         0.493  \n297 Gentoo    male             49.1   119         0.493  \n298 Gentoo    male             49.2   119         0.525  \n299 Gentoo    male             49.3   119         0.558  \n300 Gentoo    male             49.4   119         0.590  \n301 Gentoo    male             49.5   119         0.622  \n302 Gentoo    male             49.5   119         0.622  \n303 Gentoo    male             49.6   119         0.654  \n304 Gentoo    male             49.6   119         0.654  \n305 Gentoo    male             49.8   119         0.719  \n306 Gentoo    male             49.8   119         0.719  \n307 Gentoo    male             49.9   119         0.751  \n308 Gentoo    male             50     119         0.783  \n309 Gentoo    male             50     119         0.783  \n310 Gentoo    male             50     119         0.783  \n311 Gentoo    male             50     119         0.783  \n312 Gentoo    male             50.1   119         0.815  \n313 Gentoo    male             50.2   119         0.847  \n314 Gentoo    male             50.4   119         0.912  \n315 Gentoo    male             50.4   119         0.912  \n316 Gentoo    male             50.5   119         0.944  \n317 Gentoo    male             50.5   119         0.944  \n318 Gentoo    female           50.5   119         0.944  \n319 Gentoo    male             50.7   119         1.01   \n320 Gentoo    male             50.8   119         1.04   \n321 Gentoo    male             50.8   119         1.04   \n322 Gentoo    male             51.1   119         1.14   \n323 Gentoo    male             51.1   119         1.14   \n324 Gentoo    male             51.3   119         1.20   \n325 Gentoo    male             51.5   119         1.27   \n326 Gentoo    male             52.1   119         1.46   \n327 Gentoo    male             52.2   119         1.49   \n328 Gentoo    male             52.5   119         1.59   \n329 Gentoo    male             53.4   119         1.88   \n330 Gentoo    male             54.3   119         2.17   \n331 Gentoo    male             55.1   119         2.42   \n332 Gentoo    male             55.9   119         2.68   \n333 Gentoo    male             59.6   119         3.87   \n# get the largest 3 penguins by bill depth from each species\npenguins %>%\n  group_by(species) %>%\n  slice_max(bill_depth_mm, n = 3)# A tibble: 9 × 8\n# Groups:   species [3]\n  species   island   bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex  \n  <chr>     <chr>             <dbl>         <dbl>             <dbl>       <dbl> <chr>\n1 Adelie    Torgers…           46            21.5               194        4200 male \n2 Adelie    Torgers…           38.6          21.2               191        3800 male \n3 Adelie    Dream              42.3          21.2               191        4150 male \n4 Chinstrap Dream              54.2          20.8               201        4300 male \n5 Chinstrap Dream              52            20.7               210        4800 male \n6 Chinstrap Dream              51.7          20.3               194        3775 male \n7 Gentoo    Biscoe             44.4          17.3               219        5250 male \n8 Gentoo    Biscoe             50.8          17.3               228        5600 male \n9 Gentoo    Biscoe             52.2          17.1               228        5400 male \n# ℹ 1 more variable: year <dbl>"},{"path":"advanced-operations.html","id":"regrouping","chapter":"8 Advanced Operations","heading":"8.1.1 Regrouping","text":"Sometimes one group_by() may enough get need; may need re-group_by() something else finish job. example, suppose want see percent species came different islands. requires two uses group_by():combination df %>% group_by(...) %>% summarize(n = n()) common, shortcut : df %>% count(...). can demonstrate another example involving regrouping. Suppose want know percent species male/female:Groups also useful prepping data frames plotting. example, ’s chunk produces bar plot showing mean body mass changes species sex:","code":"\n# first group by species + island and summarize to get size of each group,\n# then regroup by species and MUTATE (not summarize) totals for each species,\n# then divide these to get proportion of each species from each island\npenguins %>%\n  group_by(species, island) %>%\n  summarize(n = n()) %>%\n  group_by(species) %>%\n  mutate(\n    species_total = sum(n),\n    pct_of_species_from_island = n / species_total * 100\n  )# A tibble: 5 × 5\n# Groups:   species [3]\n  species   island        n species_total pct_of_species_from_island\n  <chr>     <chr>     <int>         <int>                      <dbl>\n1 Adelie    Biscoe       44           146                       30.1\n2 Adelie    Dream        55           146                       37.7\n3 Adelie    Torgersen    47           146                       32.2\n4 Chinstrap Dream        68            68                      100  \n5 Gentoo    Biscoe      119           119                      100  \n# again, first group by species + sex and get size using the shortcut count(),\n# then regroup by species and MUTATE totals for each species,\n# then divide to get proportions of each species that were male/female\npenguins %>%\n  count(species, sex) %>%\n  group_by(species) %>%\n  mutate(\n    species_total = sum(n),\n    pct_of_species_each_sex = n / species_total * 100\n  )# A tibble: 6 × 5\n# Groups:   species [3]\n  species   sex        n species_total pct_of_species_each_sex\n  <chr>     <chr>  <int>         <int>                   <dbl>\n1 Adelie    female    73           146                    50  \n2 Adelie    male      73           146                    50  \n3 Chinstrap female    34            68                    50  \n4 Chinstrap male      34            68                    50  \n5 Gentoo    female    58           119                    48.7\n6 Gentoo    male      61           119                    51.3\n# get mean body mass by species + sex and plot\n# the %T>% is a special pipe called a Tee pipe\n# it's a shortcut for piping something into 2 different operations,\n# useful for example when you want to print a data frame, then also plot it\n# see https://magrittr.tidyverse.org/reference/tee.html for more\npenguins %>% \n  group_by(species, sex) %>% \n  summarize(mean_mass = mean(body_mass_g)) %T>% print %>% \n  ggplot(aes(x = species, y = mean_mass, fill = sex)) +\n  geom_col(position = \"dodge2\") +\n  labs(x = \"Species\", y = \"Mean body mass (g)\",\n       title = \"Mean body mass of Palmer penguins by species + sex\")# A tibble: 6 × 3\n# Groups:   species [3]\n  species   sex    mean_mass\n  <chr>     <chr>      <dbl>\n1 Adelie    female     3369.\n2 Adelie    male       4043.\n3 Chinstrap female     3527.\n4 Chinstrap male       3939.\n5 Gentoo    female     4680.\n6 Gentoo    male       5485."},{"path":"advanced-operations.html","id":"ungrouping","chapter":"8 Advanced Operations","heading":"8.1.2 Ungrouping","text":"Many operations output grouped data frames. example, look closely output previous chunks ’ll see # Groups:   species [3] . means operations run continue execute grouped way.can remove grouping structure ungroup(). allows revert running operations entire data frame. Example:","code":"\n# get count of each species + sex combination,\n# but this time get its percentage out of ALL observations\npenguins %>%\n  count(species, sex) %>%\n  ungroup() %>%\n  mutate(pct_of_all = n / sum(n))# A tibble: 6 × 4\n  species   sex        n pct_of_all\n  <chr>     <chr>  <int>      <dbl>\n1 Adelie    female    73      0.219\n2 Adelie    male      73      0.219\n3 Chinstrap female    34      0.102\n4 Chinstrap male      34      0.102\n5 Gentoo    female    58      0.174\n6 Gentoo    male      61      0.183"},{"path":"advanced-operations.html","id":"more-practice-fertility-data","chapter":"8 Advanced Operations","heading":"8.1.3 More practice! (fertility data)","text":"Let’s give penguins dataset rest practice dplyr grouping bit different dataset. following chunk imports fertility.csv, cleaned global fertility data set World Bank, giving average number births per woman year country 1960 present. past decades, global fertility sharply declining countries. Many countries now replacement rate 2.1, leading widespread concerns population collapse latter part 21st century.country 60 years data dataset. can see overview countries represented dataset listed region income group temporarily dropping years, removing duplicates, printing full output collapsible box:One additional small processing step continuing convert income_group ordered factor (see section 3.9.5), important later.can begin running summaries explore dataset. start, ’s chunk showing number countries median income group countries region:Next, ’s chunk showing median fertility rate region recent year 2022, well countries highest lowest 2022 rates (rates ) region:can also show latest rate country, well change 2000, just start 21st century:countries biggest drop fertility?countries actually increased?many countries now vs replacement rate? can grouping rate least 2.1—mention can use transformations inside group_by() well?Let’s make plots data well. 2 plots showing median fertility rate time grouping either region income level:","code":"\nfertility <- read_csv(\"https://bwu62.github.io/stat240-revamp/data/fertility.csv\")\nfertility# A tibble: 13,050 × 6\n   code  country     region     income_group  year  rate\n   <chr> <chr>       <chr>      <chr>        <dbl> <dbl>\n 1 AFG   Afghanistan South Asia Low           1960  7.28\n 2 AFG   Afghanistan South Asia Low           1961  7.28\n 3 AFG   Afghanistan South Asia Low           1962  7.29\n 4 AFG   Afghanistan South Asia Low           1963  7.30\n 5 AFG   Afghanistan South Asia Low           1964  7.30\n 6 AFG   Afghanistan South Asia Low           1965  7.30\n 7 AFG   Afghanistan South Asia Low           1966  7.32\n 8 AFG   Afghanistan South Asia Low           1967  7.34\n 9 AFG   Afghanistan South Asia Low           1968  7.36\n10 AFG   Afghanistan South Asia Low           1969  7.39\n# ℹ 13,040 more rows\nfertility %>%\n  select(country:income_group) %>%\n  distinct() %>%\n  print(n = Inf)# A tibble: 211 × 3\n    country                  region                     income_group\n    <chr>                    <chr>                      <chr>       \n  1 Afghanistan              South Asia                 Low         \n  2 Albania                  Europe & Central Asia      Upper middle\n  3 Algeria                  Middle East & North Africa Upper middle\n  4 Andorra                  Europe & Central Asia      High        \n  5 Angola                   Sub-Saharan Africa         Lower middle\n  6 Antigua & Barbuda        Latin America & Caribbean  High        \n  7 Argentina                Latin America & Caribbean  Upper middle\n  8 Armenia                  Europe & Central Asia      Upper middle\n  9 Aruba                    Latin America & Caribbean  High        \n 10 Australia                East Asia & Pacific        High        \n 11 Austria                  Europe & Central Asia      High        \n 12 Azerbaijan               Europe & Central Asia      Upper middle\n 13 Bahamas                  Latin America & Caribbean  High        \n 14 Bahrain                  Middle East & North Africa High        \n 15 Bangladesh               South Asia                 Lower middle\n 16 Barbados                 Latin America & Caribbean  High        \n 17 Belarus                  Europe & Central Asia      Upper middle\n 18 Belgium                  Europe & Central Asia      High        \n 19 Belize                   Latin America & Caribbean  Upper middle\n 20 Benin                    Sub-Saharan Africa         Lower middle\n 21 Bermuda                  North America              High        \n 22 Bhutan                   South Asia                 Lower middle\n 23 Bolivia                  Latin America & Caribbean  Lower middle\n 24 Bosnia & Herzegovina     Europe & Central Asia      Upper middle\n 25 Botswana                 Sub-Saharan Africa         Upper middle\n 26 Brazil                   Latin America & Caribbean  Upper middle\n 27 Brunei                   East Asia & Pacific        High        \n 28 Bulgaria                 Europe & Central Asia      High        \n 29 Burkina Faso             Sub-Saharan Africa         Low         \n 30 Burundi                  Sub-Saharan Africa         Low         \n 31 Cambodia                 East Asia & Pacific        Lower middle\n 32 Cameroon                 Sub-Saharan Africa         Lower middle\n 33 Canada                   North America              High        \n 34 Cape Verde               Sub-Saharan Africa         Lower middle\n 35 Central African Republic Sub-Saharan Africa         Low         \n 36 Chad                     Sub-Saharan Africa         Low         \n 37 Channel Islands          Europe & Central Asia      High        \n 38 Chile                    Latin America & Caribbean  High        \n 39 China                    East Asia & Pacific        Upper middle\n 40 Colombia                 Latin America & Caribbean  Upper middle\n 41 Comoros                  Sub-Saharan Africa         Lower middle\n 42 Congo, Dem. Rep.         Sub-Saharan Africa         Low         \n 43 Congo, Rep.              Sub-Saharan Africa         Lower middle\n 44 Costa Rica               Latin America & Caribbean  Upper middle\n 45 Croatia                  Europe & Central Asia      High        \n 46 Cuba                     Latin America & Caribbean  Upper middle\n 47 Curaçao                  Latin America & Caribbean  High        \n 48 Cyprus                   Europe & Central Asia      High        \n 49 Czechia                  Europe & Central Asia      High        \n 50 Denmark                  Europe & Central Asia      High        \n 51 Djibouti                 Middle East & North Africa Lower middle\n 52 Dominica                 Latin America & Caribbean  Upper middle\n 53 Dominican Republic       Latin America & Caribbean  Upper middle\n 54 East Timor               East Asia & Pacific        Lower middle\n 55 Ecuador                  Latin America & Caribbean  Upper middle\n 56 Egypt                    Middle East & North Africa Lower middle\n 57 El Salvador              Latin America & Caribbean  Upper middle\n 58 Equatorial Guinea        Sub-Saharan Africa         Upper middle\n 59 Eritrea                  Sub-Saharan Africa         Low         \n 60 Estonia                  Europe & Central Asia      High        \n 61 Eswatini                 Sub-Saharan Africa         Lower middle\n 62 Ethiopia                 Sub-Saharan Africa         Low         \n 63 Faroe Islands            Europe & Central Asia      High        \n 64 Fiji                     East Asia & Pacific        Upper middle\n 65 Finland                  Europe & Central Asia      High        \n 66 France                   Europe & Central Asia      High        \n 67 French Polynesia         East Asia & Pacific        High        \n 68 Gabon                    Sub-Saharan Africa         Upper middle\n 69 Gambia                   Sub-Saharan Africa         Low         \n 70 Georgia                  Europe & Central Asia      Upper middle\n 71 Germany                  Europe & Central Asia      High        \n 72 Ghana                    Sub-Saharan Africa         Lower middle\n 73 Gibraltar                Europe & Central Asia      High        \n 74 Greece                   Europe & Central Asia      High        \n 75 Greenland                Europe & Central Asia      High        \n 76 Grenada                  Latin America & Caribbean  Upper middle\n 77 Guam                     East Asia & Pacific        High        \n 78 Guatemala                Latin America & Caribbean  Upper middle\n 79 Guinea                   Sub-Saharan Africa         Lower middle\n 80 Guinea-Bissau            Sub-Saharan Africa         Low         \n 81 Guyana                   Latin America & Caribbean  High        \n 82 Haiti                    Latin America & Caribbean  Lower middle\n 83 Honduras                 Latin America & Caribbean  Lower middle\n 84 Hong Kong                East Asia & Pacific        High        \n 85 Hungary                  Europe & Central Asia      High        \n 86 Iceland                  Europe & Central Asia      High        \n 87 India                    South Asia                 Lower middle\n 88 Indonesia                East Asia & Pacific        Upper middle\n 89 Iran                     Middle East & North Africa Upper middle\n 90 Iraq                     Middle East & North Africa Upper middle\n 91 Ireland                  Europe & Central Asia      High        \n 92 Isle of Man              Europe & Central Asia      High        \n 93 Israel                   Middle East & North Africa High        \n 94 Italy                    Europe & Central Asia      High        \n 95 Ivory Coast              Sub-Saharan Africa         Lower middle\n 96 Jamaica                  Latin America & Caribbean  Upper middle\n 97 Japan                    East Asia & Pacific        High        \n 98 Jordan                   Middle East & North Africa Lower middle\n 99 Kazakhstan               Europe & Central Asia      Upper middle\n100 Kenya                    Sub-Saharan Africa         Lower middle\n101 Kiribati                 East Asia & Pacific        Lower middle\n102 Kosovo                   Europe & Central Asia      Upper middle\n103 Kuwait                   Middle East & North Africa High        \n104 Kyrgyzstan               Europe & Central Asia      Lower middle\n105 Laos                     East Asia & Pacific        Lower middle\n106 Latvia                   Europe & Central Asia      High        \n107 Lebanon                  Middle East & North Africa Lower middle\n108 Lesotho                  Sub-Saharan Africa         Lower middle\n109 Liberia                  Sub-Saharan Africa         Low         \n110 Libya                    Middle East & North Africa Upper middle\n111 Liechtenstein            Europe & Central Asia      High        \n112 Lithuania                Europe & Central Asia      High        \n113 Luxembourg               Europe & Central Asia      High        \n114 Macao                    East Asia & Pacific        High        \n115 Madagascar               Sub-Saharan Africa         Low         \n116 Malawi                   Sub-Saharan Africa         Low         \n117 Malaysia                 East Asia & Pacific        Upper middle\n118 Maldives                 South Asia                 Upper middle\n119 Mali                     Sub-Saharan Africa         Low         \n120 Malta                    Middle East & North Africa High        \n121 Marshall Islands         East Asia & Pacific        Upper middle\n122 Mauritania               Sub-Saharan Africa         Lower middle\n123 Mauritius                Sub-Saharan Africa         Upper middle\n124 Mexico                   Latin America & Caribbean  Upper middle\n125 Micronesia               East Asia & Pacific        Lower middle\n126 Moldova                  Europe & Central Asia      Upper middle\n127 Mongolia                 East Asia & Pacific        Upper middle\n128 Montenegro               Europe & Central Asia      Upper middle\n129 Morocco                  Middle East & North Africa Lower middle\n130 Mozambique               Sub-Saharan Africa         Low         \n131 Myanmar                  East Asia & Pacific        Lower middle\n132 Namibia                  Sub-Saharan Africa         Upper middle\n133 Nauru                    East Asia & Pacific        High        \n134 Nepal                    South Asia                 Lower middle\n135 Netherlands              Europe & Central Asia      High        \n136 New Caledonia            East Asia & Pacific        High        \n137 New Zealand              East Asia & Pacific        High        \n138 Nicaragua                Latin America & Caribbean  Lower middle\n139 Niger                    Sub-Saharan Africa         Low         \n140 Nigeria                  Sub-Saharan Africa         Lower middle\n141 North Korea              East Asia & Pacific        Low         \n142 North Macedonia          Europe & Central Asia      Upper middle\n143 Norway                   Europe & Central Asia      High        \n144 Oman                     Middle East & North Africa High        \n145 Pakistan                 South Asia                 Lower middle\n146 Palau                    East Asia & Pacific        High        \n147 Panama                   Latin America & Caribbean  High        \n148 Papua New Guinea         East Asia & Pacific        Lower middle\n149 Paraguay                 Latin America & Caribbean  Upper middle\n150 Peru                     Latin America & Caribbean  Upper middle\n151 Philippines              East Asia & Pacific        Lower middle\n152 Poland                   Europe & Central Asia      High        \n153 Portugal                 Europe & Central Asia      High        \n154 Puerto Rico              Latin America & Caribbean  High        \n155 Qatar                    Middle East & North Africa High        \n156 Romania                  Europe & Central Asia      High        \n157 Russia                   Europe & Central Asia      High        \n158 Rwanda                   Sub-Saharan Africa         Low         \n159 Samoa                    East Asia & Pacific        Lower middle\n160 San Marino               Europe & Central Asia      High        \n161 Saudi Arabia             Middle East & North Africa High        \n162 Senegal                  Sub-Saharan Africa         Lower middle\n163 Serbia                   Europe & Central Asia      Upper middle\n164 Seychelles               Sub-Saharan Africa         High        \n165 Sierra Leone             Sub-Saharan Africa         Low         \n166 Singapore                East Asia & Pacific        High        \n167 Sint Maarten             Latin America & Caribbean  High        \n168 Slovakia                 Europe & Central Asia      High        \n169 Slovenia                 Europe & Central Asia      High        \n170 Solomon Islands          East Asia & Pacific        Lower middle\n171 Somalia                  Sub-Saharan Africa         Low         \n172 South Africa             Sub-Saharan Africa         Upper middle\n173 South Korea              East Asia & Pacific        High        \n174 South Sudan              Sub-Saharan Africa         Low         \n175 Spain                    Europe & Central Asia      High        \n176 Sri Lanka                South Asia                 Lower middle\n177 St. Kitts & Nevis        Latin America & Caribbean  High        \n178 St. Lucia                Latin America & Caribbean  Upper middle\n179 St. Martin               Latin America & Caribbean  High        \n180 St. Vincent & Grenadines Latin America & Caribbean  Upper middle\n181 Sudan                    Sub-Saharan Africa         Low         \n182 Suriname                 Latin America & Caribbean  Upper middle\n183 Sweden                   Europe & Central Asia      High        \n184 Switzerland              Europe & Central Asia      High        \n185 Syria                    Middle East & North Africa Low         \n186 São Tomé & Principe      Sub-Saharan Africa         Lower middle\n187 Tajikistan               Europe & Central Asia      Lower middle\n188 Tanzania                 Sub-Saharan Africa         Lower middle\n189 Thailand                 East Asia & Pacific        Upper middle\n190 Togo                     Sub-Saharan Africa         Low         \n191 Tonga                    East Asia & Pacific        Upper middle\n192 Trinidad & Tobago        Latin America & Caribbean  High        \n193 Tunisia                  Middle East & North Africa Lower middle\n194 Turkey                   Europe & Central Asia      Upper middle\n195 Turkmenistan             Europe & Central Asia      Upper middle\n196 Turks & Caicos Islands   Latin America & Caribbean  High        \n197 Tuvalu                   East Asia & Pacific        Upper middle\n198 Uganda                   Sub-Saharan Africa         Low         \n199 Ukraine                  Europe & Central Asia      Upper middle\n200 United Arab Emirates     Middle East & North Africa High        \n201 United Kingdom           Europe & Central Asia      High        \n202 United States            North America              High        \n203 Uruguay                  Latin America & Caribbean  High        \n204 Uzbekistan               Europe & Central Asia      Lower middle\n205 Vanuatu                  East Asia & Pacific        Lower middle\n206 Vietnam                  East Asia & Pacific        Lower middle\n207 Virgin Islands           Latin America & Caribbean  High        \n208 West Bank & Gaza         Middle East & North Africa Lower middle\n209 Yemen                    Middle East & North Africa Low         \n210 Zambia                   Sub-Saharan Africa         Lower middle\n211 Zimbabwe                 Sub-Saharan Africa         Lower middle\nfertility <- fertility %>% mutate(\n  income_group = factor(income_group, ordered = TRUE, levels = c(\n    \"Low\", \"Lower middle\", \"Upper middle\", \"High\"))\n)\n# strangely, base R median doesn't work on ordered categories,\n# but we can use Median from DescTools instead\nfertility %>%\n  select(country, region, income_group) %>%\n  distinct() %>%\n  group_by(region) %>%\n  summarize(n = n(), median = DescTools::Median(income_group)) %>%\n  arrange(desc(median))# A tibble: 7 × 3\n  region                         n median      \n  <chr>                      <int> <ord>       \n1 Europe & Central Asia         57 High        \n2 North America                  3 High        \n3 East Asia & Pacific           35 Upper middle\n4 Latin America & Caribbean     39 Upper middle\n5 Middle East & North Africa    21 Upper middle\n6 South Asia                     8 Lower middle\n7 Sub-Saharan Africa            48 Lower middle\n# first filter to get the right year, then\n# sort by region, rate (so min, max are the first, last in each group)\n# then summarize to get median, and min/max country/rate\nfertility %>%\n  filter(year == max(year)) %>%\n  arrange(region, rate) %>%\n  group_by(region) %>%\n  summarize(\n    n           = n(),\n    median      = median(rate),\n    min_country = first(country),\n    min         = first(rate),\n    max_country = last(country),\n    max         = last(rate)\n  ) %>%\n  arrange(median)# A tibble: 7 × 7\n  region                         n median min_country   min max_country       max\n  <chr>                      <int>  <dbl> <chr>       <dbl> <chr>           <dbl>\n1 North America                  3   1.33 Bermuda     1.3   United States    1.66\n2 Europe & Central Asia         55   1.53 Spain       1.16  Uzbekistan       3.31\n3 Latin America & Caribbean     40   1.74 Puerto Rico 0.9   Haiti            2.77\n4 South Asia                     8   1.99 Bhutan      1.40  Afghanistan      4.52\n5 East Asia & Pacific           34   2.24 Hong Kong   0.701 Solomon Islands  3.92\n6 Middle East & North Africa    21   2.40 Malta       1.15  Yemen            3.72\n7 Sub-Saharan Africa            48   4.18 Mauritius   1.32  Niger            6.75\n# first filter to get the right years, then\n# sort by country, year (so 2000, 2022 are first and last in each group)\n# then summarize to get 2000 and 2022 rates, mutate to get change,\n# then ungroup, distinct, and arrange to display a neat output\n# again, collapsing output due to lengthy print out\n# %T>% is used again to both save and print the results\nfertility_change <- fertility %>%\n  filter(year %in% c(2000, max(year))) %>%\n  arrange(country, year) %>%\n  group_by(country) %>%\n  mutate(\n    rate2000 = first(rate),\n    rate2022 = last(rate),\n    change   = rate2022 - rate2000\n  ) %>%\n  select(country, region, rate2000, change, rate2022) %>%\n  ungroup() %>%\n  distinct() %>%\n  arrange(rate2022) %T>%\n  print(n = Inf)# A tibble: 209 × 5\n    country                  region                     rate2000   change rate2022\n    <chr>                    <chr>                         <dbl>    <dbl>    <dbl>\n  1 Hong Kong                East Asia & Pacific           1.03  -0.331      0.701\n  2 South Korea              East Asia & Pacific           1.48  -0.702      0.778\n  3 Puerto Rico              Latin America & Caribbean     2.05  -1.15       0.9  \n  4 Singapore                East Asia & Pacific           1.6   -0.56       1.04 \n  5 Macao                    East Asia & Pacific           0.912  0.197      1.11 \n  6 Malta                    Middle East & North Africa    1.68  -0.53       1.15 \n  7 Spain                    Europe & Central Asia         1.22  -0.0600     1.16 \n  8 China                    East Asia & Pacific           1.63  -0.453      1.18 \n  9 Aruba                    Latin America & Caribbean     1.90  -0.725      1.18 \n 10 Italy                    Europe & Central Asia         1.26  -0.0200     1.24 \n 11 Japan                    East Asia & Pacific           1.36  -0.100      1.26 \n 12 Poland                   Europe & Central Asia         1.37  -0.109      1.26 \n 13 Ukraine                  Europe & Central Asia         1.12   0.149      1.26 \n 14 Lithuania                Europe & Central Asia         1.39  -0.120      1.27 \n 15 Bermuda                  North America                 1.74  -0.44       1.3  \n 16 Curaçao                  Latin America & Caribbean     2.19  -0.89       1.3  \n 17 Luxembourg               Europe & Central Asia         1.76  -0.45       1.31 \n 18 Cyprus                   Europe & Central Asia         1.64  -0.326      1.31 \n 19 Thailand                 East Asia & Pacific           1.61  -0.295      1.32 \n 20 Finland                  Europe & Central Asia         1.73  -0.41       1.32 \n 21 Mauritius                Sub-Saharan Africa            1.99  -0.67       1.32 \n 22 Canada                   North America                 1.51  -0.18       1.33 \n 23 Jamaica                  Latin America & Caribbean     2.21  -0.87       1.34 \n 24 Bosnia & Herzegovina     Europe & Central Asia         1.28   0.0630     1.35 \n 25 Albania                  Europe & Central Asia         2.23  -0.855      1.38 \n 26 Bahamas                  Latin America & Caribbean     2.10  -0.717      1.38 \n 27 St. Lucia                Latin America & Caribbean     2.20  -0.815      1.39 \n 28 Switzerland              Europe & Central Asia         1.5   -0.110      1.39 \n 29 Bhutan                   South Asia                    3.41  -2.02       1.40 \n 30 Austria                  Europe & Central Asia         1.36   0.0500     1.41 \n 31 Estonia                  Europe & Central Asia         1.36   0.0500     1.41 \n 32 Norway                   Europe & Central Asia         1.85  -0.44       1.41 \n 33 Russia                   Europe & Central Asia         1.20   0.221      1.42 \n 34 Greece                   Europe & Central Asia         1.25   0.18       1.43 \n 35 Portugal                 Europe & Central Asia         1.55  -0.120      1.43 \n 36 United Arab Emirates     Middle East & North Africa    2.73  -1.29       1.44 \n 37 Cuba                     Latin America & Caribbean     1.58  -0.132      1.45 \n 38 Germany                  Europe & Central Asia         1.38   0.0750     1.46 \n 39 Channel Islands          Europe & Central Asia         1.49  -0.0180     1.47 \n 40 Latvia                   Europe & Central Asia         1.25   0.22       1.47 \n 41 Liechtenstein            Europe & Central Asia         1.57  -0.100      1.47 \n 42 Uruguay                  Latin America & Caribbean     2.17  -0.685      1.48 \n 43 Netherlands              Europe & Central Asia         1.72  -0.233      1.49 \n 44 Belarus                  Europe & Central Asia         1.32   0.178      1.50 \n 45 Kosovo                   Europe & Central Asia         2.66  -1.15       1.51 \n 46 St. Kitts & Nevis        Latin America & Caribbean     2.20  -0.684      1.51 \n 47 Hungary                  Europe & Central Asia         1.32   0.2        1.52 \n 48 Sweden                   Europe & Central Asia         1.54  -0.0200     1.52 \n 49 Costa Rica               Latin America & Caribbean     2.41  -0.89       1.52 \n 50 Belgium                  Europe & Central Asia         1.67  -0.140      1.53 \n 51 Croatia                  Europe & Central Asia         1.39   0.140      1.53 \n 52 Chile                    Latin America & Caribbean     1.99  -0.448      1.54 \n 53 Denmark                  Europe & Central Asia         1.77  -0.22       1.55 \n 54 Slovenia                 Europe & Central Asia         1.26   0.29       1.55 \n 55 Slovakia                 Europe & Central Asia         1.3    0.27       1.57 \n 56 United Kingdom           Europe & Central Asia         1.64  -0.0700     1.57 \n 57 Isle of Man              Europe & Central Asia         1.69  -0.123      1.57 \n 58 Sint Maarten             Latin America & Caribbean     1.85  -0.278      1.57 \n 59 Armenia                  Europe & Central Asia         1.60  -0.0280     1.58 \n 60 Antigua & Barbuda        Latin America & Caribbean     2.20  -0.616      1.58 \n 61 Dominica                 Latin America & Caribbean     2.35  -0.763      1.59 \n 62 Iceland                  Europe & Central Asia         2.08  -0.491      1.59 \n 63 North Macedonia          Europe & Central Asia         1.86  -0.261      1.6  \n 64 Trinidad & Tobago        Latin America & Caribbean     1.77  -0.155      1.61 \n 65 Czechia                  Europe & Central Asia         1.15   0.468      1.62 \n 66 Brazil                   Latin America & Caribbean     2.26  -0.629      1.63 \n 67 Australia                East Asia & Pacific           1.76  -0.126      1.63 \n 68 Serbia                   Europe & Central Asia         1.48   0.150      1.63 \n 69 Barbados                 Latin America & Caribbean     1.78  -0.141      1.63 \n 70 Turks & Caicos Islands   Latin America & Caribbean     2.51  -0.853      1.66 \n 71 New Zealand              East Asia & Pacific           1.98  -0.32       1.66 \n 72 United States            North America                 2.06  -0.391      1.66 \n 73 Azerbaijan               Europe & Central Asia         2     -0.33       1.67 \n 74 Maldives                 South Asia                    2.71  -1.03       1.68 \n 75 Iran                     Middle East & North Africa    2.02  -0.335      1.68 \n 76 French Polynesia         East Asia & Pacific           2.60  -0.908      1.69 \n 77 Colombia                 Latin America & Caribbean     2.57  -0.88       1.69 \n 78 Ireland                  Europe & Central Asia         1.89  -0.19       1.7  \n 79 Brunei                   East Asia & Pacific           2.35  -0.582      1.76 \n 80 St. Vincent & Grenadines Latin America & Caribbean     2.34  -0.562      1.78 \n 81 Bulgaria                 Europe & Central Asia         1.26   0.52       1.78 \n 82 Qatar                    Middle East & North Africa    3.23  -1.45       1.78 \n 83 El Salvador              Latin America & Caribbean     3.14  -1.36       1.78 \n 84 Malaysia                 East Asia & Pacific           2.91  -1.13       1.79 \n 85 North Korea              East Asia & Pacific           1.97  -0.176      1.79 \n 86 France                   Europe & Central Asia         1.89  -0.0960     1.79 \n 87 Bahrain                  Middle East & North Africa    2.78  -0.981      1.80 \n 88 Moldova                  Europe & Central Asia         1.50   0.301      1.8  \n 89 Montenegro               Europe & Central Asia         2.06  -0.265      1.8  \n 90 Mexico                   Latin America & Caribbean     2.72  -0.913      1.80 \n 91 Romania                  Europe & Central Asia         1.31   0.5        1.81 \n 92 Palau                    East Asia & Pacific           1.83   0          1.83 \n 93 Gibraltar                Europe & Central Asia         1.92  -0.0820     1.84 \n 94 Greenland                Europe & Central Asia         2.33  -0.49       1.84 \n 95 Argentina                Latin America & Caribbean     2.59  -0.715      1.88 \n 96 Cape Verde               Sub-Saharan Africa            3.54  -1.66       1.88 \n 97 Turkey                   Europe & Central Asia         2.50  -0.623      1.88 \n 98 Vietnam                  East Asia & Pacific           2.07  -0.131      1.94 \n 99 Bangladesh               South Asia                    3.22  -1.27       1.95 \n100 Sri Lanka                South Asia                    2.19  -0.217      1.97 \n101 Grenada                  Latin America & Caribbean     2.58  -0.596      1.99 \n102 Belize                   Latin America & Caribbean     3.63  -1.64       1.99 \n103 Virgin Islands           Latin America & Caribbean     1.87   0.134      2    \n104 Ecuador                  Latin America & Caribbean     3.10  -1.10       2.00 \n105 Nepal                    South Asia                    3.94  -1.94       2.01 \n106 India                    South Asia                    3.35  -1.34       2.01 \n107 New Caledonia            East Asia & Pacific           2.59  -0.57       2.02 \n108 Faroe Islands            Europe & Central Asia         2.58  -0.532      2.05 \n109 Georgia                  Europe & Central Asia         1.60   0.462      2.06 \n110 Tunisia                  Middle East & North Africa    2.05   0.0150     2.06 \n111 Lebanon                  Middle East & North Africa    2.50  -0.419      2.08 \n112 Kuwait                   Middle East & North Africa    2.74  -0.645      2.09 \n113 Myanmar                  East Asia & Pacific           2.78  -0.658      2.13 \n114 Indonesia                East Asia & Pacific           2.54  -0.383      2.15 \n115 Peru                     Latin America & Caribbean     2.84  -0.681      2.16 \n116 Dominican Republic       Latin America & Caribbean     2.86  -0.612      2.25 \n117 Nicaragua                Latin America & Caribbean     3.11  -0.827      2.28 \n118 Panama                   Latin America & Caribbean     2.74  -0.447      2.30 \n119 Morocco                  Middle East & North Africa    2.80  -0.497      2.30 \n120 Seychelles               Sub-Saharan Africa            2.08   0.240      2.32 \n121 Cambodia                 East Asia & Pacific           3.77  -1.45       2.32 \n122 Suriname                 Latin America & Caribbean     2.90  -0.573      2.32 \n123 Honduras                 Latin America & Caribbean     4.24  -1.90       2.34 \n124 South Africa             Sub-Saharan Africa            2.41  -0.0720     2.34 \n125 Guatemala                Latin America & Caribbean     4.58  -2.23       2.35 \n126 Guyana                   Latin America & Caribbean     3.02  -0.648      2.37 \n127 St. Martin               Latin America & Caribbean     2.71  -0.329      2.38 \n128 Saudi Arabia             Middle East & North Africa    4.12  -1.72       2.39 \n129 Libya                    Middle East & North Africa    2.85  -0.449      2.40 \n130 Paraguay                 Latin America & Caribbean     3.55  -1.11       2.44 \n131 Laos                     East Asia & Pacific           4.4   -1.95       2.45 \n132 Fiji                     East Asia & Pacific           3.03  -0.564      2.46 \n133 Guam                     East Asia & Pacific           3.01  -0.457      2.55 \n134 Oman                     Middle East & North Africa    3.89  -1.33       2.57 \n135 Bolivia                  Latin America & Caribbean     3.99  -1.41       2.58 \n136 Turkmenistan             Europe & Central Asia         2.90  -0.281      2.62 \n137 Micronesia               East Asia & Pacific           4.28  -1.61       2.67 \n138 Marshall Islands         East Asia & Pacific           4.59  -1.92       2.67 \n139 Syria                    Middle East & North Africa    4.00  -1.30       2.70 \n140 Philippines              East Asia & Pacific           3.71  -0.989      2.72 \n141 Botswana                 Sub-Saharan Africa            3.31  -0.558      2.75 \n142 Djibouti                 Middle East & North Africa    4.58  -1.82       2.76 \n143 Haiti                    Latin America & Caribbean     4.39  -1.62       2.77 \n144 Mongolia                 East Asia & Pacific           2.26   0.519      2.77 \n145 Eswatini                 Sub-Saharan Africa            4.00  -1.21       2.78 \n146 Jordan                   Middle East & North Africa    3.92  -1.13       2.79 \n147 Kyrgyzstan               Europe & Central Asia         2.4    0.4        2.8  \n148 Algeria                  Middle East & North Africa    2.57   0.263      2.83 \n149 Egypt                    Middle East & North Africa    3.44  -0.564      2.88 \n150 Israel                   Middle East & North Africa    2.95  -0.0600     2.89 \n151 Lesotho                  Sub-Saharan Africa            3.66  -0.678      2.98 \n152 East Timor               East Asia & Pacific           5.98  -2.93       3.05 \n153 Kazakhstan               Europe & Central Asia         1.8    1.25       3.05 \n154 Tajikistan               Europe & Central Asia         4.01  -0.865      3.14 \n155 Tuvalu                   East Asia & Pacific           3.81  -0.663      3.14 \n156 Papua New Guinea         East Asia & Pacific           4.53  -1.36       3.16 \n157 Tonga                    East Asia & Pacific           4.11  -0.915      3.19 \n158 Namibia                  Sub-Saharan Africa            3.98  -0.727      3.25 \n159 Kiribati                 East Asia & Pacific           4.07  -0.794      3.27 \n160 Kenya                    Sub-Saharan Africa            5.14  -1.84       3.30 \n161 Uzbekistan               Europe & Central Asia         2.58   0.728      3.31 \n162 Pakistan                 South Asia                    5.26  -1.85       3.41 \n163 West Bank & Gaza         Middle East & North Africa    5.44  -2.01       3.44 \n164 Zimbabwe                 Sub-Saharan Africa            3.97  -0.537      3.44 \n165 Iraq                     Middle East & North Africa    4.95  -1.50       3.44 \n166 Gabon                    Sub-Saharan Africa            4.47  -1.01       3.46 \n167 Nauru                    East Asia & Pacific           3.64  -0.179      3.46 \n168 Ghana                    Sub-Saharan Africa            4.85  -1.35       3.51 \n169 Vanuatu                  East Asia & Pacific           4.48  -0.783      3.70 \n170 Yemen                    Middle East & North Africa    6.32  -2.60       3.72 \n171 Rwanda                   Sub-Saharan Africa            5.92  -2.18       3.75 \n172 São Tomé & Principe      Sub-Saharan Africa            5.18  -1.43       3.75 \n173 Eritrea                  Sub-Saharan Africa            5.40  -1.61       3.79 \n174 Madagascar               Sub-Saharan Africa            5.40  -1.61       3.79 \n175 Malawi                   Sub-Saharan Africa            6.04  -2.19       3.85 \n176 Samoa                    East Asia & Pacific           4.51  -0.639      3.88 \n177 Sierra Leone             Sub-Saharan Africa            6.36  -2.48       3.88 \n178 Comoros                  Sub-Saharan Africa            5.30  -1.38       3.91 \n179 Guinea-Bissau            Sub-Saharan Africa            5.72  -1.80       3.92 \n180 Solomon Islands          East Asia & Pacific           4.76  -0.831      3.92 \n181 Liberia                  Sub-Saharan Africa            5.88  -1.86       4.02 \n182 Ethiopia                 Sub-Saharan Africa            6.56  -2.50       4.06 \n183 Congo, Rep.              Sub-Saharan Africa            4.76  -0.669      4.10 \n184 Equatorial Guinea        Sub-Saharan Africa            5.83  -1.66       4.17 \n185 Togo                     Sub-Saharan Africa            5.27  -1.07       4.20 \n186 Zambia                   Sub-Saharan Africa            5.93  -1.68       4.24 \n187 Guinea                   Sub-Saharan Africa            5.94  -1.63       4.30 \n188 Senegal                  Sub-Saharan Africa            5.50  -1.18       4.31 \n189 South Sudan              Sub-Saharan Africa            7.51  -3.18       4.34 \n190 Ivory Coast              Sub-Saharan Africa            5.81  -1.47       4.34 \n191 Mauritania               Sub-Saharan Africa            5.46  -1.12       4.34 \n192 Cameroon                 Sub-Saharan Africa            5.53  -1.15       4.38 \n193 Sudan                    Sub-Saharan Africa            5.38  -0.996      4.38 \n194 Uganda                   Sub-Saharan Africa            6.83  -2.36       4.47 \n195 Afghanistan              South Asia                    7.53  -3.01       4.52 \n196 Mozambique               Sub-Saharan Africa            5.81  -1.25       4.56 \n197 Gambia                   Sub-Saharan Africa            5.80  -1.21       4.59 \n198 Tanzania                 Sub-Saharan Africa            5.69  -1.03       4.66 \n199 Burkina Faso             Sub-Saharan Africa            6.52  -1.85       4.66 \n200 Benin                    Sub-Saharan Africa            5.89  -0.995      4.89 \n201 Burundi                  Sub-Saharan Africa            6.87  -1.89       4.98 \n202 Nigeria                  Sub-Saharan Africa            6.12  -0.981      5.14 \n203 Angola                   Sub-Saharan Africa            6.64  -1.43       5.21 \n204 Mali                     Sub-Saharan Africa            6.87  -1.01       5.87 \n205 Central African Republic Sub-Saharan Africa            5.92   0.00300    5.92 \n206 Congo, Dem. Rep.         Sub-Saharan Africa            6.72  -0.612      6.11 \n207 Somalia                  Sub-Saharan Africa            7.61  -1.41       6.20 \n208 Chad                     Sub-Saharan Africa            7.25  -1.03       6.22 \n209 Niger                    Sub-Saharan Africa            7.73  -0.983      6.75 \nfertility_change %>% slice_min(change, n = 10)# A tibble: 10 × 5\n   country      region                     rate2000 change rate2022\n   <chr>        <chr>                         <dbl>  <dbl>    <dbl>\n 1 South Sudan  Sub-Saharan Africa             7.51  -3.18     4.34\n 2 Afghanistan  South Asia                     7.53  -3.01     4.52\n 3 East Timor   East Asia & Pacific            5.98  -2.93     3.05\n 4 Yemen        Middle East & North Africa     6.32  -2.60     3.72\n 5 Ethiopia     Sub-Saharan Africa             6.56  -2.50     4.06\n 6 Sierra Leone Sub-Saharan Africa             6.36  -2.48     3.88\n 7 Uganda       Sub-Saharan Africa             6.83  -2.36     4.47\n 8 Guatemala    Latin America & Caribbean      4.58  -2.23     2.35\n 9 Malawi       Sub-Saharan Africa             6.04  -2.19     3.85\n10 Rwanda       Sub-Saharan Africa             5.92  -2.18     3.75\nfertility_change %>% slice_max(change, n = 10)# A tibble: 10 × 5\n   country    region                rate2000 change rate2022\n   <chr>      <chr>                    <dbl>  <dbl>    <dbl>\n 1 Kazakhstan Europe & Central Asia     1.8   1.25      3.05\n 2 Uzbekistan Europe & Central Asia     2.58  0.728     3.31\n 3 Bulgaria   Europe & Central Asia     1.26  0.52      1.78\n 4 Mongolia   East Asia & Pacific       2.26  0.519     2.77\n 5 Romania    Europe & Central Asia     1.31  0.5       1.81\n 6 Czechia    Europe & Central Asia     1.15  0.468     1.62\n 7 Georgia    Europe & Central Asia     1.60  0.462     2.06\n 8 Kyrgyzstan Europe & Central Asia     2.4   0.4       2.8 \n 9 Moldova    Europe & Central Asia     1.50  0.301     1.8 \n10 Slovenia   Europe & Central Asia     1.26  0.29      1.55\n# group by a new column called at_replacement indicating rate>=2.1\nfertility %>%\n  group_by(at_replacement = rate >= 2.1) %>%\n  summarize(n = n()) %>%\n  mutate(pct = 100 * n / sum(n))# A tibble: 2 × 3\n  at_replacement     n   pct\n  <lgl>          <int> <dbl>\n1 FALSE           3450  26.4\n2 TRUE            9600  73.6\n# we can repeat this grouping by region, this time using count()\n# and just showing the percentage of countries at replacement\nfertility %>%\n  count(region, at_replacement = rate >= 2.1) %>%\n  mutate(pct_at_rep = 100 * n / sum(n)) %>%\n  filter(at_replacement) %>%\n  select(-n, -at_replacement) %>%\n  arrange(-pct_at_rep)# A tibble: 7 × 2\n  region                     pct_at_rep\n  <chr>                           <dbl>\n1 Sub-Saharan Africa             22.6  \n2 Latin America & Caribbean      15.1  \n3 East Asia & Pacific            12.7  \n4 Europe & Central Asia          10.4  \n5 Middle East & North Africa      8.90 \n6 South Asia                      3.55 \n7 North America                   0.307\n# first get mean rate in each region + year, then pipe into line plot\n# fct_reorder2() is used to reorder legend to be same order as end of lines\n# see https://forcats.tidyverse.org/reference/fct_reorder.html for more details\nfertility %>%\n  group_by(region, year) %>%\n  summarize(median_rate = median(rate)) %>%\n  ggplot(aes(x = year, y = median_rate,\n             linetype = fct_reorder2(region, year, median_rate),\n             color = fct_reorder2(region, year, median_rate))) +\n  geom_hline(yintercept = 2.1, linetype = \"dotted\") + geom_line(linewidth = 1) +\n  labs(x = \"Year\", y = \"Median fertility rate\", linetype = \"Region\", color = \"Region\",\n       title = \"Median fertility by region from 1960-2022\",\n       subtitle = \"(black dotted line at replacement rate of 2.1)\") +\n  scale_x_continuous(expand = c(0, 0), breaks = seq(1960, 2022, 10),\n                     minor_breaks = seq(1960, 2022, 2)) +\n  scale_y_continuous(expand = c(0, 0), limits = c(1.2, 7.2),\n                     breaks = 2:7, minor_breaks = seq(1.2, 7.2, .2))\n# first get mean rate in each income group + year, then pipe into line plot\nfertility %>%\n  group_by(income_group, year) %>%\n  summarize(median_rate = median(rate)) %>%\n  ggplot(aes(x = year, y = median_rate,\n             linetype = income_group, color = income_group)) +\n  geom_hline(yintercept = 2.1, linetype = \"dotted\") + geom_line(linewidth = 1) +\n  labs(x = \"Year\", y = \"Median fertility rate\",\n       linetype = \"Income group\", color = \"Income group\",\n       title = \"Median fertility by income group from 1960-2022\",\n       subtitle = \"(black dotted line at replacement rate of 2.1)\") +\n  scale_x_continuous(expand = c(0, 0), breaks = seq(1960, 2022, 10),\n                     minor_breaks = seq(1960, 2022, 2)) +\n  scale_y_continuous(expand = c(0, 0), limits = c(1.4, 7.2),\n                     breaks = 2:7, minor_breaks = seq(1.6, 7.2, .2))"},{"path":"advanced-operations.html","id":"bonus-choropleth","chapter":"8 Advanced Operations","heading":"8.1.3.1 Bonus: choropleth","text":"’s bonus plotly choropleth just fun (need learn ). can change year pan/zoom see specific country. Red color indicates countries replacement rate 2.1, white indicates replacement rate, blue indicates replacement rate.","code":"\nlibrary(plotly)\nplot_ly(fertility, type = \"choropleth\", locations = ~code, z = ~rate,\n        text = ~country, frame = ~year, zmin = 0.7, zmax = 8.9, colorscale = list(\n        c(0, \"rgb(255,0,0)\"), c(0.1707, \"rgb(255,255,255)\"), c(1, \"rgb(0,0,255)\"))) %>%\n  layout(margin = list(l = 10, r = 10, b = 10, t = 35)) %>% animation_opts(frame = 100)"},{"path":"advanced-operations.html","id":"merging","chapter":"8 Advanced Operations","heading":"8.2 Merging","text":"Let’s move another topic: merging data frames. Often, information need may spread across several data frames different samples different sources, case may need merge data frames together.generally 2 common ways data may need merged: binding rows, joining columns.Binding rows done two data frames share columns, different rows, want combine rows together.Joining columns done two data frames share rows, different columns, want combine columns together.two , ’s important remember .","code":""},{"path":"advanced-operations.html","id":"binding","chapter":"8 Advanced Operations","heading":"8.2.1 Binding","text":"Binding simpler two, let’s start . Returning briefly penguins data set, note ’s year column indicates sample collected. means 3 different studies conducted. Suppose years originally data frame (suspect likely true).can see 3 data frames penguins2007, penguins2008, penguins2009 share exact columns (number columns, column names, column types) different rows. data frame can thought containing fraction overall samples subjects. case, must row-bind 3 data frames together.function bind_rows(df1, df2, ...) lets us . Just pass data frame needs binding :may hard see, since first 10 rows printed , look row numbers, can see now 103+113+117=333 rows binding.best results, ensure input data frames exact columns, names types!","code":"\npenguins2007 <- penguins %>% filter(year == 2007)\npenguins2008 <- penguins %>% filter(year == 2008)\npenguins2009 <- penguins %>% filter(year == 2009)\nprint(penguins2007, n = 5)# A tibble: 103 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex   \n  <chr>   <chr>              <dbl>         <dbl>             <dbl>       <dbl> <chr> \n1 Adelie  Torgersen           39.1          18.7               181        3750 male  \n2 Adelie  Torgersen           39.5          17.4               186        3800 female\n3 Adelie  Torgersen           40.3          18                 195        3250 female\n4 Adelie  Torgersen           36.7          19.3               193        3450 female\n5 Adelie  Torgersen           39.3          20.6               190        3650 male  \n# ℹ 98 more rows\n# ℹ 1 more variable: year <dbl>\nprint(penguins2008, n = 5)# A tibble: 113 × 8\n  species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex   \n  <chr>   <chr>           <dbl>         <dbl>             <dbl>       <dbl> <chr> \n1 Adelie  Biscoe           39.6          17.7               186        3500 female\n2 Adelie  Biscoe           40.1          18.9               188        4300 male  \n3 Adelie  Biscoe           35            17.9               190        3450 female\n4 Adelie  Biscoe           42            19.5               200        4050 male  \n5 Adelie  Biscoe           34.5          18.1               187        2900 female\n# ℹ 108 more rows\n# ℹ 1 more variable: year <dbl>\nprint(penguins2009, n = 5)# A tibble: 117 × 8\n  species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex   \n  <chr>   <chr>           <dbl>         <dbl>             <dbl>       <dbl> <chr> \n1 Adelie  Biscoe           35            17.9               192        3725 female\n2 Adelie  Biscoe           41            20                 203        4725 male  \n3 Adelie  Biscoe           37.7          16                 183        3075 female\n4 Adelie  Biscoe           37.8          20                 190        4250 male  \n5 Adelie  Biscoe           37.9          18.6               193        2925 female\n# ℹ 112 more rows\n# ℹ 1 more variable: year <dbl>\npenguins_bound <- bind_rows(penguins2007, penguins2008, penguins2009)\npenguins_bound# A tibble: 333 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex  \n   <chr>   <chr>              <dbl>         <dbl>             <dbl>       <dbl> <chr>\n 1 Adelie  Torgersen           39.1          18.7               181        3750 male \n 2 Adelie  Torgersen           39.5          17.4               186        3800 fema…\n 3 Adelie  Torgersen           40.3          18                 195        3250 fema…\n 4 Adelie  Torgersen           36.7          19.3               193        3450 fema…\n 5 Adelie  Torgersen           39.3          20.6               190        3650 male \n 6 Adelie  Torgersen           38.9          17.8               181        3625 fema…\n 7 Adelie  Torgersen           39.2          19.6               195        4675 male \n 8 Adelie  Torgersen           41.1          17.6               182        3200 fema…\n 9 Adelie  Torgersen           38.6          21.2               191        3800 male \n10 Adelie  Torgersen           34.6          21.1               198        4400 male \n# ℹ 323 more rows\n# ℹ 1 more variable: year <dbl>"},{"path":"advanced-operations.html","id":"joining","chapter":"8 Advanced Operations","heading":"8.2.2 Joining","text":"Joining slightly complicated. rows together, columns need spread several data frames. Often, occurs obtain data different sources want combine look patterns, can also happen sometimes multiple data frames gathered source.Joining performed first matching rows using set key variables adding additional columns. key variables uniquely identify rows. ’s simple demo start. Suppose following data frames:Suppose want join x y using column “key”, .e. “” column uniquely matches rows across data frames. 4 different joins can use: inner_join(), full_join(), left_join(), right_join() , depending rows want result:inner_join(x, y) matches rows using key variable(s), returns rows x y,full_join(x, y) matches rows using key variable(s), returns rows either x y,left_join(x, y) matches rows using key variable(s), returns rows x,right_join(x, y) matches rows using key variable(s), returns rows y.demos join. Note join exact columns; difference rows included output. Also note NAs automatically used fill missing values arise merge.4 called “mutating joins” since mutate (.e. change) data frame adding additional columns. 2 less commonly used joins called “filterting joins” called semi_join() anti_join() actually add columns; used filter rows match don’t match another data frame. Examples:examples 1 key column, works 2 key columns; rows matched values key columns.joining, R automatically look columns name use key columns. Therefore, run smoothly, ’s highly recommended ensure following joining:Key columns name type.non-key columns different names.picking join, carefully consider rows actually need later.Generally, key values unique row. need duplicate key values, watch joins closely ensure join works way want.Let’s see real example joins action.","code":"\nx <- tibble(\n  A = c(\"a\", \"b\", \"c\"),\n  B = c(1, 2, 3)\n)\ny <- tibble(\n  A = c(\"a\", \"b\", \"d\"),\n  C = ymd(\"2024.1.1\") + 0:2\n)\nx# A tibble: 3 × 2\n  A         B\n  <chr> <dbl>\n1 a         1\n2 b         2\n3 c         3\ny# A tibble: 3 × 2\n  A     C         \n  <chr> <date>    \n1 a     2024-01-01\n2 b     2024-01-02\n3 d     2024-01-03\n# only return rows in both x and y\ninner_join(x, y)# A tibble: 2 × 3\n  A         B C         \n  <chr> <dbl> <date>    \n1 a         1 2024-01-01\n2 b         2 2024-01-02\n# return rows in either x or y\nfull_join(x, y)# A tibble: 4 × 3\n  A         B C         \n  <chr> <dbl> <date>    \n1 a         1 2024-01-01\n2 b         2 2024-01-02\n3 c         3 NA        \n4 d        NA 2024-01-03\n# return only rows in x\nleft_join(x, y)# A tibble: 3 × 3\n  A         B C         \n  <chr> <dbl> <date>    \n1 a         1 2024-01-01\n2 b         2 2024-01-02\n3 c         3 NA        \n# return only rows in y\nright_join(x, y)# A tibble: 3 × 3\n  A         B C         \n  <chr> <dbl> <date>    \n1 a         1 2024-01-01\n2 b         2 2024-01-02\n3 d        NA 2024-01-03\n# semi_join(x, y) will FILTER rows in x that have matches in y\n# note there are NO new columns added to x\nsemi_join(x, y)# A tibble: 2 × 2\n  A         B\n  <chr> <dbl>\n1 a         1\n2 b         2\n# conversely, anti_join() will FILTER rows in x with NO match in y\n# again, note NO new columns were added to x\nanti_join(x, y)# A tibble: 1 × 2\n  A         B\n  <chr> <dbl>\n1 c         3"},{"path":"advanced-operations.html","id":"example-cleaning-fertility","chapter":"8 Advanced Operations","heading":"8.2.3 Example: cleaning fertility","text":"World Bank fertility data set used earlier obviously didn’t start perfectly clean tidy. download CSV file data page comes zip following two (renamed) files: fertility_meta.csv fertility_raw.csv. One contains metadata country, contains actual annual fertility rates.First, several columns like \"SpecialNotes\", \"Indicator Name\", \"Indicator Code\" don’t need; can remove select(). Country names duplicated data frames, can pick one use. Let’s pick \"TableName\" since names slightly nicer (check ). rest columns probably renamed rename().can also change \"Low income\", \"Lower middle income\", … values just \"Low\", \"Lower middle\", … slightly simplify column. Shorter labels also easier work filter() plots.Note well existence several NAs region income. , verify , subregion groupings countries (e.g. AFE AFW Eastern/Southern Western/Central African countries), can simply drop rows.Now comes key step! ’re going use \"code\" columns (3-letter ISO 3166-1 country codes) key columns join two data frames together. Let’s use inner_join() keep countries appear , since want look region income group together fertility rates.Note data frames already satisfy recommended conditions, .e. key columns name type uniquely identify country, columns different names, issues.already looks pretty good! data frames joined nicely along key \"code\" column, now region, income, fertility data 1 single data frame instead spread across 2 data frames.However, may noticed still problem: annual fertility rates spread across 63 columns, year column. compatible tidyverse functions. fix ?","code":"\nfertility_meta <- read_csv(\n  \"https://bwu62.github.io/stat240-revamp/data/fertility_meta.csv\")\nfertility_raw <- read_csv(\n  \"https://bwu62.github.io/stat240-revamp/data/fertility_raw.csv\")\nfertility_meta# A tibble: 265 × 5\n   `Country Code` Region                     IncomeGroup       SpecialNotes TableName\n   <chr>          <chr>                      <chr>             <chr>        <chr>    \n 1 ABW            Latin America & Caribbean  High income        <NA>        Aruba    \n 2 AFE            <NA>                       <NA>              \"26 countri… Africa E…\n 3 AFG            South Asia                 Low income        \"The report… Afghanis…\n 4 AFW            <NA>                       <NA>              \"22 countri… Africa W…\n 5 AGO            Sub-Saharan Africa         Lower middle inc… \"The World … Angola   \n 6 ALB            Europe & Central Asia      Upper middle inc…  <NA>        Albania  \n 7 AND            Europe & Central Asia      High income        <NA>        Andorra  \n 8 ARB            <NA>                       <NA>              \"Arab World… Arab Wor…\n 9 ARE            Middle East & North Africa High income        <NA>        United A…\n10 ARG            Latin America & Caribbean  Upper middle inc… \"The World … Argentina\n# ℹ 255 more rows\nfertility_raw# A tibble: 266 × 67\n   `Country Name`      `Country Code` `Indicator Name` `Indicator Code` `1960` `1961`\n   <chr>               <chr>          <chr>            <chr>             <dbl>  <dbl>\n 1 Aruba               ABW            Fertility rate,… SP.DYN.TFRT.IN     4.82   4.66\n 2 Africa Eastern and… AFE            Fertility rate,… SP.DYN.TFRT.IN     6.72   6.74\n 3 Afghanistan         AFG            Fertility rate,… SP.DYN.TFRT.IN     7.28   7.28\n 4 Africa Western and… AFW            Fertility rate,… SP.DYN.TFRT.IN     6.46   6.47\n 5 Angola              AGO            Fertility rate,… SP.DYN.TFRT.IN     6.71   6.79\n 6 Albania             ALB            Fertility rate,… SP.DYN.TFRT.IN     6.46   6.35\n 7 Andorra             AND            Fertility rate,… SP.DYN.TFRT.IN    NA     NA   \n 8 Arab World          ARB            Fertility rate,… SP.DYN.TFRT.IN     6.93   6.98\n 9 United Arab Emirat… ARE            Fertility rate,… SP.DYN.TFRT.IN     6.72   6.68\n10 Argentina           ARG            Fertility rate,… SP.DYN.TFRT.IN     3.08   3.07\n# ℹ 256 more rows\n# ℹ 61 more variables: `1962` <dbl>, `1963` <dbl>, `1964` <dbl>, `1965` <dbl>,\n#   `1966` <dbl>, `1967` <dbl>, `1968` <dbl>, `1969` <dbl>, `1970` <dbl>,\n#   `1971` <dbl>, `1972` <dbl>, `1973` <dbl>, `1974` <dbl>, `1975` <dbl>,\n#   `1976` <dbl>, `1977` <dbl>, `1978` <dbl>, `1979` <dbl>, `1980` <dbl>,\n#   `1981` <dbl>, `1982` <dbl>, `1983` <dbl>, `1984` <dbl>, `1985` <dbl>,\n#   `1986` <dbl>, `1987` <dbl>, `1988` <dbl>, `1989` <dbl>, `1990` <dbl>, …\n# apply the processing steps above\nfertility_meta2 <- fertility_meta %>%\n  rename(code = \"Country Code\", country = \"TableName\", region = \"Region\", income_group = \"IncomeGroup\") %>%\n  select(code, country, region, income_group) %>%\n  mutate(income_group = sub(\" income\", \"\", income_group)) %>%\n  filter(!is.na(income_group))\nfertility_raw2 <- fertility_raw %>%\n  select(2, \"1960\":last_col()) %>%\n  rename(code = \"Country Code\")\nprint(fertility_meta2, n = 5)# A tibble: 216 × 4\n  code  country     region                    income_group\n  <chr> <chr>       <chr>                     <chr>       \n1 ABW   Aruba       Latin America & Caribbean High        \n2 AFG   Afghanistan South Asia                Low         \n3 AGO   Angola      Sub-Saharan Africa        Lower middle\n4 ALB   Albania     Europe & Central Asia     Upper middle\n5 AND   Andorra     Europe & Central Asia     High        \n# ℹ 211 more rows\nprint(fertility_raw2, n = 5)# A tibble: 266 × 64\n  code  `1960` `1961` `1962` `1963` `1964` `1965` `1966` `1967` `1968` `1969` `1970`\n  <chr>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n1 ABW     4.82   4.66   4.47   4.27   4.06   3.84   3.62   3.42   3.23   3.05   2.91\n2 AFE     6.72   6.74   6.76   6.78   6.79   6.80   6.81   6.82   6.83   6.83   6.84\n3 AFG     7.28   7.28   7.29   7.30   7.30   7.30   7.32   7.34   7.36   7.39   7.4 \n4 AFW     6.46   6.47   6.49   6.51   6.53   6.54   6.56   6.59   6.61   6.64   6.66\n5 AGO     6.71   6.79   6.87   6.95   7.04   7.12   7.19   7.27   7.33   7.39   7.43\n# ℹ 261 more rows\n# ℹ 52 more variables: `1971` <dbl>, `1972` <dbl>, `1973` <dbl>, `1974` <dbl>,\n#   `1975` <dbl>, `1976` <dbl>, `1977` <dbl>, `1978` <dbl>, `1979` <dbl>,\n#   `1980` <dbl>, `1981` <dbl>, `1982` <dbl>, `1983` <dbl>, `1984` <dbl>,\n#   `1985` <dbl>, `1986` <dbl>, `1987` <dbl>, `1988` <dbl>, `1989` <dbl>,\n#   `1990` <dbl>, `1991` <dbl>, `1992` <dbl>, `1993` <dbl>, `1994` <dbl>,\n#   `1995` <dbl>, `1996` <dbl>, `1997` <dbl>, `1998` <dbl>, `1999` <dbl>, …\nfertility_joined <- inner_join(fertility_meta2, fertility_raw2)\nfertility_joined# A tibble: 216 × 67\n   code  country region income_group `1960` `1961` `1962` `1963` `1964` `1965` `1966`\n   <chr> <chr>   <chr>  <chr>         <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n 1 ABW   Aruba   Latin… High           4.82   4.66   4.47   4.27   4.06   3.84   3.62\n 2 AFG   Afghan… South… Low            7.28   7.28   7.29   7.30   7.30   7.30   7.32\n 3 AGO   Angola  Sub-S… Lower middle   6.71   6.79   6.87   6.95   7.04   7.12   7.19\n 4 ALB   Albania Europ… Upper middle   6.46   6.35   6.21   6.05   5.85   5.62   5.46\n 5 AND   Andorra Europ… High          NA     NA     NA     NA     NA     NA     NA   \n 6 ARE   United… Middl… High           6.72   6.68   6.66   6.62   6.57   6.52   6.49\n 7 ARG   Argent… Latin… Upper middle   3.08   3.07   3.11   3.10   3.08   3.06   3.05\n 8 ARM   Armenia Europ… Upper middle   4.79   4.67   4.52   4.34   4.15   3.99   3.83\n 9 ASM   Americ… East … High          NA     NA     NA     NA     NA     NA     NA   \n10 ATG   Antigu… Latin… High           4.60   4.56   4.55   4.54   4.48   4.42   4.32\n# ℹ 206 more rows\n# ℹ 56 more variables: `1967` <dbl>, `1968` <dbl>, `1969` <dbl>, `1970` <dbl>,\n#   `1971` <dbl>, `1972` <dbl>, `1973` <dbl>, `1974` <dbl>, `1975` <dbl>,\n#   `1976` <dbl>, `1977` <dbl>, `1978` <dbl>, `1979` <dbl>, `1980` <dbl>,\n#   `1981` <dbl>, `1982` <dbl>, `1983` <dbl>, `1984` <dbl>, `1985` <dbl>,\n#   `1986` <dbl>, `1987` <dbl>, `1988` <dbl>, `1989` <dbl>, `1990` <dbl>,\n#   `1991` <dbl>, `1992` <dbl>, `1993` <dbl>, `1994` <dbl>, `1995` <dbl>, …"},{"path":"advanced-operations.html","id":"pivoting","chapter":"8 Advanced Operations","heading":"8.3 Pivoting","text":"pivoting becomes relevant. Pivoting (also sometimes called reshaping) refers process transforming data different representations . Let’s start small example better illustrate point.Suppose two people Alice Bob playing game. agree play 3 rounds. round, person tries score points maximum 10. person wins rounds wins overall. Suppose final scores:However, data can also represented alternative format:Despite difference shape dimensions, data contained data frames identical. often called long wide representations data, named one tends longer (.e. rows) wider (.e. columns). Generally, long formats easier use R/tidyverse, whereas wide formats easier humans read, course exceptions everything.Usually, data considered “tidy” needs longer format. Tidy data data satisfies following:variable column; column variable.observation row; row observation.value cell; cell single value.32Data format generally easier work using tidyverse, broadly speaking R, since format highly versatile functions designed work best format.Hopefully, easy see scores_long satisfies properties. variable indeed column (vice versa), row observation (vv.), etc. also evident scores_wide tidy, since row actually contains 2 scores, column person, variable (distinction subtle meaningful).Tidyr’s pivot_longer() pivot_wider() functions let easily convert two representations. used correctly, two inverses , .e. can take data frame pivot longer, pivot wider (vice versa) get back original data frame. many ways using functions (see help page) ’s brief guide common important usage:df %>% pivot_longer(cols, names_to = \"..\", values_to = \"..\") turns “wider” representation “longer” representation.\ncols set columns actual observations “spread ”. can set using numbers, names, ranges, selector functions (just like select()). scores_wide data frame, two columns Alice Bob since points round stored.\nnames_to sets name new column containing names cols. scores_wide data frame, filled repetitions \"Alice\" \"Bob\" corresponding round’s points.\nvalues_to sets name new column containing values inside cols. scores_wide data frame, filled actual points scored round.\n\n# example:\nscores_wide %>%\n  pivot_longer(Alice:Bob, names_to = \"player\", values_to = \"points\")\n# tibble: 6 × 3\n  round player points\n  <int> <chr>   <dbl>\n1     1 Alice       9\n2     1 Bob         4\n3     2 Alice       7\n4     2 Bob         1\n5     3 Alice       2\n6     3 Bob         7cols set columns actual observations “spread ”. can set using numbers, names, ranges, selector functions (just like select()). scores_wide data frame, two columns Alice Bob since points round stored.names_to sets name new column containing names cols. scores_wide data frame, filled repetitions \"Alice\" \"Bob\" corresponding round’s points.values_to sets name new column containing values inside cols. scores_wide data frame, filled actual points scored round.df %>% pivot_wider(names_from = \"..\", values_from = \"..\") turns “longer” represetation “wider” representation.\nnames_from sets column names become column wider data frame. scores_long data frame, player column.\nvalues_from sets column actual observations fill newly created wider set columns. scores_long data frame, points column.\n\n# example:\nscores_long %>%\n  pivot_wider(names_from = \"player\", values_from = \"points\")\n# tibble: 3 × 3\n  round Alice   Bob\n  <int> <dbl> <dbl>\n1     1     9     4\n2     2     7     1\n3     3     2     7names_from sets column names become column wider data frame. scores_long data frame, player column.values_from sets column actual observations fill newly created wider set columns. scores_long data frame, points column.Note examples, passing scores_wide pivot_longer() gives us scores_long exactly, passing scores_long pivot_wider() gives us scores_wide exactly.","code":"\n# create demo scores data frame\n# sample() is used here to randomly generate points\nscores_long <- tibble(\n  round  = rep(1:3, each = 2),\n  player = rep(c(\"Alice\", \"Bob\"), 3),\n  points = c(9, 4, 7, 1, 2, 7)\n)\nscores_long# A tibble: 6 × 3\n  round player points\n  <int> <chr>   <dbl>\n1     1 Alice       9\n2     1 Bob         4\n3     2 Alice       7\n4     2 Bob         1\n5     3 Alice       2\n6     3 Bob         7\nscores_wide <- tibble(\n  round = 1:3,\n  Alice = c(9, 7, 2),\n  Bob   = c(4, 1, 7)\n)\nscores_wide# A tibble: 3 × 3\n  round Alice   Bob\n  <int> <dbl> <dbl>\n1     1     9     4\n2     2     7     1\n3     3     2     7\n# example:\nscores_wide %>%\n  pivot_longer(Alice:Bob, names_to = \"player\", values_to = \"points\")# A tibble: 6 × 3\n  round player points\n  <int> <chr>   <dbl>\n1     1 Alice       9\n2     1 Bob         4\n3     2 Alice       7\n4     2 Bob         1\n5     3 Alice       2\n6     3 Bob         7\n# example:\nscores_long %>%\n  pivot_wider(names_from = \"player\", values_from = \"points\")# A tibble: 3 × 3\n  round Alice   Bob\n  <int> <dbl> <dbl>\n1     1     9     4\n2     2     7     1\n3     3     2     7"},{"path":"advanced-operations.html","id":"example-finish-cleaning-fertility","chapter":"8 Advanced Operations","heading":"8.3.1 Example: finish cleaning fertility","text":"Let’s turn back fertility_joined example. joining, left following data frame:Now clear need apply pivot_longer():fertility data set now 100% fully cleaned ready exploration, visualization, modeling!move , let’s demonstrate one usage pivot_wider(). function also great making human-friendly summary tables, especially looking 3 variables interrelate. example, suppose want look , region, percentage countries income group. just compute percentages print, get something like :great plotting ’s wanted , e.g:However, can also see numeric values laid table using pivot_wider() put income_group column:NAs due lack countries region/income combination. case, can fill missing values setting values_fill argument:","code":"\nfertility_joined# A tibble: 216 × 67\n   code  country region income_group `1960` `1961` `1962` `1963` `1964` `1965` `1966`\n   <chr> <chr>   <chr>  <chr>         <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n 1 ABW   Aruba   Latin… High           4.82   4.66   4.47   4.27   4.06   3.84   3.62\n 2 AFG   Afghan… South… Low            7.28   7.28   7.29   7.30   7.30   7.30   7.32\n 3 AGO   Angola  Sub-S… Lower middle   6.71   6.79   6.87   6.95   7.04   7.12   7.19\n 4 ALB   Albania Europ… Upper middle   6.46   6.35   6.21   6.05   5.85   5.62   5.46\n 5 AND   Andorra Europ… High          NA     NA     NA     NA     NA     NA     NA   \n 6 ARE   United… Middl… High           6.72   6.68   6.66   6.62   6.57   6.52   6.49\n 7 ARG   Argent… Latin… Upper middle   3.08   3.07   3.11   3.10   3.08   3.06   3.05\n 8 ARM   Armenia Europ… Upper middle   4.79   4.67   4.52   4.34   4.15   3.99   3.83\n 9 ASM   Americ… East … High          NA     NA     NA     NA     NA     NA     NA   \n10 ATG   Antigu… Latin… High           4.60   4.56   4.55   4.54   4.48   4.42   4.32\n# ℹ 206 more rows\n# ℹ 56 more variables: `1967` <dbl>, `1968` <dbl>, `1969` <dbl>, `1970` <dbl>,\n#   `1971` <dbl>, `1972` <dbl>, `1973` <dbl>, `1974` <dbl>, `1975` <dbl>,\n#   `1976` <dbl>, `1977` <dbl>, `1978` <dbl>, `1979` <dbl>, `1980` <dbl>,\n#   `1981` <dbl>, `1982` <dbl>, `1983` <dbl>, `1984` <dbl>, `1985` <dbl>,\n#   `1986` <dbl>, `1987` <dbl>, `1988` <dbl>, `1989` <dbl>, `1990` <dbl>,\n#   `1991` <dbl>, `1992` <dbl>, `1993` <dbl>, `1994` <dbl>, `1995` <dbl>, …\n# let's pivot_longer(), then drop any rows with missing values\n# after our careful processing, it should be safe to just do drop_na()\n# we can also again convert income_group to ordered categories if needed,\n# and finally arrange by country and year for extra neatness\nfertility <- fertility_joined %>%\n  pivot_longer(\"1960\":last_col(), names_to = \"year\", values_to = \"rate\") %>%\n  drop_na() %>%\n  mutate(income_group = factor(income_group, ordered = TRUE, levels = c(\n    \"Low\", \"Lower middle\", \"Upper middle\", \"High\"))) %>%\n  arrange(country, year)\n# print our final, clean & tidy data frame!\nfertility# A tibble: 13,050 × 6\n   code  country     region     income_group year   rate\n   <chr> <chr>       <chr>      <ord>        <chr> <dbl>\n 1 AFG   Afghanistan South Asia Low          1960   7.28\n 2 AFG   Afghanistan South Asia Low          1961   7.28\n 3 AFG   Afghanistan South Asia Low          1962   7.29\n 4 AFG   Afghanistan South Asia Low          1963   7.30\n 5 AFG   Afghanistan South Asia Low          1964   7.30\n 6 AFG   Afghanistan South Asia Low          1965   7.30\n 7 AFG   Afghanistan South Asia Low          1966   7.32\n 8 AFG   Afghanistan South Asia Low          1967   7.34\n 9 AFG   Afghanistan South Asia Low          1968   7.36\n10 AFG   Afghanistan South Asia Low          1969   7.39\n# ℹ 13,040 more rows\n# count how many countries in each region + income group,\n# regroup by region to compute percentages,\n# remove the n count column, and print\nregion_income_pct <- fertility %>%\n  count(region, income_group) %>%\n  group_by(region) %>%\n  mutate(pct = round(100 * n / sum(n), 1)) %>%\n  select(-n) %>%\n  print()# A tibble: 22 × 3\n# Groups:   region [7]\n   region                    income_group   pct\n   <chr>                     <ord>        <dbl>\n 1 East Asia & Pacific       Low            2.9\n 2 East Asia & Pacific       Lower middle  35.2\n 3 East Asia & Pacific       Upper middle  26.4\n 4 East Asia & Pacific       High          35.5\n 5 Europe & Central Asia     Lower middle   5.6\n 6 Europe & Central Asia     Upper middle  27.8\n 7 Europe & Central Asia     High          66.7\n 8 Latin America & Caribbean Lower middle  10  \n 9 Latin America & Caribbean Upper middle  47.5\n10 Latin America & Caribbean High          42.5\n# ℹ 12 more rows\n# plot income group percentages by region\n# str_wrap used to line-break long region names\nregion_income_pct %>% \n  ggplot(aes(x = str_wrap(region, 12), y = pct, fill = income_group)) +\n  geom_col() + labs(x = NULL, y = \"Percent\", fill = \"Income level\",\n                    title = \"% countries in each income level by region\")\n# pivot region/income percentages to wider table format\nregion_income_pct %>%\n  pivot_wider(names_from = income_group, values_from = pct)# A tibble: 7 × 5\n# Groups:   region [7]\n  region                       Low `Lower middle` `Upper middle`  High\n  <chr>                      <dbl>          <dbl>          <dbl> <dbl>\n1 East Asia & Pacific          2.9           35.2           26.4  35.5\n2 Europe & Central Asia       NA              5.6           27.8  66.7\n3 Latin America & Caribbean   NA             10             47.5  42.5\n4 Middle East & North Africa   9.7           31.8           19.5  39  \n5 North America               NA             NA             NA   100  \n6 South Asia                  12.5           75             12.5  NA  \n7 Sub-Saharan Africa          46.3           40             12.6   1  \n# fill in missing values with 0 in region/income table\nregion_income_pct %>%\n  pivot_wider(names_from = income_group, values_from = pct, values_fill = 0)# A tibble: 7 × 5\n# Groups:   region [7]\n  region                       Low `Lower middle` `Upper middle`  High\n  <chr>                      <dbl>          <dbl>          <dbl> <dbl>\n1 East Asia & Pacific          2.9           35.2           26.4  35.5\n2 Europe & Central Asia        0              5.6           27.8  66.7\n3 Latin America & Caribbean    0             10             47.5  42.5\n4 Middle East & North Africa   9.7           31.8           19.5  39  \n5 North America                0              0              0   100  \n6 South Asia                  12.5           75             12.5   0  \n7 Sub-Saharan Africa          46.3           40             12.6   1  "},{"path":"data-modeling.html","id":"data-modeling","chapter":"Data Modeling","heading":"Data Modeling","text":"next section, discuss start modeling cleaned data. loosely broken several sections.start discussing big picture view modeling works learn key conceptual topics like populations vs samples, probability vs statistics, parameters vs estimates, etc., cover foundational probability principles necessary understanding later modeling steps, discrete continuous random variables, distributions, PDF/PMFs vs CDFs, expectation variance, .Next, learn arguably two important versatile random variables: normal & binomial, form basis two general categories models discuss later (means vs proportions infereence).Finally, conclude introducing basic framework hypothesis tests & confidence intervals, explore apply following section.","code":""},{"path":"overview.html","id":"overview","chapter":"9 Overview","heading":"9 Overview","text":"want start modeling section following overview role modeling plays “life cycle” data science project.Roughly speaking, data science can divided 3 phases:Phase , identify research question, design experiment, gather sample, collect raw data. steps correspond first row “life cycle”.Phase II, start raw data clean (probably 60-90% time actually spent), explore , figure best way model . second row.Phase III, fine tune model, double check work, interpret results, may involve reporting estimates, computing tests/intervals, making predictions, etc. third row.Usually, iterative process; start question, gather data, analyze , either modify initial inquiry ask follow question, cycle continues.Experiment design & sampling advanced topic, thus covered detail STAT 240, however summarize key ideas Phase next subsection since relevant later topics.’ve spent lot time learning basics data cleaning, exploration, visualization, ’re reasonably well covered Phase II now, though course ’re always encouraged explore .remainder class, focus Phase III: identifying appropriate models, fitting well, interpreting results meaningfully, producing useful inference hypothesis tests & confidence intervals, communicating results effectively broader audience.First, need briefly summarize key concepts relating experiment design greatly enrich later exploration models.","code":""},{"path":"overview.html","id":"population-vs-sample","chapter":"9 Overview","heading":"9.1 Population vs sample","text":"Statistics primarily science studying samples understand populations. Generally, ’s impractical observe every member population, luckily usually necessary well-drawn sample sufficient answer questions.population can large group want learn , e.g. US mothers (~85 million), arctic terns (~3 million), gen-5 Toyota Priuses (~15000), etc..sample smaller set drawn (intended represent) population.MANY ways draw sample, pros, cons, potential biases. detailed discussion reserved advanced courses.","code":""},{"path":"overview.html","id":"model-vs-data","chapter":"9 Overview","heading":"9.2 Model vs data","text":"Using mathematical logic, can derive different theoretical probability models certain parameters aim represent real world phenomena, compare real data, .e. fitting, evaluate performance make inferences /predictions.model idealized mathematical representation process, e.g. normal distribution may used model distribution human heights.Models often parameters values can adjusted (“tuned”) fit model matches real data.distinction model vs data may seem obvious, often analogous features often easily confused one another. example, model can theoretical statistics values mean, median, variance, skew, etc. related different sample statistics mean, median, variance, skew.Recall statistic can computed numeric summary dataset (hypothethical model). values discussed chapter 5 examples statistics.sample suffciently large high quality, model well chosen, values match, .e. model’s predicted statistics agree sample statistics, problems along process can result discrepancies.","code":""},{"path":"intro-to-probability.html","id":"intro-to-probability","chapter":"10 Intro to Probability","heading":"10 Intro to Probability","text":"section, ’ll introduce foundational probability theory necessary later models. way semi-rigorous, emphasis teaching materials intuitive fashion.","code":""},{"path":"intro-to-probability.html","id":"random-variables","chapter":"10 Intro to Probability","heading":"10.1 Random variables","text":"Suppose experiment produces outcome time ’s observed. modeled random variable, often denoted capital letter, e.g. \\(X\\) \\(Y\\). set possible outcomes called sample space often denoted \\(\\Omega\\).Sets possible outcomes called events. event probability associated . probability event often denoted \\(P(\\text{event})\\).Let \\(X\\) result rolling 6-sided die fair, .e. outcomes 1, 2, 3, 4, 5, 6 equal probability. examples events corresponding probabilities:Probability getting 1: \\(P(X=1)=\\frac16\\)Probability getting 4: \\(P(X>4)=\\frac13\\)Probability getting even number: \\(P(X=2,4,\\text{}6)=\\frac12\\)Probability getting 7: \\(P(X=7)=0\\)","code":""},{"path":"intro-to-probability.html","id":"axioms-of-probability","chapter":"10 Intro to Probability","heading":"10.2 Axioms of probability","text":"math, axioms basic rules formally define object inviolably true. axioms probability, can never broken:probability event always non-negative.\nMathematically, \\(P(E)\\ge0\\) event \\(E\\) random variable.\nMathematically, \\(P(E)\\ge0\\) event \\(E\\) random variable.probability entire sample space always 1.\nMathematically, \\(P(\\Omega)=1\\) random variable. Note 1 equivalent 100%.\nMathematically, \\(P(\\Omega)=1\\) random variable. Note 1 equivalent 100%.probability union mutually exclusive events equal sum probabilities event.\nMathematically, \\(\\cap B\\) empty, \\(P(\\cup B)=P()+P(B)\\)\nMathematically, \\(\\cap B\\) empty, \\(P(\\cup B)=P()+P(B)\\)Let \\(\\) \\(B\\) two events random variable.union \\(\\) \\(B\\), denoted \\(\\cup B\\), event observing \\(\\) \\(B\\).intersection \\(\\) \\(B\\), denoted \\(\\cap B\\), event observing \\(\\) \\(B\\).\\(\\), \\(B\\) mutually exclusive, intersection, .e. outcomes \\(\\) \\(B\\).Let’s see example. Let \\(X\\) result rolling fair, 6-sided die outcomes 1,2,…,6.Let \\(\\) event observing \\(X\\) 4, let \\(B\\) event observing \\(X\\) even number. , \\(\\cap B=\\{6\\}\\) \\(\\cup B=\\{2,4,5,6\\}\\). Note \\(1,3\\) neither \\(\\) \\(B\\).Since \\(\\cap B=\\{6\\}\\) empty, \\(\\) \\(B\\) mutually exclusive. Suppose define third event \\(C\\) observing \\(X\\) either 1 3. , \\(C\\) mutually exclusive \\(\\) \\(B\\), since \\(\\cap C\\) \\(B\\cap C\\) empty.","code":""},{"path":"datasets.html","id":"datasets","chapter":"A Datasets","heading":"A Datasets","text":"page contains updating/processing scripts additional info datasets used course, well brief discussions chosen. Datasets ordered order appearance notes.Also, since mostly keep track datasets processing scripts, ’s meticulously formatted like rest notes, e.g. lines code kept ~80 characters, comments may brief, ’re . may also use advanced syntax additional packages. Read discretion.","code":"\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(lubridate)\nlibrary(xlsx)"},{"path":"datasets.html","id":"datasets-list","chapter":"A Datasets","heading":"A.1 List of datasets","text":"’s convenient list dataset files generated. Note files used notes!. primarily record keeping purposes. Also note files may automatically open download prompt others may . force download, right click file link choose “Save link ”.enrollment.csveruptions_recent.csveruptions_recent.delimeruptions_recent.tsveruptions_recent.xlsxfertility_meta.csvfertility_raw.csvfertility.csvpenguins.csvAlternatively, can also run following line, download files current working directory. ’s recommended first set working directory appropriate place running , e.g. data/ directory STAT240/ course folder.","code":"\nlapply(readLines(\"https://bwu62.github.io/stat240-revamp/data_list.txt\"),\n       \\(.)download.file(.,basename(.)))"},{"path":"datasets.html","id":"eruptions","chapter":"A Datasets","heading":"A.2 Eruptions","text":"introducing reading CSVs, wanted dataset 4 data types discussed (numeric, logical, character, date) interesting enough, without many columns rows, without problems add complexity since ’re just starting . volcanic eruptions dataset (specifically “Holocene Eruptions”) table seemed fit bill nicely.","code":""},{"path":"datasets.html","id":"load-raw-data","chapter":"A Datasets","heading":"A.2.1 Load raw data","text":"","code":"\n# load html source code\neruptions_raw <- read_html(\"https://volcano.si.edu/volcanolist_countries.cfm?country=United%20States\") %>% \n  # extract table code\n  html_nodes(xpath=\"//table[@title='Holocene Eruptions']\") %>% \n  # convert to data frame\n  html_table(header=T,na.strings=c(\"Uncertain\",\"Unknown\",\"[Unknown]\")) %>% \n  # remove list wrapper\n  .[[1]] %>% \n  # remove unnecessary evidence column\n  select(-Evidence) %>% \n  # make names nice\n  set_names(c(\"volcano\",\"start\",\"stop\",\"confirmed\",\"vei\"))"},{"path":"datasets.html","id":"process-data","chapter":"A Datasets","heading":"A.2.2 Process data","text":"","code":"\neruptions <- eruptions_raw %>% \n  mutate(\n    volcano = str_replace(volcano,\"°\",\"°\"),\n    # convert confirmed? column to logical\n    confirmed = if_else(replace_na(confirmed,\"NA\")==\"Confirmed\",T,F),\n    # replace continuing eruptions with today's date\n    # (continuation last validated 7/23/24)\n    stop = if_else(str_detect(stop,\"continu\"),format(today(),\"%Y %b %e\"),stop,missing=stop)\n  ) %>% \n  # extract date error to new column\n  separate(start,c(\"start\",\"start_error\"),\"±\") %>% \n  separate(stop,c(\"stop\",\"stop_error\"),\"±\") %>% \n  mutate(\n    # fix a few names\n    volcano = volcano %>% str_replace(\"Asuncion\",\"Asunción\") %>% str_replace(\"Pajaros\",\"Pájaros\") %>% str_replace(\"Kilauea\",\"Kīlauea\"),\n    # parse error time string to number of days\n    start_error = as.duration(start_error)/ddays(1),\n    stop_error = as.duration(stop_error)/ddays(1),\n    # extract start year since some earlier eruptions are missing month/day\n    start_year = str_extract(start,\"(\\\\d{4,5})\"),\n    stop_year = str_extract(stop,\"(\\\\d{4,5})\"),\n    # parse start year, adding - if BCE\n    start_year = as.numeric(start_year) * if_else(str_detect(start,\"BCE\"),-1,1),\n    stop_year = as.numeric(stop_year) * if_else(str_detect(stop,\"BCE\"),-1,1),\n    # extract start month\n    start_month = str_replace(start,\".*\\\\d{4}\\\\s([:alpha:]{3}).*\",\"\\\\1\"),\n    stop_month = str_replace(stop,\".*\\\\d{4}\\\\s([:alpha:]{3}).*\",\"\\\\1\"),\n    start = start %>% str_replace_all(\"\\\\[|\\\\]|\\\\(.*?\\\\)\",\"\") %>% str_extract(\"^\\\\s?\\\\d+\\\\s\\\\w+\\\\s\\\\d+\") %>% ymd,\n    stop = stop %>% str_replace_all(\"\\\\[|\\\\]|\\\\(.*?\\\\)\",\"\") %>% str_extract(\"^\\\\s?\\\\d+\\\\s\\\\w+\\\\s\\\\d+\") %>% ymd,\n    # if missing date but has month, use middle day +- half-month error\n    # first, compute number of days in each month\n    start_mdays = days_in_month(ymd(str_c(start_year,start_month,\"1\"))),\n    stop_mdays = days_in_month(ymd(str_c(stop_year,stop_month,\"1\"))),\n    # next, if start/stop NA but month exists, set error as half of number of days in month rounded up, then set no error (NA) as 0\n    start_error = if_else(is.na(start) & !is.na(start_month) & is.na(start_error),ceiling(start_mdays/2),start_error) %>% replace_na(0),\n    stop_error = if_else(is.na(stop) & !is.na(stop_month) & is.na(stop_error),ceiling(stop_mdays/2),stop_error) %>% replace_na(0),\n    # finally, if start/stop NA but month exists, set start/stop as middle day of month rounded down\n    start = if_else(is.na(start) & !is.na(start_month),ymd(str_c(start_year,start_month,floor(start_mdays/2))),start),\n    stop = if_else(is.na(stop) & !is.na(stop_month),ymd(str_c(stop_year,stop_month,floor(stop_mdays/2))),stop),\n    duration = (stop-start)/ddays(1)\n  ) %>% \n  # remove intermediate rows\n  select(volcano,start,start_error,start_year,stop,stop_error,stop_year,duration,confirmed,vei)\n\n# get just subset for demo\neruptions_recent <- eruptions %>% \n  filter(start_error <= 30, start_year > 2000, !is.na(stop)) %>% \n  select(-contains(\"_\"))"},{"path":"datasets.html","id":"write-out-data","chapter":"A Datasets","heading":"A.2.3 Write out data","text":"","code":"\n# save complete file too\nwrite_csv(eruptions,file=\"data/eruptions.csv\")\n\n# write out to different formats for reading\nwrite_csv(eruptions_recent,file=\"data/eruptions_recent.csv\")\nwrite_tsv(eruptions_recent,file=\"data/eruptions_recent.tsv\")\nwrite_delim(eruptions_recent,file=\"data/eruptions_recent.delim\",delim=\"|\",na=\"\")\neruptions_recent %>% as.data.frame %>% write.xlsx(file=\"data/eruptions_recent.xlsx\",row.names=F,showNA=F)\n\n# originally line below was b/c I wanted to prep example for read_table but turns out\n# its behavior changed recentlyish https://www.tidyverse.org/blog/2021/07/readr-2-0-0/\n# it no longer works well here, and read.table needs to be used instead\n# (alternatively read_fwf from readr also works but that seems beyond scope)\n# but I don't want to confuse students by introducing a mix of readr + base R\n# so quitting this example, need to reevaluate in the future importance\n# of reading whitespace aligned table formats\n\n# eruptions_recent %>% as.data.frame %>% print(print.gap=2,width=1000,row.names=F,right=F) %>% capture.output() %>% \n#   str_replace(\"<NA>\",\"NA  \") %>% str_replace(\"^ *\",'\"') %>% str_replace(\"( {2,})\",'\"\\\\1') %>% str_replace('\"name\"',\"name  \") %>% write_lines(file=\"data/eruptions_recent.txt\")"},{"path":"datasets.html","id":"inspect-data","chapter":"A Datasets","heading":"A.2.4 Inspect data","text":"","code":"\neruptions_recent# A tibble: 73 × 6\n   volcano               start      stop       duration confirmed   vei\n   <chr>                 <date>     <date>        <dbl> <lgl>     <dbl>\n 1 Kīlauea               2024-06-03 2024-06-03        0 TRUE         NA\n 2 Atka Volcanic Complex 2024-03-27 2024-03-27        0 TRUE         NA\n 3 Ahyi                  2024-01-01 2024-03-27       86 TRUE         NA\n 4 Kanaga                2023-12-18 2023-12-18        0 TRUE          1\n 5 Ruby                  2023-09-14 2023-09-15        1 TRUE          1\n 6 Shishaldin            2023-07-11 2023-11-03      115 TRUE          3\n 7 Mauna Loa             2022-11-27 2022-12-10       13 TRUE          0\n 8 Ahyi                  2022-11-18 2023-06-11      205 TRUE          1\n 9 Kīlauea               2021-09-29 2023-09-16      717 TRUE          0\n10 Pavlof                2021-08-05 2022-12-07      489 TRUE          2\n# ℹ 63 more rows"},{"path":"datasets.html","id":"palmer-penguins-1","chapter":"A Datasets","heading":"A.3 Palmer penguins","text":"data visualization, wanted feature rich dataset healthy combination numerics characters ready go, easy use, fun & interesting, make good looking plots demos. spent long brainstorming ideas, including scraping additional info volcanoes, wasn’t happy result. , looking inspiration, found Hadley Wickham’s excellent R4DS book Palmer penguins dataset, absolutely perfect.Now, want students continue practicing reading datasets, following code simple extracts dataset therein rewrites .","code":""},{"path":"datasets.html","id":"write-out-data-1","chapter":"A Datasets","heading":"A.3.1 Write out data","text":"","code":"\nlibrary(palmerpenguins)\nwrite_csv(penguins %>% drop_na,\"data/penguins.csv\")"},{"path":"datasets.html","id":"inspect-data-1","chapter":"A Datasets","heading":"A.3.2 Inspect data","text":"","code":"\npenguins# A tibble: 333 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex  \n   <chr>   <chr>              <dbl>         <dbl>             <dbl>       <dbl> <chr>\n 1 Adelie  Torgersen           39.1          18.7               181        3750 male \n 2 Adelie  Torgersen           39.5          17.4               186        3800 fema…\n 3 Adelie  Torgersen           40.3          18                 195        3250 fema…\n 4 Adelie  Torgersen           36.7          19.3               193        3450 fema…\n 5 Adelie  Torgersen           39.3          20.6               190        3650 male \n 6 Adelie  Torgersen           38.9          17.8               181        3625 fema…\n 7 Adelie  Torgersen           39.2          19.6               195        4675 male \n 8 Adelie  Torgersen           41.1          17.6               182        3200 fema…\n 9 Adelie  Torgersen           38.6          21.2               191        3800 male \n10 Adelie  Torgersen           34.6          21.1               198        4400 male \n# ℹ 323 more rows\n# ℹ 1 more variable: year <dbl>"},{"path":"datasets.html","id":"college-enrollment","chapter":"A Datasets","heading":"A.4 College enrollment","text":"also briefly needed nice time series dataset 1 groups demonstrate line plots. Eventually settled table 303.10 National Center Education Statistics (NCES) contains historic college enrollment data, stratified sex.","code":"\nlast.yy <- tryCatch({\n  rvest::read_html(\"https://nces.ed.gov/programs/digest/current_tables.asp\") %>%\n  rvest::html_nodes(xpath=\"//select[@name='quickjump']/option[2]/text()\") %>% \n  as.character %>% as.numeric\n},error = \\(e){\n  (lubridate::year(Sys.Date()-3*30)-1)\n}) %% 100"},{"path":"datasets.html","id":"process-data-1","chapter":"A Datasets","heading":"A.4.1 Process data","text":"","code":"\nenrollment <- \"https://nces.ed.gov/programs/digest/d{last.yy}/tables/dt{last.yy}_303.10.asp\" %>% \n  str_glue %>% \n  read_html %>% \n  html_nodes(xpath=\"//div[@class='nces']/table[1]\") %>% \n  html_table %>% \n  {.[[1]][-3,]} %>% \n  t %>% as.data.frame %>% \n  rownames_to_column %>% \n  unite(\"name\",1:3) %>% \n  column_to_rownames(\"name\") %>% \n  t %>% as.data.frame %>% \n  select(matches(\"Year|(Sex.*(Male|Female))|Nonprofit\",ignore.case=F)) %>% \n  set_names(c(\"year\",\"male\",\"female\",\"nonprofit\")) %>% \n  mutate(year = str_sub(year,1,4)) %>% \n  mutate_all(parse_number) %>% \n  filter(!(is.na(year)&is.na(male)&is.na(female))&year>20,\n         year<year(today())-10|!is.na(nonprofit)) %>% \n  select(-nonprofit) %>% \n  mutate(male = male/1e6, female = female/1e6) %>% \n  pivot_longer(male:female,names_to=\"sex\",values_to=\"enrolled_millions\")"},{"path":"datasets.html","id":"write-out-data-2","chapter":"A Datasets","heading":"A.4.2 Write out data","text":"","code":"\nwrite_csv(enrollment, file=\"data/enrollment.csv\")"},{"path":"datasets.html","id":"inspect-data-2","chapter":"A Datasets","heading":"A.4.3 Inspect data","text":"","code":"\nenrollment# A tibble: 146 × 3\n    year sex    enrolled_millions\n   <dbl> <chr>              <dbl>\n 1  1947 male               1.66 \n 2  1947 female             0.679\n 3  1948 male               1.71 \n 4  1948 female             0.694\n 5  1949 male               1.72 \n 6  1949 female             0.723\n 7  1950 male               1.56 \n 8  1950 female             0.721\n 9  1951 male               1.39 \n10  1951 female             0.711\n# ℹ 136 more rows"},{"path":"datasets.html","id":"fertility-rate","chapter":"A Datasets","heading":"A.5 Fertility rate","text":"advanced data operations section needed something suitable demonstrating grouping, joining, pivoting, hopefully interesting. found World Bank fertility rate dataset quite suitable purpose. dataset presented 2 ways, first fully cleaned version grouping, partially cleaned version joining pivoting.","code":""},{"path":"datasets.html","id":"process-data-2","chapter":"A Datasets","heading":"A.5.1 Process data","text":"","code":"\nif(!dir.exists(\"temp\")) dir.create(\"temp\")\nf <- \"temp/fertility.zip\"\ndownload.file(\"https://api.worldbank.org/v2/en/indicator/SP.DYN.TFRT.IN?downloadformat=csv\",f,mode=\"wb\")\nfiles = unzip(f, list=T)$Name %>% str_subset(\"Indicator\",negate=T)\nunzip(f,files,exdir=\"temp/\")\nfertility_meta <- str_subset(list.files(\"temp/\",full=T),\"^temp/Meta.*API_SP.DYN.TFRT\") %>% read_csv\nskip = str_subset(list.files(\"temp/\",full=T),\"^temp/API_SP.DYN.TFRT\") %>% read_lines %>% \n  str_detect(\"Country Name\") %>% which %>% min %>% subtract(1)\nfertility_raw <- str_subset(list.files(\"temp/\",full=T),\"^temp/API_SP.DYN.TFRT\") %>% read_csv(skip=skip)\n# simplify/shorten some names for convenience\nfertility_meta <- fertility_meta %>% mutate(\n  TableName = TableName %>% \n    str_replace_all(c(\n      \" and the \" = \" & \",\n      \" and \" = \" & \",\n      \", The\" = \"\",\n      \"SAR, China\" = \"\",\n      \"Korea, Rep.\" = \"South Korea\",\n      \"British Virgin Islands\" = \"Virgin Islands\",\n      \"Russian Federation\" = \"Russia\",\n      \" \\\\(.*\" = \"\",\n      \"Slovak Republic\" = \"Slovakia\",\n      \"Iran, Islamic Rep.\" = \"Iran\",\n      \"Brunei Darussalam\" = \"Brunei\",\n      \"Korea, Dem. People's Rep.\" = \"North Korea\",\n      \"Cabo Verde\" = \"Cape Verde\",\n      \"Türkiye\" = \"Turkey\",\n      \"Viet Nam\" = \"Vietnam\",\n      \"Lao PDR\" = \"Laos\",\n      \"Micronesia, Fed. Sts.\" = \"Micronesia\",\n      \"Syrian Arab Republic\" = \"Syria\",\n      \"Kyrgyz Republic\" = \"Kyrgyzstan\",\n      \"Egypt, Arab Rep.\" = \"Egypt\",\n      \"Timor-Leste\" = \"East Timor\",\n      \"Yemen, Rep.\" = \"Yemen\",\n      \"Côte d'Ivoire\" = \"Ivory Coast\"\n    ))\n)\n\n# remove some extra columns with only NAs?\n\nfertility_meta <- fertility_meta %>% select(where(\\(x)mean(is.na(x))<1))\nfertility_raw <- fertility_raw %>% select(where(\\(x)mean(is.na(x))<1))"},{"path":"datasets.html","id":"write-out-raw-data","chapter":"A Datasets","heading":"A.5.2 Write out raw data","text":"","code":"\nwrite_csv(fertility_meta, file=\"data/fertility_meta.csv\")\nwrite_csv(fertility_raw, file=\"data/fertility_raw.csv\")"},{"path":"datasets.html","id":"process-more-tidy-version","chapter":"A Datasets","heading":"A.5.3 Process more (tidy version)","text":"","code":"\nfertility_meta <- fertility_meta %>% filter(!is.na(IncomeGroup)) %>% \n  rename(code = \"Country Code\", country = \"TableName\", region = \"Region\", income_group = \"IncomeGroup\") %>% \n  select(code, country, region, income_group)\n\nfertility <- fertility_raw %>% select(-matches(\"Indicator|Name|^\\\\.\\\\.\")) %>% \n  rename(code = \"Country Code\") %>% inner_join(fertility_meta) %>%\n  pivot_longer(matches(\"^\\\\d+\"),names_to=\"year\",values_to=\"rate\") %>% \n  # mutate(income_group = factor(str_replace(income_group,\" income\",\"\"),ordered = T, levels=c(\n  #   \"Low\", \"Lower middle\", \"Upper middle\", \"High\"))) %>%\n  arrange(country,year)\n# # show pct NA for each country with NAs\n# fertility %>% group_by(country) %>% summarize(pctna = round(100*mean(is.na(rate)))) %>% filter(pctna>0) %>% arrange(-pctna)\n# # show all years for these countries to see pattern of NAs\n# fertility %>% group_by(country) %>% mutate(pctna = 100*mean(is.na(rate))) %>% ungroup %>% \n#   filter(pctna>0) %>% arrange(-pctna) %>% pivot_wider(names_from = year,values_from = rate) %>% View\n\n# based on exploration, let's just drop the small number of country/year combos with NAs for simplicity\nfertility <- fertility %>% drop_na()"},{"path":"datasets.html","id":"write-out-tidy-data","chapter":"A Datasets","heading":"A.5.4 Write out tidy data","text":"","code":"\nwrite_csv(fertility, \"data/fertility.csv\")"},{"path":"datasets.html","id":"inspect-data-3","chapter":"A Datasets","heading":"A.5.5 Inspect data","text":"","code":"\nfertility"},{"path":"cheat-sheets.html","id":"cheat-sheets","chapter":"B Cheat Sheets","heading":"B Cheat Sheets","text":"consolidation “cheat sheets” mentioned notes, well extra mentioned. page intended use quick reference basically entire course without needing dig notes. ’re loosely organized order appearance.","code":""},{"path":"cheat-sheets.html","id":"rstudio-ide","chapter":"B Cheat Sheets","heading":"B.1 Rstudio IDE","text":"Rstudio cheat sheet detailed description every button Rstudio , well additional tips like common keyboard shortcuts workflow suggestions.","code":""},{"path":"cheat-sheets.html","id":"base-r","chapter":"B Cheat Sheets","heading":"B.2 Base R","text":"Matt Baggott’s R Reference Card v2.0 nice complete one-stop-shop R’s built-functions.IQSS’s Base R Cheat Sheet Alexey Shipunov’s One Page R Reference Card slightly shorter curated, offer nice, tighter set critical R commands, along useful examples syntax.slightly longer complete reference manual R, especially details R works different object types data structures, Emmanuel Paradis’s R Beginners may helpful.","code":""},{"path":"cheat-sheets.html","id":"r-markdown-1","chapter":"B Cheat Sheets","heading":"B.3 R Markdown","text":"R Markdown cheat sheet convenient summary everything need know effectively use R Markdown, including basic markdown syntax, common chunk/YAML options, additional styling settings, .’s also slightly longer R Markdown reference guide longer list chunk YAML options.’s also separate Markdown cheat sheet; note basic syntax completely supported, extended syntax supported. Feel free experiment .","code":""},{"path":"cheat-sheets.html","id":"latex","chapter":"B Cheat Sheets","heading":"B.4 \\(\\LaTeX\\)","text":"wish read \\(\\LaTeX\\), start Rong Zhuang’s MathJax cheat sheet David Richeson’s quick guide lots great beginner-friendly examples. slightly complete list symbols, Eric Torrence’s cheat sheet may also useful.","code":""},{"path":"cheat-sheets.html","id":"readr","chapter":"B Cheat Sheets","heading":"B.5 readr","text":"readr cheat sheet good overview read_* functions well example code common arguments.","code":""},{"path":"cheat-sheets.html","id":"lubridate","chapter":"B Cheat Sheets","heading":"B.6 lubridate","text":"first page lubridate cheat sheet useful quickly checking ’re using right date-related operation.","code":""},{"path":"cheat-sheets.html","id":"ggplot2-1","chapter":"B Cheat Sheets","heading":"B.7 ggplot2","text":"ggplot2 cheat sheet great summary every plot type first page, organized type number variables ’s designed visualize. second page, ’s nice list additional plot features, faceting (.e. subplot) options, setting scales, adjusting positions plot elements, changing themes, editing labels/legends, etc.","code":""},{"path":"cheat-sheets.html","id":"dplyr","chapter":"B Cheat Sheets","heading":"B.8 dplyr","text":"dplyr cheat sheet basic rundown common data frame transformation operations, grouped type, along brief helpful examples diagrams. includes everything subsetting rows columns, adding/editing columns, summarizing data frames, grouping operations, joining/binding multiple data frames, etc.","code":""},{"path":"cheat-sheets.html","id":"tidyr","chapter":"B Cheat Sheets","heading":"B.9 tidyr","text":"tidyr cheat shows summary different data tidying operations, cover class. Notably, use NA reshaping operations. Feel free read .","code":""}]
